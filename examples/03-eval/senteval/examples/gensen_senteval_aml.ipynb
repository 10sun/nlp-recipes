{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on GenSen model by SentEval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentEval is the evaluation toolkit for sentence embeddings. SentEval is a library for evaluating the quality of sentence embeddings. It is used to assess their generalization power by using them as features on a broad and diverse set of \"transfer\" tasks. SentEval currently includes 17 downstream tasks.\n",
    "\n",
    "This notebook will show you how to run SentEval and evaluate trained GenSen model locally. We used the [SentEval](https://github.com/facebookresearch/SentEval) toolkit to run most of our transfer learning experiments. To replicate these numbers, clone their repository and follow setup instructions. Once complete, copy this notebook and `gensen.py` into their examples folder and run the following commands to reproduce different rows in Table 2 of our paper. Note: Please set the path to the pretrained glove embeddings (`glove.840B.300d.h5`) and model folder as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the functions used in the notebook can be found in the `gensen.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.23\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\lishao\\Project\\NLP\\examples\\03-eval\\senteval\\examples\\.azureml\\config.json\n",
      "Workspace name: MAIDAPNLP\n",
      "Azure region: eastus2\n",
      "Subscription id: 15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\n",
      "Resource group: nlprg\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_run:begin\n",
    "# Import dependencies\n",
    "# pip install azureml-contrib-notebook\n",
    "from azureml.core import Workspace, Experiment, RunConfiguration\n",
    "from azureml.contrib.notebook.notebook_run_config import NotebookRunConfig\n",
    "\n",
    "# Create new experiment\n",
    "ws = Workspace.from_config()\n",
    "exp = Experiment(workspace, \"simple_notebook_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-04-23T12:27:46.775000+00:00', 'errors': None, 'creationTime': '2019-04-17T17:21:26.968570+00:00', 'modifiedTime': '2019-04-17T17:27:28.740980+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT7200S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current AmlCompute. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "ds = Datastore.register_azure_file_share(workspace=ws,\n",
    "                                        datastore_name= 'GenSen',\n",
    "                                        file_share_name='azureml-filestore-09b72610-7938-4ed2-86a2-5004896b12d9',\n",
    "                                        account_name='maidapnlp0056795534',\n",
    "                                        account_key='8LtGFZErNlvI6fSrgODqCxJCckkVgq3AL/5S/8ma7Re7xUHgWrNRCfTFnP/QDhF7KDY6ScAORsUpSm7ziog5/Q==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "# Customize run configuration to execute in user managed environment\n",
    "run_config_user_managed = RunConfiguration()\n",
    "run_config_user_managed.target = compute_target.name\n",
    "\n",
    "dr = {\n",
    "    'nsmr': ds.as_mount()\n",
    "}\n",
    "\n",
    "run_config_user_managed.data_references = dr\n",
    "\n",
    "# Specify conda dependencies with scikit-learn\n",
    "# cd = CondaDependencies.create(conda_packages=['scikit-learn'])\n",
    "# run_config_user_managed.environment.python.conda_dependencies = cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create notebook run configuration and set parameters values\n",
    "cfg = NotebookRunConfig(source_directory=\"./\",\n",
    "                        notebook=\"gensen_senteval.ipynb\",\n",
    "                        parameters={},\n",
    "                        run_config=run_config_user_managed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit experiment and wait for completion\n",
    "run = exp.submit(cfg)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Use SentEval\n",
    "To evaluate your sentence embeddings, SentEval requires that you implement two functions:\n",
    "\n",
    "1. **prepare** (sees the whole dataset of each task and can thus construct the word vocabulary, the dictionary of word vectors etc)\n",
    "2. **batcher** (transforms a batch of text sentences into sentence embeddings)\n",
    "\n",
    "### 1.) prepare(params, samples) (optional)\n",
    "\n",
    "*batcher* only sees one batch at a time while the *samples* argument of *prepare* contains all the sentences of a task.\n",
    "\n",
    "```\n",
    "prepare(params, samples)\n",
    "```\n",
    "* *params*: senteval parameters.\n",
    "* *samples*: list of all sentences from the tranfer task.\n",
    "* *output*: No output. Arguments stored in \"params\" can further be used by *batcher*.\n",
    "\n",
    "### 2.) batcher(params, batch)\n",
    "```\n",
    "batcher(params, batch)\n",
    "```\n",
    "* *params*: senteval parameters.\n",
    "* *batch*: numpy array of text sentences (of size params.batch_size)\n",
    "* *output*: numpy array of sentence embeddings (of size params.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(params, samples):\n",
    "    print('Preparing task : %s ' % (params.current_task))\n",
    "    vocab = set()\n",
    "    for sample in samples:\n",
    "        if params.current_task != 'TREC':\n",
    "            sample = ' '.join(sample).lower().split()\n",
    "        else:\n",
    "            sample = ' '.join(sample).split()\n",
    "        for word in sample:\n",
    "            if word not in vocab:\n",
    "                vocab.add(word)\n",
    "\n",
    "    vocab.add('<s>')\n",
    "    vocab.add('<pad>')\n",
    "    vocab.add('<unk>')\n",
    "    vocab.add('</s>')\n",
    "    # If you want to turn off vocab expansion just comment out the below line.\n",
    "    params['gensen'].vocab_expansion(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Batcher function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batcher(local_strategy):\n",
    "    \n",
    "    def batcher(params, batch):\n",
    "        # batch contains list of words\n",
    "        max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\n",
    "        if local_strategy == 'best':\n",
    "            if params.current_task in max_tasks:\n",
    "                strategy = 'max'\n",
    "            else:\n",
    "                strategy = 'last'\n",
    "        else:\n",
    "            strategy = local_strategy\n",
    "\n",
    "        sentences = [' '.join(s).lower() for s in batch]\n",
    "        _, embeddings = params['gensen'].get_representation(\n",
    "            sentences, pool=strategy, return_numpy=True\n",
    "        )\n",
    "        return embeddings\n",
    "    \n",
    "    return batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n",
      "{'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'from __future__ import absolute_import, division, unicode_literals\\n\\nimport sys\\nsys.path.append(\\'.\\')\\nimport torch\\nimport logging\\n\\nimport argparse\\nfrom gensen import GenSen, GenSenSingle\\n\\n# Set SentEval Path.\\nPATH_SENTEVAL = \\'../\\'\\n# Set data path after running bash file to get all the transfer tasks datasets:\\n# https://github.com/facebookresearch/SentEval/blob/master/data/downstream/get_transfer_data.bash\\nPATH_TO_DATA = \\'../data/\\'\\n\\nsys.path.insert(0, PATH_SENTEVAL)\\nimport senteval\\n\\n# set gpu device\\ntorch.cuda.set_device(0)\\n\\nprint(\"System version: {}\".format(sys.version))\\nprint(\"Torch version: {}\".format(torch.__version__))', \"def prepare(params, samples):\\n    print('Preparing task : %s ' % (params.current_task))\\n    vocab = set()\\n    for sample in samples:\\n        if params.current_task != 'TREC':\\n            sample = ' '.join(sample).lower().split()\\n        else:\\n            sample = ' '.join(sample).split()\\n        for word in sample:\\n            if word not in vocab:\\n                vocab.add(word)\\n\\n    vocab.add('<s>')\\n    vocab.add('<pad>')\\n    vocab.add('<unk>')\\n    vocab.add('</s>')\\n    # If you want to turn off vocab expansion just comment out the below line.\\n    params['gensen'].vocab_expansion(vocab)\", \"def batcher(params, batch):\\n    # batch contains list of words\\n    max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\\n    if args.strategy == 'best':\\n        if params.current_task in max_tasks:\\n            strategy = 'max'\\n        else:\\n            strategy = 'last'\\n    else:\\n        strategy = args.strategy\\n\\n    sentences = [' '.join(s).lower() for s in batch]\\n    _, embeddings = params['gensen'].get_representation(\\n        sentences, pool=strategy, return_numpy=True\\n    )\\n    return embeddings\", \"# define transfer tasks\\ntransfer_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'SST5', 'TREC', 'SICKRelatedness',\\\\\\n                  'SICKEntailment', 'MRPC', 'STS14', 'STSBenchmark', 'STS12', 'STS13', 'STS15', 'STS16']\\nparams_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\\nparams_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\\n                                 'tenacity': 5, 'epoch_size': 4}\\n\\n# Set up logger\\nlogging.basicConfig(format='%(asctime)s : %(message)s', level=logging.INFO)\", \"def gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda):\\n    gensen_1 = GenSenSingle(\\n        model_folder=folder_path,\\n        filename_prefix=prefix_1,\\n        pretrained_emb=pretrain,\\n        cuda=cuda\\n    )\\n    gensen_2 = GenSenSingle(\\n        model_folder=folder_path,\\n        filename_prefix=prefix_2,\\n        pretrained_emb=pretrain,\\n        cuda=cuda\\n    )\\n    gensen = GenSen(gensen_1, gensen_2)\\n    params_senteval['gensen'] = gensen\\n    se = senteval.engine.SE(params_senteval, batcher, prepare)\\n    results_transfer = se.eval(transfer_tasks)\\n\\n    print('--------------------------------------------')\\n    print('Table 2 of Our Paper : ')\\n    print('--------------------------------------------')\\n    print('MR                [Dev:%.1f/Test:%.1f]' % (results_transfer['MR']['devacc'], results_transfer['MR']['acc']))\\n    print('CR                [Dev:%.1f/Test:%.1f]' % (results_transfer['CR']['devacc'], results_transfer['CR']['acc']))\\n    print('SUBJ              [Dev:%.1f/Test:%.1f]' % (results_transfer['SUBJ']['devacc'], results_transfer['SUBJ']['acc']))\\n    print('MPQA              [Dev:%.1f/Test:%.1f]' % (results_transfer['MPQA']['devacc'], results_transfer['MPQA']['acc']))\\n    print('SST2              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST2']['devacc'], results_transfer['SST2']['acc']))\\n    print('SST5              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST5']['devacc'], results_transfer['SST5']['acc']))\\n    print('TREC              [Dev:%.1f/Test:%.1f]' % (results_transfer['TREC']['devacc'], results_transfer['TREC']['acc']))\\n    print('MRPC              [Dev:%.1f/TestAcc:%.1f/TestF1:%.1f]' % (results_transfer['MRPC']['devacc'], results_transfer['MRPC']['acc'], results_transfer['MRPC']['f1']))\\n    print('SICKRelatedness   [Dev:%.3f/Test:%.3f]' % (results_transfer['SICKRelatedness']['devpearson'], results_transfer['SICKRelatedness']['pearson']))\\n    print('SICKEntailment    [Dev:%.1f/Test:%.1f]' % (results_transfer['SICKEntailment']['devacc'], results_transfer['SICKEntailment']['acc']))\\n    print('STS12             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS12']['all']['pearson']['mean'], results_transfer['STS12']['all']['spearman']['mean']))\\n    print('STS13             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS13']['all']['pearson']['mean'], results_transfer['STS13']['all']['spearman']['mean']))\\n    print('STS14             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS14']['all']['pearson']['mean'], results_transfer['STS14']['all']['spearman']['mean']))\\n    print('STS15             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS15']['all']['pearson']['mean'], results_transfer['STS15']['all']['spearman']['mean']))\\n    print('STS16             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS16']['all']['pearson']['mean'], results_transfer['STS16']['all']['spearman']['mean']))\\n    print('STSBenchmark      [Dev:%.5f/Pearson:%.5f/Spearman:%.5f]' % (results_transfer['STSBenchmark']['devpearson'], results_transfer['STSBenchmark']['pearson'], results_transfer['STSBenchmark']['spearman']))\\n    print('--------------------------------------------')\", \"# All the parameters by default.\\nfolder_path = './data/models'\\nprefix_1 = 'nli_large_bothskip_parse'\\nprefix_2 = 'nli_large_bothskip'\\npretrain = './data/embedding/glove.840B.300d.h5'\\nstrategy = 'best'\\ncuda = torch.cuda.is_available()\", 'gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda)', \"def get_batcher(strategy):\\n    \\n    def batcher(params, batch):\\n        # batch contains list of words\\n        max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\\n        if strategy == 'best':\\n            if params.current_task in max_tasks:\\n                strategy = 'max'\\n            else:\\n                strategy = 'last'\\n\\n        sentences = [' '.join(s).lower() for s in batch]\\n        _, embeddings = params['gensen'].get_representation(\\n            sentences, pool=strategy, return_numpy=True\\n        )\\n        return embeddings\", \"def gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda):\\n    gensen_1 = GenSenSingle(\\n        model_folder=folder_path,\\n        filename_prefix=prefix_1,\\n        pretrained_emb=pretrain,\\n        cuda=cuda\\n    )\\n    gensen_2 = GenSenSingle(\\n        model_folder=folder_path,\\n        filename_prefix=prefix_2,\\n        pretrained_emb=pretrain,\\n        cuda=cuda\\n    )\\n    gensen = GenSen(gensen_1, gensen_2)\\n    params_senteval['gensen'] = gensen\\n    se = senteval.engine.SE(params_senteval, get_batcher(strategy), prepare)\\n    results_transfer = se.eval(transfer_tasks)\\n\\n    print('--------------------------------------------')\\n    print('Table 2 of Our Paper : ')\\n    print('--------------------------------------------')\\n    print('MR                [Dev:%.1f/Test:%.1f]' % (results_transfer['MR']['devacc'], results_transfer['MR']['acc']))\\n    print('CR                [Dev:%.1f/Test:%.1f]' % (results_transfer['CR']['devacc'], results_transfer['CR']['acc']))\\n    print('SUBJ              [Dev:%.1f/Test:%.1f]' % (results_transfer['SUBJ']['devacc'], results_transfer['SUBJ']['acc']))\\n    print('MPQA              [Dev:%.1f/Test:%.1f]' % (results_transfer['MPQA']['devacc'], results_transfer['MPQA']['acc']))\\n    print('SST2              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST2']['devacc'], results_transfer['SST2']['acc']))\\n    print('SST5              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST5']['devacc'], results_transfer['SST5']['acc']))\\n    print('TREC              [Dev:%.1f/Test:%.1f]' % (results_transfer['TREC']['devacc'], results_transfer['TREC']['acc']))\\n    print('MRPC              [Dev:%.1f/TestAcc:%.1f/TestF1:%.1f]' % (results_transfer['MRPC']['devacc'], results_transfer['MRPC']['acc'], results_transfer['MRPC']['f1']))\\n    print('SICKRelatedness   [Dev:%.3f/Test:%.3f]' % (results_transfer['SICKRelatedness']['devpearson'], results_transfer['SICKRelatedness']['pearson']))\\n    print('SICKEntailment    [Dev:%.1f/Test:%.1f]' % (results_transfer['SICKEntailment']['devacc'], results_transfer['SICKEntailment']['acc']))\\n    print('STS12             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS12']['all']['pearson']['mean'], results_transfer['STS12']['all']['spearman']['mean']))\\n    print('STS13             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS13']['all']['pearson']['mean'], results_transfer['STS13']['all']['spearman']['mean']))\\n    print('STS14             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS14']['all']['pearson']['mean'], results_transfer['STS14']['all']['spearman']['mean']))\\n    print('STS15             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS15']['all']['pearson']['mean'], results_transfer['STS15']['all']['spearman']['mean']))\\n    print('STS16             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS16']['all']['pearson']['mean'], results_transfer['STS16']['all']['spearman']['mean']))\\n    print('STSBenchmark      [Dev:%.5f/Pearson:%.5f/Spearman:%.5f]' % (results_transfer['STSBenchmark']['devpearson'], results_transfer['STSBenchmark']['pearson'], results_transfer['STSBenchmark']['spearman']))\\n    print('--------------------------------------------')\", 'gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda)', \"def get_batcher(strategy):\\n    \\n    def batcher(params, batch):\\n        # batch contains list of words\\n        max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\\n        if strategy == 'best':\\n            if params.current_task in max_tasks:\\n                strategy = 'max'\\n            else:\\n                strategy = 'last'\\n\\n        sentences = [' '.join(s).lower() for s in batch]\\n        _, embeddings = params['gensen'].get_representation(\\n            sentences, pool=strategy, return_numpy=True\\n        )\\n        return embeddings\\n    \\n    return batcher\", 'gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda)', \"def get_batcher(strategy):\\n    \\n    def batcher(params, batch):\\n        # batch contains list of words\\n        max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\\n        if strategy == 'best':\\n            if params.current_task in max_tasks:\\n                strategy = 'max'\\n            else:\\n                strategy = 'last'\\n\\n        sentences = [' '.join(s).lower() for s in batch]\\n        _, embeddings = params['gensen'].get_representation(\\n            sentences, pool=strategy, return_numpy=True\\n        )\\n        return embeddings\\n    \\n    return batcher\", \"get_batcher('best')\", \"get_batcher('best').__code__\", \"dir(get_batcher('best'))\", \"print(dir(get_batcher('best')))\\nget_batcher('best').__closure__\", \"print(dir(get_batcher('best')))\\nprint(get_batcher('best').__closure__)\", \"print(dir(get_batcher('best')))\\nprint(get_batcher('best').__globals__)\"], '_oh': {14: <function get_batcher.<locals>.batcher at 0x0000019FC212B8C8>, 15: <code object batcher at 0x0000019FC7E82DB0, file \"<ipython-input-13-c2436a5a404e>\", line 3>, 16: ['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']}, '_dh': ['C:\\\\Users\\\\lishao\\\\Project\\\\NLP\\\\examples\\\\03-eval\\\\senteval\\\\examples'], 'In': ['', 'from __future__ import absolute_import, division, unicode_literals\\n\\nimport sys\\nsys.path.append(\\'.\\')\\nimport torch\\nimport logging\\n\\nimport argparse\\nfrom gensen import GenSen, GenSenSingle\\n\\n# Set SentEval Path.\\nPATH_SENTEVAL = \\'../\\'\\n# Set data path after running bash file to get all the transfer tasks datasets:\\n# https://github.com/facebookresearch/SentEval/blob/master/data/downstream/get_transfer_data.bash\\nPATH_TO_DATA = \\'../data/\\'\\n\\nsys.path.insert(0, PATH_SENTEVAL)\\nimport senteval\\n\\n# set gpu device\\ntorch.cuda.set_device(0)\\n\\nprint(\"System version: {}\".format(sys.version))\\nprint(\"Torch version: {}\".format(torch.__version__))', \"def prepare(params, samples):\\n    print('Preparing task : %s ' % (params.current_task))\\n    vocab = set()\\n    for sample in samples:\\n        if params.current_task != 'TREC':\\n            sample = ' '.join(sample).lower().split()\\n        else:\\n            sample = ' '.join(sample).split()\\n        for word in sample:\\n            if word not in vocab:\\n                vocab.add(word)\\n\\n    vocab.add('<s>')\\n    vocab.add('<pad>')\\n    vocab.add('<unk>')\\n    vocab.add('</s>')\\n    # If you want to turn off vocab expansion just comment out the below line.\\n    params['gensen'].vocab_expansion(vocab)\", \"def batcher(params, batch):\\n    # batch contains list of words\\n    max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\\n    if args.strategy == 'best':\\n        if params.current_task in max_tasks:\\n            strategy = 'max'\\n        else:\\n            strategy = 'last'\\n    else:\\n        strategy = args.strategy\\n\\n    sentences = [' '.join(s).lower() for s in batch]\\n    _, embeddings = params['gensen'].get_representation(\\n        sentences, pool=strategy, return_numpy=True\\n    )\\n    return embeddings\", \"# define transfer tasks\\ntransfer_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'SST5', 'TREC', 'SICKRelatedness',\\\\\\n                  'SICKEntailment', 'MRPC', 'STS14', 'STSBenchmark', 'STS12', 'STS13', 'STS15', 'STS16']\\nparams_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\\nparams_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\\n                                 'tenacity': 5, 'epoch_size': 4}\\n\\n# Set up logger\\nlogging.basicConfig(format='%(asctime)s : %(message)s', level=logging.INFO)\", \"def gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda):\\n    gensen_1 = GenSenSingle(\\n        model_folder=folder_path,\\n        filename_prefix=prefix_1,\\n        pretrained_emb=pretrain,\\n        cuda=cuda\\n    )\\n    gensen_2 = GenSenSingle(\\n        model_folder=folder_path,\\n        filename_prefix=prefix_2,\\n        pretrained_emb=pretrain,\\n        cuda=cuda\\n    )\\n    gensen = GenSen(gensen_1, gensen_2)\\n    params_senteval['gensen'] = gensen\\n    se = senteval.engine.SE(params_senteval, batcher, prepare)\\n    results_transfer = se.eval(transfer_tasks)\\n\\n    print('--------------------------------------------')\\n    print('Table 2 of Our Paper : ')\\n    print('--------------------------------------------')\\n    print('MR                [Dev:%.1f/Test:%.1f]' % (results_transfer['MR']['devacc'], results_transfer['MR']['acc']))\\n    print('CR                [Dev:%.1f/Test:%.1f]' % (results_transfer['CR']['devacc'], results_transfer['CR']['acc']))\\n    print('SUBJ              [Dev:%.1f/Test:%.1f]' % (results_transfer['SUBJ']['devacc'], results_transfer['SUBJ']['acc']))\\n    print('MPQA              [Dev:%.1f/Test:%.1f]' % (results_transfer['MPQA']['devacc'], results_transfer['MPQA']['acc']))\\n    print('SST2              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST2']['devacc'], results_transfer['SST2']['acc']))\\n    print('SST5              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST5']['devacc'], results_transfer['SST5']['acc']))\\n    print('TREC              [Dev:%.1f/Test:%.1f]' % (results_transfer['TREC']['devacc'], results_transfer['TREC']['acc']))\\n    print('MRPC              [Dev:%.1f/TestAcc:%.1f/TestF1:%.1f]' % (results_transfer['MRPC']['devacc'], results_transfer['MRPC']['acc'], results_transfer['MRPC']['f1']))\\n    print('SICKRelatedness   [Dev:%.3f/Test:%.3f]' % (results_transfer['SICKRelatedness']['devpearson'], results_transfer['SICKRelatedness']['pearson']))\\n    print('SICKEntailment    [Dev:%.1f/Test:%.1f]' % (results_transfer['SICKEntailment']['devacc'], results_transfer['SICKEntailment']['acc']))\\n    print('STS12             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS12']['all']['pearson']['mean'], results_transfer['STS12']['all']['spearman']['mean']))\\n    print('STS13             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS13']['all']['pearson']['mean'], results_transfer['STS13']['all']['spearman']['mean']))\\n    print('STS14             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS14']['all']['pearson']['mean'], results_transfer['STS14']['all']['spearman']['mean']))\\n    print('STS15             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS15']['all']['pearson']['mean'], results_transfer['STS15']['all']['spearman']['mean']))\\n    print('STS16             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS16']['all']['pearson']['mean'], results_transfer['STS16']['all']['spearman']['mean']))\\n    print('STSBenchmark      [Dev:%.5f/Pearson:%.5f/Spearman:%.5f]' % (results_transfer['STSBenchmark']['devpearson'], results_transfer['STSBenchmark']['pearson'], results_transfer['STSBenchmark']['spearman']))\\n    print('--------------------------------------------')\", \"# All the parameters by default.\\nfolder_path = './data/models'\\nprefix_1 = 'nli_large_bothskip_parse'\\nprefix_2 = 'nli_large_bothskip'\\npretrain = './data/embedding/glove.840B.300d.h5'\\nstrategy = 'best'\\ncuda = torch.cuda.is_available()\", 'gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda)', \"def get_batcher(strategy):\\n    \\n    def batcher(params, batch):\\n        # batch contains list of words\\n        max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\\n        if strategy == 'best':\\n            if params.current_task in max_tasks:\\n                strategy = 'max'\\n            else:\\n                strategy = 'last'\\n\\n        sentences = [' '.join(s).lower() for s in batch]\\n        _, embeddings = params['gensen'].get_representation(\\n            sentences, pool=strategy, return_numpy=True\\n        )\\n        return embeddings\", \"def gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda):\\n    gensen_1 = GenSenSingle(\\n        model_folder=folder_path,\\n        filename_prefix=prefix_1,\\n        pretrained_emb=pretrain,\\n        cuda=cuda\\n    )\\n    gensen_2 = GenSenSingle(\\n        model_folder=folder_path,\\n        filename_prefix=prefix_2,\\n        pretrained_emb=pretrain,\\n        cuda=cuda\\n    )\\n    gensen = GenSen(gensen_1, gensen_2)\\n    params_senteval['gensen'] = gensen\\n    se = senteval.engine.SE(params_senteval, get_batcher(strategy), prepare)\\n    results_transfer = se.eval(transfer_tasks)\\n\\n    print('--------------------------------------------')\\n    print('Table 2 of Our Paper : ')\\n    print('--------------------------------------------')\\n    print('MR                [Dev:%.1f/Test:%.1f]' % (results_transfer['MR']['devacc'], results_transfer['MR']['acc']))\\n    print('CR                [Dev:%.1f/Test:%.1f]' % (results_transfer['CR']['devacc'], results_transfer['CR']['acc']))\\n    print('SUBJ              [Dev:%.1f/Test:%.1f]' % (results_transfer['SUBJ']['devacc'], results_transfer['SUBJ']['acc']))\\n    print('MPQA              [Dev:%.1f/Test:%.1f]' % (results_transfer['MPQA']['devacc'], results_transfer['MPQA']['acc']))\\n    print('SST2              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST2']['devacc'], results_transfer['SST2']['acc']))\\n    print('SST5              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST5']['devacc'], results_transfer['SST5']['acc']))\\n    print('TREC              [Dev:%.1f/Test:%.1f]' % (results_transfer['TREC']['devacc'], results_transfer['TREC']['acc']))\\n    print('MRPC              [Dev:%.1f/TestAcc:%.1f/TestF1:%.1f]' % (results_transfer['MRPC']['devacc'], results_transfer['MRPC']['acc'], results_transfer['MRPC']['f1']))\\n    print('SICKRelatedness   [Dev:%.3f/Test:%.3f]' % (results_transfer['SICKRelatedness']['devpearson'], results_transfer['SICKRelatedness']['pearson']))\\n    print('SICKEntailment    [Dev:%.1f/Test:%.1f]' % (results_transfer['SICKEntailment']['devacc'], results_transfer['SICKEntailment']['acc']))\\n    print('STS12             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS12']['all']['pearson']['mean'], results_transfer['STS12']['all']['spearman']['mean']))\\n    print('STS13             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS13']['all']['pearson']['mean'], results_transfer['STS13']['all']['spearman']['mean']))\\n    print('STS14             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS14']['all']['pearson']['mean'], results_transfer['STS14']['all']['spearman']['mean']))\\n    print('STS15             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS15']['all']['pearson']['mean'], results_transfer['STS15']['all']['spearman']['mean']))\\n    print('STS16             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS16']['all']['pearson']['mean'], results_transfer['STS16']['all']['spearman']['mean']))\\n    print('STSBenchmark      [Dev:%.5f/Pearson:%.5f/Spearman:%.5f]' % (results_transfer['STSBenchmark']['devpearson'], results_transfer['STSBenchmark']['pearson'], results_transfer['STSBenchmark']['spearman']))\\n    print('--------------------------------------------')\", 'gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda)', \"def get_batcher(strategy):\\n    \\n    def batcher(params, batch):\\n        # batch contains list of words\\n        max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\\n        if strategy == 'best':\\n            if params.current_task in max_tasks:\\n                strategy = 'max'\\n            else:\\n                strategy = 'last'\\n\\n        sentences = [' '.join(s).lower() for s in batch]\\n        _, embeddings = params['gensen'].get_representation(\\n            sentences, pool=strategy, return_numpy=True\\n        )\\n        return embeddings\\n    \\n    return batcher\", 'gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda)', \"def get_batcher(strategy):\\n    \\n    def batcher(params, batch):\\n        # batch contains list of words\\n        max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\\n        if strategy == 'best':\\n            if params.current_task in max_tasks:\\n                strategy = 'max'\\n            else:\\n                strategy = 'last'\\n\\n        sentences = [' '.join(s).lower() for s in batch]\\n        _, embeddings = params['gensen'].get_representation(\\n            sentences, pool=strategy, return_numpy=True\\n        )\\n        return embeddings\\n    \\n    return batcher\", \"get_batcher('best')\", \"get_batcher('best').__code__\", \"dir(get_batcher('best'))\", \"print(dir(get_batcher('best')))\\nget_batcher('best').__closure__\", \"print(dir(get_batcher('best')))\\nprint(get_batcher('best').__closure__)\", \"print(dir(get_batcher('best')))\\nprint(get_batcher('best').__globals__)\"], 'Out': {14: <function get_batcher.<locals>.batcher at 0x0000019FC212B8C8>, 15: <code object batcher at 0x0000019FC7E82DB0, file \"<ipython-input-13-c2436a5a404e>\", line 3>, 16: ['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x0000019F2A802B38>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x0000019F2A86EA20>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x0000019F2A86EA20>, '_': ['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__'], '__': <code object batcher at 0x0000019FC7E82DB0, file \"<ipython-input-13-c2436a5a404e>\", line 3>, '___': <function get_batcher.<locals>.batcher at 0x0000019FC212B8C8>, '_i': \"print(dir(get_batcher('best')))\\nprint(get_batcher('best').__closure__)\", '_ii': \"print(dir(get_batcher('best')))\\nget_batcher('best').__closure__\", '_iii': \"dir(get_batcher('best'))\", '_i1': 'from __future__ import absolute_import, division, unicode_literals\\n\\nimport sys\\nsys.path.append(\\'.\\')\\nimport torch\\nimport logging\\n\\nimport argparse\\nfrom gensen import GenSen, GenSenSingle\\n\\n# Set SentEval Path.\\nPATH_SENTEVAL = \\'../\\'\\n# Set data path after running bash file to get all the transfer tasks datasets:\\n# https://github.com/facebookresearch/SentEval/blob/master/data/downstream/get_transfer_data.bash\\nPATH_TO_DATA = \\'../data/\\'\\n\\nsys.path.insert(0, PATH_SENTEVAL)\\nimport senteval\\n\\n# set gpu device\\ntorch.cuda.set_device(0)\\n\\nprint(\"System version: {}\".format(sys.version))\\nprint(\"Torch version: {}\".format(torch.__version__))', 'absolute_import': _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0), 16384), 'division': _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192), 'unicode_literals': _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 131072), 'sys': <module 'sys' (built-in)>, 'torch': <module 'torch' from 'C:\\\\Users\\\\lishao\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\onboarding_aml\\\\lib\\\\site-packages\\\\torch\\\\__init__.py'>, 'logging': <module 'logging' from 'C:\\\\Users\\\\lishao\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\onboarding_aml\\\\lib\\\\logging\\\\__init__.py'>, 'argparse': <module 'argparse' from 'C:\\\\Users\\\\lishao\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\onboarding_aml\\\\lib\\\\argparse.py'>, 'GenSen': <class 'gensen.GenSen'>, 'GenSenSingle': <class 'gensen.GenSenSingle'>, 'PATH_SENTEVAL': '../', 'PATH_TO_DATA': '../data/', 'senteval': <module 'senteval' from '..\\\\senteval\\\\__init__.py'>, '_i2': \"def prepare(params, samples):\\n    print('Preparing task : %s ' % (params.current_task))\\n    vocab = set()\\n    for sample in samples:\\n        if params.current_task != 'TREC':\\n            sample = ' '.join(sample).lower().split()\\n        else:\\n            sample = ' '.join(sample).split()\\n        for word in sample:\\n            if word not in vocab:\\n                vocab.add(word)\\n\\n    vocab.add('<s>')\\n    vocab.add('<pad>')\\n    vocab.add('<unk>')\\n    vocab.add('</s>')\\n    # If you want to turn off vocab expansion just comment out the below line.\\n    params['gensen'].vocab_expansion(vocab)\", 'prepare': <function prepare at 0x0000019F2A95AC80>, '_i3': \"def batcher(params, batch):\\n    # batch contains list of words\\n    max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\\n    if args.strategy == 'best':\\n        if params.current_task in max_tasks:\\n            strategy = 'max'\\n        else:\\n            strategy = 'last'\\n    else:\\n        strategy = args.strategy\\n\\n    sentences = [' '.join(s).lower() for s in batch]\\n    _, embeddings = params['gensen'].get_representation(\\n        sentences, pool=strategy, return_numpy=True\\n    )\\n    return embeddings\", 'batcher': <function batcher at 0x0000019F2A95AD08>, '_i4': \"# define transfer tasks\\ntransfer_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'SST5', 'TREC', 'SICKRelatedness',\\\\\\n                  'SICKEntailment', 'MRPC', 'STS14', 'STSBenchmark', 'STS12', 'STS13', 'STS15', 'STS16']\\nparams_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\\nparams_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\\n                                 'tenacity': 5, 'epoch_size': 4}\\n\\n# Set up logger\\nlogging.basicConfig(format='%(asctime)s : %(message)s', level=logging.INFO)\", 'transfer_tasks': ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'SST5', 'TREC', 'SICKRelatedness', 'SICKEntailment', 'MRPC', 'STS14', 'STSBenchmark', 'STS12', 'STS13', 'STS15', 'STS16'], 'params_senteval': {'task_path': '../data/', 'usepytorch': True, 'kfold': 10, 'classifier': {'nhid': 0, 'optim': 'adam', 'batch_size': 64, 'tenacity': 5, 'epoch_size': 4}, 'gensen': GenSen()}, '_i5': \"def gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda):\\n    gensen_1 = GenSenSingle(\\n        model_folder=folder_path,\\n        filename_prefix=prefix_1,\\n        pretrained_emb=pretrain,\\n        cuda=cuda\\n    )\\n    gensen_2 = GenSenSingle(\\n        model_folder=folder_path,\\n        filename_prefix=prefix_2,\\n        pretrained_emb=pretrain,\\n        cuda=cuda\\n    )\\n    gensen = GenSen(gensen_1, gensen_2)\\n    params_senteval['gensen'] = gensen\\n    se = senteval.engine.SE(params_senteval, batcher, prepare)\\n    results_transfer = se.eval(transfer_tasks)\\n\\n    print('--------------------------------------------')\\n    print('Table 2 of Our Paper : ')\\n    print('--------------------------------------------')\\n    print('MR                [Dev:%.1f/Test:%.1f]' % (results_transfer['MR']['devacc'], results_transfer['MR']['acc']))\\n    print('CR                [Dev:%.1f/Test:%.1f]' % (results_transfer['CR']['devacc'], results_transfer['CR']['acc']))\\n    print('SUBJ              [Dev:%.1f/Test:%.1f]' % (results_transfer['SUBJ']['devacc'], results_transfer['SUBJ']['acc']))\\n    print('MPQA              [Dev:%.1f/Test:%.1f]' % (results_transfer['MPQA']['devacc'], results_transfer['MPQA']['acc']))\\n    print('SST2              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST2']['devacc'], results_transfer['SST2']['acc']))\\n    print('SST5              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST5']['devacc'], results_transfer['SST5']['acc']))\\n    print('TREC              [Dev:%.1f/Test:%.1f]' % (results_transfer['TREC']['devacc'], results_transfer['TREC']['acc']))\\n    print('MRPC              [Dev:%.1f/TestAcc:%.1f/TestF1:%.1f]' % (results_transfer['MRPC']['devacc'], results_transfer['MRPC']['acc'], results_transfer['MRPC']['f1']))\\n    print('SICKRelatedness   [Dev:%.3f/Test:%.3f]' % (results_transfer['SICKRelatedness']['devpearson'], results_transfer['SICKRelatedness']['pearson']))\\n    print('SICKEntailment    [Dev:%.1f/Test:%.1f]' % (results_transfer['SICKEntailment']['devacc'], results_transfer['SICKEntailment']['acc']))\\n    print('STS12             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS12']['all']['pearson']['mean'], results_transfer['STS12']['all']['spearman']['mean']))\\n    print('STS13             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS13']['all']['pearson']['mean'], results_transfer['STS13']['all']['spearman']['mean']))\\n    print('STS14             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS14']['all']['pearson']['mean'], results_transfer['STS14']['all']['spearman']['mean']))\\n    print('STS15             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS15']['all']['pearson']['mean'], results_transfer['STS15']['all']['spearman']['mean']))\\n    print('STS16             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS16']['all']['pearson']['mean'], results_transfer['STS16']['all']['spearman']['mean']))\\n    print('STSBenchmark      [Dev:%.5f/Pearson:%.5f/Spearman:%.5f]' % (results_transfer['STSBenchmark']['devpearson'], results_transfer['STSBenchmark']['pearson'], results_transfer['STSBenchmark']['spearman']))\\n    print('--------------------------------------------')\", 'gensen_eval': <function gensen_eval at 0x0000019FC211A730>, '_i6': \"# All the parameters by default.\\nfolder_path = './data/models'\\nprefix_1 = 'nli_large_bothskip_parse'\\nprefix_2 = 'nli_large_bothskip'\\npretrain = './data/embedding/glove.840B.300d.h5'\\nstrategy = 'best'\\ncuda = torch.cuda.is_available()\", 'folder_path': './data/models', 'prefix_1': 'nli_large_bothskip_parse', 'prefix_2': 'nli_large_bothskip', 'pretrain': './data/embedding/glove.840B.300d.h5', 'strategy': 'best', 'cuda': True, '_i7': 'gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda)', '_i8': \"def get_batcher(strategy):\\n    \\n    def batcher(params, batch):\\n        # batch contains list of words\\n        max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\\n        if strategy == 'best':\\n            if params.current_task in max_tasks:\\n                strategy = 'max'\\n            else:\\n                strategy = 'last'\\n\\n        sentences = [' '.join(s).lower() for s in batch]\\n        _, embeddings = params['gensen'].get_representation(\\n            sentences, pool=strategy, return_numpy=True\\n        )\\n        return embeddings\", 'get_batcher': <function get_batcher at 0x000001A142F90840>, '_i9': \"def gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda):\\n    gensen_1 = GenSenSingle(\\n        model_folder=folder_path,\\n        filename_prefix=prefix_1,\\n        pretrained_emb=pretrain,\\n        cuda=cuda\\n    )\\n    gensen_2 = GenSenSingle(\\n        model_folder=folder_path,\\n        filename_prefix=prefix_2,\\n        pretrained_emb=pretrain,\\n        cuda=cuda\\n    )\\n    gensen = GenSen(gensen_1, gensen_2)\\n    params_senteval['gensen'] = gensen\\n    se = senteval.engine.SE(params_senteval, get_batcher(strategy), prepare)\\n    results_transfer = se.eval(transfer_tasks)\\n\\n    print('--------------------------------------------')\\n    print('Table 2 of Our Paper : ')\\n    print('--------------------------------------------')\\n    print('MR                [Dev:%.1f/Test:%.1f]' % (results_transfer['MR']['devacc'], results_transfer['MR']['acc']))\\n    print('CR                [Dev:%.1f/Test:%.1f]' % (results_transfer['CR']['devacc'], results_transfer['CR']['acc']))\\n    print('SUBJ              [Dev:%.1f/Test:%.1f]' % (results_transfer['SUBJ']['devacc'], results_transfer['SUBJ']['acc']))\\n    print('MPQA              [Dev:%.1f/Test:%.1f]' % (results_transfer['MPQA']['devacc'], results_transfer['MPQA']['acc']))\\n    print('SST2              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST2']['devacc'], results_transfer['SST2']['acc']))\\n    print('SST5              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST5']['devacc'], results_transfer['SST5']['acc']))\\n    print('TREC              [Dev:%.1f/Test:%.1f]' % (results_transfer['TREC']['devacc'], results_transfer['TREC']['acc']))\\n    print('MRPC              [Dev:%.1f/TestAcc:%.1f/TestF1:%.1f]' % (results_transfer['MRPC']['devacc'], results_transfer['MRPC']['acc'], results_transfer['MRPC']['f1']))\\n    print('SICKRelatedness   [Dev:%.3f/Test:%.3f]' % (results_transfer['SICKRelatedness']['devpearson'], results_transfer['SICKRelatedness']['pearson']))\\n    print('SICKEntailment    [Dev:%.1f/Test:%.1f]' % (results_transfer['SICKEntailment']['devacc'], results_transfer['SICKEntailment']['acc']))\\n    print('STS12             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS12']['all']['pearson']['mean'], results_transfer['STS12']['all']['spearman']['mean']))\\n    print('STS13             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS13']['all']['pearson']['mean'], results_transfer['STS13']['all']['spearman']['mean']))\\n    print('STS14             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS14']['all']['pearson']['mean'], results_transfer['STS14']['all']['spearman']['mean']))\\n    print('STS15             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS15']['all']['pearson']['mean'], results_transfer['STS15']['all']['spearman']['mean']))\\n    print('STS16             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS16']['all']['pearson']['mean'], results_transfer['STS16']['all']['spearman']['mean']))\\n    print('STSBenchmark      [Dev:%.5f/Pearson:%.5f/Spearman:%.5f]' % (results_transfer['STSBenchmark']['devpearson'], results_transfer['STSBenchmark']['pearson'], results_transfer['STSBenchmark']['spearman']))\\n    print('--------------------------------------------')\", '_i10': 'gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda)', '_i11': \"def get_batcher(strategy):\\n    \\n    def batcher(params, batch):\\n        # batch contains list of words\\n        max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\\n        if strategy == 'best':\\n            if params.current_task in max_tasks:\\n                strategy = 'max'\\n            else:\\n                strategy = 'last'\\n\\n        sentences = [' '.join(s).lower() for s in batch]\\n        _, embeddings = params['gensen'].get_representation(\\n            sentences, pool=strategy, return_numpy=True\\n        )\\n        return embeddings\\n    \\n    return batcher\", '_i12': 'gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda)', '_i13': \"def get_batcher(strategy):\\n    \\n    def batcher(params, batch):\\n        # batch contains list of words\\n        max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\\n        if strategy == 'best':\\n            if params.current_task in max_tasks:\\n                strategy = 'max'\\n            else:\\n                strategy = 'last'\\n\\n        sentences = [' '.join(s).lower() for s in batch]\\n        _, embeddings = params['gensen'].get_representation(\\n            sentences, pool=strategy, return_numpy=True\\n        )\\n        return embeddings\\n    \\n    return batcher\", '_i14': \"get_batcher('best')\", '_14': <function get_batcher.<locals>.batcher at 0x0000019FC212B8C8>, '_i15': \"get_batcher('best').__code__\", '_15': <code object batcher at 0x0000019FC7E82DB0, file \"<ipython-input-13-c2436a5a404e>\", line 3>, '_i16': \"dir(get_batcher('best'))\", '_16': ['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__'], '_i17': \"print(dir(get_batcher('best')))\\nget_batcher('best').__closure__\", '_i18': \"print(dir(get_batcher('best')))\\nprint(get_batcher('best').__closure__)\", '_i19': \"print(dir(get_batcher('best')))\\nprint(get_batcher('best').__globals__)\"}\n"
     ]
    }
   ],
   "source": [
    "print(dir(get_batcher('best')))\n",
    "print(get_batcher('best').__globals__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Evaluation of GenSen trained model on Transfter Tasks (SentEval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Parameters for SentEval\n",
    "\n",
    "The current list of available tasks is:\n",
    "```python\n",
    "['CR', 'MR', 'MPQA', 'SUBJ', 'SST2', 'SST5', 'TREC', 'MRPC', 'SNLI',\n",
    "'SICKEntailment', 'SICKRelatedness', 'STSBenchmark', 'ImageCaptionRetrieval',\n",
    "'STS12', 'STS13', 'STS14', 'STS15', 'STS16',\n",
    "'Length', 'WordContent', 'Depth', 'TopConstituents','BigramShift', 'Tense',\n",
    "'SubjNumber', 'ObjNumber', 'OddManOut', 'CoordinationInversion']\n",
    "```\n",
    "Users can chose the subset of above tasks.\n",
    "\n",
    "1) to perform the actual evaluation, first import senteval and set its parameters:\n",
    "```python\n",
    "import senteval\n",
    "params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "```\n",
    "\n",
    "2) (optional) set the parameters of the classifier (when applicable):\n",
    "```python\n",
    "params['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\n",
    "                                 'tenacity': 5, 'epoch_size': 4}\n",
    "```\n",
    "You can choose **nhid=0** (Logistic Regression) or **nhid>0** (MLP) and define the parameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transfer tasks\n",
    "transfer_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'SST5', 'TREC', 'SICKRelatedness',\\\n",
    "                  'SICKEntailment', 'MRPC', 'STS14', 'STSBenchmark', 'STS12', 'STS13', 'STS15', 'STS16']\n",
    "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "params_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\n",
    "                                 'tenacity': 5, 'epoch_size': 4}\n",
    "\n",
    "# Set up logger\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create an instance of the class SE:\n",
    "\n",
    "```python\n",
    "se = senteval.engine.SE(params, batcher, prepare)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the parameters by default.\n",
    "folder_path = './data/models'\n",
    "prefix_1 = 'nli_large_bothskip_parse'\n",
    "prefix_2 = 'nli_large_bothskip'\n",
    "pretrain = './data/embedding/glove.840B.300d.h5'\n",
    "strategy = 'best'\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda, strategy):\n",
    "    gensen_1 = GenSenSingle(\n",
    "        model_folder=folder_path,\n",
    "        filename_prefix=prefix_1,\n",
    "        pretrained_emb=pretrain,\n",
    "        cuda=cuda\n",
    "    )\n",
    "    gensen_2 = GenSenSingle(\n",
    "        model_folder=folder_path,\n",
    "        filename_prefix=prefix_2,\n",
    "        pretrained_emb=pretrain,\n",
    "        cuda=cuda\n",
    "    )\n",
    "    gensen = GenSen(gensen_1, gensen_2)\n",
    "    params_senteval['gensen'] = gensen\n",
    "    se = senteval.engine.SE(params_senteval, get_batcher(strategy), prepare)\n",
    "    results_transfer = se.eval(transfer_tasks)\n",
    "\n",
    "    print('--------------------------------------------')\n",
    "    print('Table 2 of Our Paper : ')\n",
    "    print('--------------------------------------------')\n",
    "    print('MR                [Dev:%.1f/Test:%.1f]' % (results_transfer['MR']['devacc'], results_transfer['MR']['acc']))\n",
    "    print('CR                [Dev:%.1f/Test:%.1f]' % (results_transfer['CR']['devacc'], results_transfer['CR']['acc']))\n",
    "    print('SUBJ              [Dev:%.1f/Test:%.1f]' % (results_transfer['SUBJ']['devacc'], results_transfer['SUBJ']['acc']))\n",
    "    print('MPQA              [Dev:%.1f/Test:%.1f]' % (results_transfer['MPQA']['devacc'], results_transfer['MPQA']['acc']))\n",
    "    print('SST2              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST2']['devacc'], results_transfer['SST2']['acc']))\n",
    "    print('SST5              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST5']['devacc'], results_transfer['SST5']['acc']))\n",
    "    print('TREC              [Dev:%.1f/Test:%.1f]' % (results_transfer['TREC']['devacc'], results_transfer['TREC']['acc']))\n",
    "    print('MRPC              [Dev:%.1f/TestAcc:%.1f/TestF1:%.1f]' % (results_transfer['MRPC']['devacc'], results_transfer['MRPC']['acc'], results_transfer['MRPC']['f1']))\n",
    "    print('SICKRelatedness   [Dev:%.3f/Test:%.3f]' % (results_transfer['SICKRelatedness']['devpearson'], results_transfer['SICKRelatedness']['pearson']))\n",
    "    print('SICKEntailment    [Dev:%.1f/Test:%.1f]' % (results_transfer['SICKEntailment']['devacc'], results_transfer['SICKEntailment']['acc']))\n",
    "    print('STS12             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS12']['all']['pearson']['mean'], results_transfer['STS12']['all']['spearman']['mean']))\n",
    "    print('STS13             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS13']['all']['pearson']['mean'], results_transfer['STS13']['all']['spearman']['mean']))\n",
    "    print('STS14             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS14']['all']['pearson']['mean'], results_transfer['STS14']['all']['spearman']['mean']))\n",
    "    print('STS15             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS15']['all']['pearson']['mean'], results_transfer['STS15']['all']['spearman']['mean']))\n",
    "    print('STS16             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS16']['all']['pearson']['mean'], results_transfer['STS16']['all']['spearman']['mean']))\n",
    "    print('STSBenchmark      [Dev:%.5f/Pearson:%.5f/Spearman:%.5f]' % (results_transfer['STSBenchmark']['devpearson'], results_transfer['STSBenchmark']['pearson'], results_transfer['STSBenchmark']['spearman']))\n",
    "    print('--------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Results from SentEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing task : MR \n",
      "Loading pretrained word embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lishao\\AppData\\Local\\Continuum\\miniconda3\\envs\\onboarding_aml\\lib\\site-packages\\h5py\\_hl\\dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training vocab expansion on model\n",
      "Found 5292 task OOVs \n",
      "Found 1781 pretrain OOVs \n",
      "\n",
      "                Warning pretrained embedding shape mismatch 20328 x 512\n",
      "                expected 80004 x 512\n",
      "Loading pretrained word embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lishao\\AppData\\Local\\Continuum\\miniconda3\\envs\\onboarding_aml\\lib\\site-packages\\h5py\\_hl\\dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training vocab expansion on model\n",
      "Found 5292 task OOVs \n",
      "Found 1781 pretrain OOVs \n",
      "\n",
      "                Warning pretrained embedding shape mismatch 20328 x 512\n",
      "                expected 80004 x 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-29 16:51:18,172 : Generating sentence embeddings\n",
      "C:\\Users\\lishao\\Project\\NLP\\examples\\03-eval\\senteval\\examples\\gensen.py:303: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  sentences = Variable(torch.LongTensor(sentences), volatile=True)\n",
      "C:\\Users\\lishao\\Project\\NLP\\examples\\03-eval\\senteval\\examples\\gensen.py:304: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  rev = Variable(torch.LongTensor(rev), volatile=True)\n",
      "2019-04-29 16:51:57,127 : Generated sentence embeddings\n",
      "2019-04-29 16:51:57,130 : Training pytorch-MLP-nhid0-adam-bs64 with (inner) 10-fold cross-validation\n",
      "2019-04-29 17:00:04,531 : Best param found at split 1: l2reg = 0.0001                 with score 83.23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-02cde44201ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgensen_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-3edd94340359>\u001b[0m in \u001b[0;36mgensen_eval\u001b[1;34m(folder_path, prefix_1, prefix_2, pretrain, cuda, strategy)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mparams_senteval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gensen'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msenteval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_senteval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_batcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprepare\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mresults_transfer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransfer_tasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'--------------------------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\engine.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# evaluate on evaluation [name], either takes string or list of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\engine.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# evaluate on evaluation [name], either takes string or list of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\engine.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatcher\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\binary.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, params, batcher)\u001b[0m\n\u001b[0;32m     55\u001b[0m                   'nhid': params.nhid, 'kfold': params.kfold}\n\u001b[0;32m     56\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInnerKFoldClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mdevacc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestacc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dev acc : {0} Test acc : {1}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevacc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestacc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         return {'devacc': devacc, 'acc': testacc, 'ndev': self.n_samples,\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\tools\\validation.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m                                   seed=self.seed)\n\u001b[0;32m     81\u001b[0m                         clf.fit(X_in_train, y_in_train,\n\u001b[1;32m---> 82\u001b[1;33m                                 validation_data=(X_in_test, y_in_test))\n\u001b[0m\u001b[0;32m     83\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\tools\\classifier.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, validation_data, validation_split, early_stop)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;31m# Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstop_train\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnepoch\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainepoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbestaccuracy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\tools\\classifier.py\u001b[0m in \u001b[0;36mtrainepoch\u001b[1;34m(self, X, y, epoch_size)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;31m# forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                 \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[0mXbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda, strategy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [1] A. Conneau, D. Kiela, [*SentEval: An Evaluation Toolkit for Universal Sentence Representations*](https://arxiv.org/abs/1803.05449)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
