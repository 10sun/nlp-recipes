{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on GenSen model by SentEval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentEval is the evaluation toolkit for sentence embeddings. SentEval is a library for evaluating the quality of sentence embeddings. It is used to assess their generalization power by using them as features on a broad and diverse set of \"transfer\" tasks. SentEval currently includes 17 downstream tasks.\n",
    "\n",
    "This notebook will show you how to run SentEval and evaluate trained GenSen model locally. We used the [SentEval](https://github.com/facebookresearch/SentEval) toolkit to run most of our transfer learning experiments. To replicate these numbers, clone their repository and follow setup instructions. Once complete, copy this notebook and `gensen.py` into their examples folder and run the following commands to reproduce different rows in Table 2 of our paper. Note: Please set the path to the pretrained glove embeddings (`glove.840B.300d.h5`) and model folder as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the functions used in the notebook can be found in the `gensen.py` file. Set the `PATH_SENTEVAL` as SentEval Data path and `PATH_TO_DATA` as model data path, which you should put your trained model here: pre-trained models under `embedding/` and trained models under `models/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]\n",
      "Torch version: 1.0.1\n",
      "Senteval data path: ../\n",
      "Trained model path: ../data/\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, unicode_literals\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from gensen import GenSen, GenSenSingle\n",
    "\n",
    "# Set SentEval Data Path.\n",
    "# Set data path after running bash file to get all the transfer tasks datasets:\n",
    "# https://github.com/facebookresearch/SentEval/blob/master/data/downstream/get_transfer_data.bash\n",
    "PATH_SENTEVAL = '../'\n",
    "# Path to model data.\n",
    "PATH_TO_DATA = '../data/'\n",
    "\n",
    "# Set the senteval code folder.\n",
    "sys.path.insert(0, '../')\n",
    "import senteval\n",
    "\n",
    "# set gpu device\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Torch version: {}\".format(torch.__version__))\n",
    "print(\"Senteval data path: {}\".format(PATH_SENTEVAL))\n",
    "print(\"Trained model path: {}\".format(PATH_TO_DATA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Use SentEval\n",
    "To evaluate your sentence embeddings, SentEval requires that you implement two functions:\n",
    "\n",
    "1. **prepare** (sees the whole dataset of each task and can thus construct the word vocabulary, the dictionary of word vectors etc)\n",
    "2. **batcher** (transforms a batch of text sentences into sentence embeddings)\n",
    "\n",
    "### 1.) prepare(params, samples) (optional)\n",
    "\n",
    "*batcher* only sees one batch at a time while the *samples* argument of *prepare* contains all the sentences of a task.\n",
    "\n",
    "```\n",
    "prepare(params, samples)\n",
    "```\n",
    "* *params*: senteval parameters.\n",
    "* *samples*: list of all sentences from the tranfer task.\n",
    "* *output*: No output. Arguments stored in \"params\" can further be used by *batcher*.\n",
    "\n",
    "### 2.) batcher(params, batch)\n",
    "```\n",
    "batcher(params, batch)\n",
    "```\n",
    "* *params*: senteval parameters.\n",
    "* *batch*: numpy array of text sentences (of size params.batch_size)\n",
    "* *output*: numpy array of sentence embeddings (of size params.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(params, samples):\n",
    "    print('Preparing task : %s ' % (params.current_task))\n",
    "    vocab = set()\n",
    "    for sample in samples:\n",
    "        if params.current_task != 'TREC':\n",
    "            sample = ' '.join(sample).lower().split()\n",
    "        else:\n",
    "            sample = ' '.join(sample).split()\n",
    "        for word in sample:\n",
    "            if word not in vocab:\n",
    "                vocab.add(word)\n",
    "\n",
    "    vocab.add('<s>')\n",
    "    vocab.add('<pad>')\n",
    "    vocab.add('<unk>')\n",
    "    vocab.add('</s>')\n",
    "    # If you want to turn off vocab expansion just comment out the below line.\n",
    "    params['gensen'].vocab_expansion(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Batcher function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batcher(local_strategy):\n",
    "    \n",
    "    def batcher(params, batch):\n",
    "        # batch contains list of words\n",
    "        max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\n",
    "        if local_strategy == 'best':\n",
    "            if params.current_task in max_tasks:\n",
    "                strategy = 'max'\n",
    "            else:\n",
    "                strategy = 'last'\n",
    "        else:\n",
    "            strategy = local_strategy\n",
    "\n",
    "        sentences = [' '.join(s).lower() for s in batch]\n",
    "        _, embeddings = params['gensen'].get_representation(\n",
    "            sentences, pool=strategy, return_numpy=True\n",
    "        )\n",
    "        return embeddings\n",
    "    \n",
    "    return batcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Evaluation of GenSen trained model on Transfter Tasks (SentEval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Parameters for SentEval\n",
    "\n",
    "The current list of available tasks is:\n",
    "```python\n",
    "['CR', 'MR', 'MPQA', 'SUBJ', 'SST2', 'SST5', 'TREC', 'MRPC', 'SNLI',\n",
    "'SICKEntailment', 'SICKRelatedness', 'STSBenchmark', 'ImageCaptionRetrieval',\n",
    "'STS12', 'STS13', 'STS14', 'STS15', 'STS16',\n",
    "'Length', 'WordContent', 'Depth', 'TopConstituents','BigramShift', 'Tense',\n",
    "'SubjNumber', 'ObjNumber', 'OddManOut', 'CoordinationInversion']\n",
    "```\n",
    "Users can chose the subset of above tasks.\n",
    "\n",
    "1) to perform the actual evaluation, first import senteval and set its parameters:\n",
    "```python\n",
    "import senteval\n",
    "params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "```\n",
    "\n",
    "2) (optional) set the parameters of the classifier (when applicable):\n",
    "```python\n",
    "params['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\n",
    "                                 'tenacity': 5, 'epoch_size': 4}\n",
    "```\n",
    "You can choose **nhid=0** (Logistic Regression) or **nhid>0** (MLP) and define the parameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transfer tasks\n",
    "transfer_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'SST5', 'TREC', 'SICKRelatedness',\\\n",
    "                  'SICKEntailment', 'MRPC', 'STS14', 'STSBenchmark', 'STS12', 'STS13', 'STS15', 'STS16']\n",
    "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "params_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\n",
    "                                 'tenacity': 5, 'epoch_size': 4}\n",
    "\n",
    "# Set up logger\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create an instance of the class SE:\n",
    "\n",
    "```python\n",
    "se = senteval.engine.SE(params, batcher, prepare)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the parameters by default.\n",
    "folder_path = './data/models'\n",
    "prefix_1 = 'nli_large_bothskip_parse'\n",
    "prefix_2 = 'nli_large_bothskip'\n",
    "pretrain = './data/embedding/glove.840B.300d.h5'\n",
    "strategy = 'best'\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda, strategy):\n",
    "    gensen_1 = GenSenSingle(\n",
    "        model_folder=folder_path,\n",
    "        filename_prefix=prefix_1,\n",
    "        pretrained_emb=pretrain,\n",
    "        cuda=cuda\n",
    "    )\n",
    "    gensen_2 = GenSenSingle(\n",
    "        model_folder=folder_path,\n",
    "        filename_prefix=prefix_2,\n",
    "        pretrained_emb=pretrain,\n",
    "        cuda=cuda\n",
    "    )\n",
    "    gensen = GenSen(gensen_1, gensen_2)\n",
    "    params_senteval['gensen'] = gensen\n",
    "    se = senteval.engine.SE(params_senteval, get_batcher(strategy), prepare)\n",
    "    results_transfer = se.eval(transfer_tasks)\n",
    "\n",
    "    print('--------------------------------------------')\n",
    "    print('Table 2 of Our Paper : ')\n",
    "    print('--------------------------------------------')\n",
    "    print('MR                [Dev:%.1f/Test:%.1f]' % (results_transfer['MR']['devacc'], results_transfer['MR']['acc']))\n",
    "    print('CR                [Dev:%.1f/Test:%.1f]' % (results_transfer['CR']['devacc'], results_transfer['CR']['acc']))\n",
    "    print('SUBJ              [Dev:%.1f/Test:%.1f]' % (results_transfer['SUBJ']['devacc'], results_transfer['SUBJ']['acc']))\n",
    "    print('MPQA              [Dev:%.1f/Test:%.1f]' % (results_transfer['MPQA']['devacc'], results_transfer['MPQA']['acc']))\n",
    "    print('SST2              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST2']['devacc'], results_transfer['SST2']['acc']))\n",
    "    print('SST5              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST5']['devacc'], results_transfer['SST5']['acc']))\n",
    "    print('TREC              [Dev:%.1f/Test:%.1f]' % (results_transfer['TREC']['devacc'], results_transfer['TREC']['acc']))\n",
    "    print('MRPC              [Dev:%.1f/TestAcc:%.1f/TestF1:%.1f]' % (results_transfer['MRPC']['devacc'], results_transfer['MRPC']['acc'], results_transfer['MRPC']['f1']))\n",
    "    print('SICKRelatedness   [Dev:%.3f/Test:%.3f]' % (results_transfer['SICKRelatedness']['devpearson'], results_transfer['SICKRelatedness']['pearson']))\n",
    "    print('SICKEntailment    [Dev:%.1f/Test:%.1f]' % (results_transfer['SICKEntailment']['devacc'], results_transfer['SICKEntailment']['acc']))\n",
    "    print('STS12             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS12']['all']['pearson']['mean'], results_transfer['STS12']['all']['spearman']['mean']))\n",
    "    print('STS13             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS13']['all']['pearson']['mean'], results_transfer['STS13']['all']['spearman']['mean']))\n",
    "    print('STS14             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS14']['all']['pearson']['mean'], results_transfer['STS14']['all']['spearman']['mean']))\n",
    "    print('STS15             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS15']['all']['pearson']['mean'], results_transfer['STS15']['all']['spearman']['mean']))\n",
    "    print('STS16             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS16']['all']['pearson']['mean'], results_transfer['STS16']['all']['spearman']['mean']))\n",
    "    print('STSBenchmark      [Dev:%.5f/Pearson:%.5f/Spearman:%.5f]' % (results_transfer['STSBenchmark']['devpearson'], results_transfer['STSBenchmark']['pearson'], results_transfer['STSBenchmark']['spearman']))\n",
    "    print('--------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Results from SentEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing task : MR \n",
      "Loading pretrained word embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lishao\\AppData\\Local\\Continuum\\miniconda3\\envs\\onboarding_aml\\lib\\site-packages\\h5py\\_hl\\dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training vocab expansion on model\n",
      "Found 5292 task OOVs \n",
      "Found 1781 pretrain OOVs \n",
      "\n",
      "                Warning pretrained embedding shape mismatch 20328 x 512\n",
      "                expected 80004 x 512\n",
      "Loading pretrained word embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lishao\\AppData\\Local\\Continuum\\miniconda3\\envs\\onboarding_aml\\lib\\site-packages\\h5py\\_hl\\dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training vocab expansion on model\n",
      "Found 5292 task OOVs \n",
      "Found 1781 pretrain OOVs \n",
      "\n",
      "                Warning pretrained embedding shape mismatch 20328 x 512\n",
      "                expected 80004 x 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-01 13:00:55,808 : Generating sentence embeddings\n",
      "C:\\Users\\lishao\\Project\\NLP\\examples\\03-eval\\senteval\\examples\\gensen.py:303: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  sentences = Variable(torch.LongTensor(sentences), volatile=True)\n",
      "C:\\Users\\lishao\\Project\\NLP\\examples\\03-eval\\senteval\\examples\\gensen.py:304: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  rev = Variable(torch.LongTensor(rev), volatile=True)\n",
      "2019-05-01 13:01:34,831 : Generated sentence embeddings\n",
      "2019-05-01 13:01:34,843 : Training pytorch-MLP-nhid0-adam-bs64 with (inner) 10-fold cross-validation\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-6bde2cf817a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgensen_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-3edd94340359>\u001b[0m in \u001b[0;36mgensen_eval\u001b[1;34m(folder_path, prefix_1, prefix_2, pretrain, cuda, strategy)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mparams_senteval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gensen'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msenteval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_senteval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_batcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprepare\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mresults_transfer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransfer_tasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'--------------------------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\engine.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# evaluate on evaluation [name], either takes string or list of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\engine.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# evaluate on evaluation [name], either takes string or list of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\engine.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatcher\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\binary.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, params, batcher)\u001b[0m\n\u001b[0;32m     55\u001b[0m                   'nhid': params.nhid, 'kfold': params.kfold}\n\u001b[0;32m     56\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInnerKFoldClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mdevacc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestacc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dev acc : {0} Test acc : {1}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevacc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestacc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         return {'devacc': devacc, 'acc': testacc, 'ndev': self.n_samples,\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\tools\\validation.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m                                   seed=self.seed)\n\u001b[0;32m     81\u001b[0m                         clf.fit(X_in_train, y_in_train,\n\u001b[1;32m---> 82\u001b[1;33m                                 validation_data=(X_in_test, y_in_test))\n\u001b[0m\u001b[0;32m     83\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\tools\\classifier.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, validation_data, validation_split, early_stop)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;31m# Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstop_train\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnepoch\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainepoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbestaccuracy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\tools\\classifier.py\u001b[0m in \u001b[0;36mtrainepoch\u001b[1;34m(self, X, y, epoch_size)\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[1;31m# backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m                 \u001b[1;31m# Update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\onboarding_aml\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\onboarding_aml\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda, strategy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [1] A. Conneau, D. Kiela, [*SentEval: An Evaluation Toolkit for Universal Sentence Representations*](https://arxiv.org/abs/1803.05449)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
