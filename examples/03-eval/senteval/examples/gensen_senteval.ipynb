{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on GenSen model by SentEval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentEval is the evaluation toolkit for sentence embeddings. SentEval is a library for evaluating the quality of sentence embeddings. It is used to assess their generalization power by using them as features on a broad and diverse set of \"transfer\" tasks. SentEval currently includes 17 downstream tasks.\n",
    "\n",
    "This notebook will show you how to run SentEval and evaluate trained GenSen model locally. We used the [SentEval](https://github.com/facebookresearch/SentEval) toolkit to run most of our transfer learning experiments. To replicate these numbers, clone their repository and follow setup instructions. Once complete, copy this notebook and `gensen.py` into their examples folder and run the following commands to reproduce different rows in Table 2 of our paper. Note: Please set the path to the pretrained glove embeddings (`glove.840B.300d.h5`) and model folder as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the functions used in the notebook can be found in the `gensen.py` file. Set the `PATH_SENTEVAL` as SentEval Data path and `PATH_TO_DATA` as model data path, which you should put your trained model here: pre-trained models under `embedding/` and trained models under `models/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize workspace\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: MAIDAPNLP\n",
      "Azure region: eastus2\n",
      "Subscription id: 15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\n",
      "Resource group: nlprg\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access to Datastore\n",
    "\n",
    "We can access and upload senteval data and models to datastore blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_gensen"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "ds = Datastore.register_azure_file_share(workspace=ws,\n",
    "                                        datastore_name= 'GenSen',\n",
    "                                        file_share_name='azureml-filestore-09b72610-7938-4ed2-86a2-5004896b12d9',\n",
    "                                        account_name='maidapnlp0056795534',\n",
    "                                        account_key='8LtGFZErNlvI6fSrgODqCxJCckkVgq3AL/5S/8ma7Re7xUHgWrNRCfTFnP/QDhF7KDY6ScAORsUpSm7ziog5/Q==')\n",
    "\n",
    "ds.as_mount()\n",
    "# Upload files from local.\n",
    "# ds.upload(src_dir='data', target_path='data', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]\n",
      "Torch version: 1.0.1\n",
      "Senteval data path: $AZUREML_DATAREFERENCE_252b942da6a34c2cb9b0982ec4fbade7\n",
      "Trained model path: $AZUREML_DATAREFERENCE_cefa1446b5e34ae79832eb6a65846b5b\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, unicode_literals\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from gensen import GenSen, GenSenSingle\n",
    "\n",
    "# Set SentEval Data Path.\n",
    "# Set data path after running bash file to get all the transfer tasks datasets:\n",
    "# https://github.com/facebookresearch/SentEval/blob/master/data/downstream/get_transfer_data.bash\n",
    "#PATH_SENTEVAL = os.path.join(os.environ['AZUREML_DATAREFERENCE_gensen'], '/senteval/')\n",
    "PATH_SENTEVAL = ds.path('/senteval/')\n",
    "# Path to model data.\n",
    "# PATH_TO_DATA = os.path.join(os.environ['AZUREML_DATAREFERENCE_gensen'], '/data/')\n",
    "PATH_TO_DATA = ds.path('/data/')\n",
    "\n",
    "# Set the senteval code folder.\n",
    "sys.path.insert(0, '../')\n",
    "import senteval\n",
    "\n",
    "# set gpu device\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Torch version: {}\".format(torch.__version__))\n",
    "print(\"Senteval data path: {}\".format(PATH_SENTEVAL))\n",
    "print(\"Trained model path: {}\".format(PATH_TO_DATA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Use SentEval\n",
    "To evaluate your sentence embeddings, SentEval requires that you implement two functions:\n",
    "\n",
    "1. **prepare** (sees the whole dataset of each task and can thus construct the word vocabulary, the dictionary of word vectors etc)\n",
    "2. **batcher** (transforms a batch of text sentences into sentence embeddings)\n",
    "\n",
    "### 1.) prepare(params, samples) (optional)\n",
    "\n",
    "*batcher* only sees one batch at a time while the *samples* argument of *prepare* contains all the sentences of a task.\n",
    "\n",
    "```\n",
    "prepare(params, samples)\n",
    "```\n",
    "* *params*: senteval parameters.\n",
    "* *samples*: list of all sentences from the tranfer task.\n",
    "* *output*: No output. Arguments stored in \"params\" can further be used by *batcher*.\n",
    "\n",
    "### 2.) batcher(params, batch)\n",
    "```\n",
    "batcher(params, batch)\n",
    "```\n",
    "* *params*: senteval parameters.\n",
    "* *batch*: numpy array of text sentences (of size params.batch_size)\n",
    "* *output*: numpy array of sentence embeddings (of size params.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(params, samples):\n",
    "    print('Preparing task : %s ' % (params.current_task))\n",
    "    vocab = set()\n",
    "    for sample in samples:\n",
    "        if params.current_task != 'TREC':\n",
    "            sample = ' '.join(sample).lower().split()\n",
    "        else:\n",
    "            sample = ' '.join(sample).split()\n",
    "        for word in sample:\n",
    "            if word not in vocab:\n",
    "                vocab.add(word)\n",
    "\n",
    "    vocab.add('<s>')\n",
    "    vocab.add('<pad>')\n",
    "    vocab.add('<unk>')\n",
    "    vocab.add('</s>')\n",
    "    # If you want to turn off vocab expansion just comment out the below line.\n",
    "    params['gensen'].vocab_expansion(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Batcher function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batcher(local_strategy):\n",
    "    \n",
    "    def batcher(params, batch):\n",
    "        # batch contains list of words\n",
    "        max_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'ImageCaptionRetrieval']\n",
    "        if local_strategy == 'best':\n",
    "            if params.current_task in max_tasks:\n",
    "                strategy = 'max'\n",
    "            else:\n",
    "                strategy = 'last'\n",
    "        else:\n",
    "            strategy = local_strategy\n",
    "\n",
    "        sentences = [' '.join(s).lower() for s in batch]\n",
    "        _, embeddings = params['gensen'].get_representation(\n",
    "            sentences, pool=strategy, return_numpy=True\n",
    "        )\n",
    "        return embeddings\n",
    "    \n",
    "    return batcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Evaluation of GenSen trained model on Transfter Tasks (SentEval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Parameters for SentEval\n",
    "\n",
    "The current list of available tasks is:\n",
    "```python\n",
    "['CR', 'MR', 'MPQA', 'SUBJ', 'SST2', 'SST5', 'TREC', 'MRPC', 'SNLI',\n",
    "'SICKEntailment', 'SICKRelatedness', 'STSBenchmark', 'ImageCaptionRetrieval',\n",
    "'STS12', 'STS13', 'STS14', 'STS15', 'STS16',\n",
    "'Length', 'WordContent', 'Depth', 'TopConstituents','BigramShift', 'Tense',\n",
    "'SubjNumber', 'ObjNumber', 'OddManOut', 'CoordinationInversion']\n",
    "```\n",
    "Users can chose the subset of above tasks.\n",
    "\n",
    "1) to perform the actual evaluation, first import senteval and set its parameters:\n",
    "```python\n",
    "import senteval\n",
    "params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "```\n",
    "\n",
    "2) (optional) set the parameters of the classifier (when applicable):\n",
    "```python\n",
    "params['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\n",
    "                                 'tenacity': 5, 'epoch_size': 4}\n",
    "```\n",
    "You can choose **nhid=0** (Logistic Regression) or **nhid>0** (MLP) and define the parameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transfer tasks\n",
    "transfer_tasks = ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'SST5', 'TREC', 'SICKRelatedness',\\\n",
    "                  'SICKEntailment', 'MRPC', 'STS14', 'STSBenchmark', 'STS12', 'STS13', 'STS15', 'STS16']\n",
    "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "params_senteval['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\n",
    "                                 'tenacity': 5, 'epoch_size': 4}\n",
    "\n",
    "# Set up logger\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create an instance of the class SE:\n",
    "\n",
    "```python\n",
    "se = senteval.engine.SE(params, batcher, prepare)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the parameters by default.\n",
    "folder_path = './data/models'\n",
    "prefix_1 = 'nli_large_bothskip_parse'\n",
    "prefix_2 = 'nli_large_bothskip'\n",
    "pretrain = './data/embedding/glove.840B.300d.h5'\n",
    "strategy = 'best'\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda, strategy):\n",
    "    gensen_1 = GenSenSingle(\n",
    "        model_folder=folder_path,\n",
    "        filename_prefix=prefix_1,\n",
    "        pretrained_emb=pretrain,\n",
    "        cuda=cuda\n",
    "    )\n",
    "    gensen_2 = GenSenSingle(\n",
    "        model_folder=folder_path,\n",
    "        filename_prefix=prefix_2,\n",
    "        pretrained_emb=pretrain,\n",
    "        cuda=cuda\n",
    "    )\n",
    "    gensen = GenSen(gensen_1, gensen_2)\n",
    "    params_senteval['gensen'] = gensen\n",
    "    se = senteval.engine.SE(params_senteval, get_batcher(strategy), prepare)\n",
    "    results_transfer = se.eval(transfer_tasks)\n",
    "\n",
    "    print('--------------------------------------------')\n",
    "    print('Table 2 of Our Paper : ')\n",
    "    print('--------------------------------------------')\n",
    "    print('MR                [Dev:%.1f/Test:%.1f]' % (results_transfer['MR']['devacc'], results_transfer['MR']['acc']))\n",
    "    print('CR                [Dev:%.1f/Test:%.1f]' % (results_transfer['CR']['devacc'], results_transfer['CR']['acc']))\n",
    "    print('SUBJ              [Dev:%.1f/Test:%.1f]' % (results_transfer['SUBJ']['devacc'], results_transfer['SUBJ']['acc']))\n",
    "    print('MPQA              [Dev:%.1f/Test:%.1f]' % (results_transfer['MPQA']['devacc'], results_transfer['MPQA']['acc']))\n",
    "    print('SST2              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST2']['devacc'], results_transfer['SST2']['acc']))\n",
    "    print('SST5              [Dev:%.1f/Test:%.1f]' % (results_transfer['SST5']['devacc'], results_transfer['SST5']['acc']))\n",
    "    print('TREC              [Dev:%.1f/Test:%.1f]' % (results_transfer['TREC']['devacc'], results_transfer['TREC']['acc']))\n",
    "    print('MRPC              [Dev:%.1f/TestAcc:%.1f/TestF1:%.1f]' % (results_transfer['MRPC']['devacc'], results_transfer['MRPC']['acc'], results_transfer['MRPC']['f1']))\n",
    "    print('SICKRelatedness   [Dev:%.3f/Test:%.3f]' % (results_transfer['SICKRelatedness']['devpearson'], results_transfer['SICKRelatedness']['pearson']))\n",
    "    print('SICKEntailment    [Dev:%.1f/Test:%.1f]' % (results_transfer['SICKEntailment']['devacc'], results_transfer['SICKEntailment']['acc']))\n",
    "    print('STS12             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS12']['all']['pearson']['mean'], results_transfer['STS12']['all']['spearman']['mean']))\n",
    "    print('STS13             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS13']['all']['pearson']['mean'], results_transfer['STS13']['all']['spearman']['mean']))\n",
    "    print('STS14             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS14']['all']['pearson']['mean'], results_transfer['STS14']['all']['spearman']['mean']))\n",
    "    print('STS15             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS15']['all']['pearson']['mean'], results_transfer['STS15']['all']['spearman']['mean']))\n",
    "    print('STS16             [Pearson:%.3f/Spearman:%.3f]' % (results_transfer['STS16']['all']['pearson']['mean'], results_transfer['STS16']['all']['spearman']['mean']))\n",
    "    print('STSBenchmark      [Dev:%.5f/Pearson:%.5f/Spearman:%.5f]' % (results_transfer['STSBenchmark']['devpearson'], results_transfer['STSBenchmark']['pearson'], results_transfer['STSBenchmark']['spearman']))\n",
    "    print('--------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Results from SentEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'DataReference' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-6bde2cf817a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgensen_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-3edd94340359>\u001b[0m in \u001b[0;36mgensen_eval\u001b[1;34m(folder_path, prefix_1, prefix_2, pretrain, cuda, strategy)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mparams_senteval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gensen'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msenteval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_senteval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_batcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprepare\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mresults_transfer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransfer_tasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'--------------------------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\engine.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# evaluate on evaluation [name], either takes string or list of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\engine.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# evaluate on evaluation [name], either takes string or list of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Project\\NLP\\examples\\03-eval\\senteval\\senteval\\engine.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCREval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/downstream/CR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'MR'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMREval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/downstream/MR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'MPQA'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMPQAEval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/downstream/MPQA'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'DataReference' and 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "gensen_eval(folder_path, prefix_1, prefix_2, pretrain, cuda, strategy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [1] A. Conneau, D. Kiela, [*SentEval: An Evaluation Toolkit for Universal Sentence Representations*](https://arxiv.org/abs/1803.05449)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
