{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Microsoft Corporation. All rights reserved.*  \n",
    "\n",
    "*Licensed under the MIT License.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Inference on MultiNLI Dataset using Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before You Start\n",
    "\n",
    "The running time shown in this notebook is on a Standard_NC24s_v3 Azure Deep Learning Virtual Machine with 4 NVIDIA Tesla V100 GPUs. \n",
    "> **Tip:** If you want to run through the notebook quickly, you can set the **`QUICK_RUN`** flag in the cell below to **`True`** to run the notebook on a small subset of the data and a smaller number of epochs. \n",
    "\n",
    "The table below provides some reference running time on different machine configurations.  \n",
    "\n",
    "|QUICK_RUN|Machine Configurations|Running time|\n",
    "|:---------|:----------------------|:------------|\n",
    "|True|4 **CPU**s, 14GB memory| ~ 15 minutes|\n",
    "|True|1 NVIDIA Tesla K80 GPUs, 12GB GPU memory| ~ 5 minutes|\n",
    "|False|1 NVIDIA Tesla K80 GPUs, 12GB GPU memory| ~ 10.5 hours|\n",
    "|False|4 NVIDIA Tesla V100 GPUs, 64GB GPU memory| ~ 2.5 hours|\n",
    "\n",
    "If you run into CUDA out-of-memory error, try reducing the `BATCH_SIZE` and `MAX_SEQ_LENGTH`, but note that model performance will be compromised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set QUICK_RUN = True to run the notebook on a small subset of data and a smaller number of epochs.\n",
    "QUICK_RUN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, we demostrate using [BERT](https://arxiv.org/abs/1810.04805) to perform Natural Language Inference (NLI). We use the [MultiNLI](https://www.nyu.edu/projects/bowman/multinli/) dataset and the task is to classify sentence pairs into three classes: contradiction, entailment, and neutral.   \n",
    "The figure below shows how [BERT](https://arxiv.org/abs/1810.04805) classifies sentence pairs. It concatenates the tokens in each sentence pairs and separates the sentences by the [SEP] token. A [CLS] token is prepended to the token list and used as the aggregate sequence representation for the classification task.\n",
    "<img src=\"https://nlpbp.blob.core.windows.net/images/bert_two_sentence.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1107 22:10:21.768640 139623268476672 file_utils.py:39] PyTorch version 1.2.0 available.\n",
      "I1107 22:10:21.812602 139623268476672 modeling_xlnet.py:194] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I1107 22:10:22.139613 139623268476672 utils.py:141] NumExpr defaulting to 6 threads.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "nlp_path = os.path.abspath('../../')\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "    \n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils_nlp.models.transformers.sequence_classification import Processor, SequenceClassifier\n",
    "from utils_nlp.dataset.multinli import load_pandas_df\n",
    "from utils_nlp.common.timer import Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "\n",
    "TRAIN_DATA_USED_PERCENT = 1\n",
    "DEV_DATA_USED_PERCENT = 1\n",
    "NUM_EPOCHS = 2\n",
    "WARMUP_STEPS= 2500\n",
    "\n",
    "if QUICK_RUN:\n",
    "    TRAIN_DATA_USED_PERCENT = 0.001\n",
    "    DEV_DATA_USED_PERCENT = 0.01\n",
    "    NUM_EPOCHS = 1\n",
    "    WARMUP_STEPS= 10\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    BATCH_SIZE = 32\n",
    "else:\n",
    "    BATCH_SIZE = 16\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# model configurations\n",
    "TO_LOWER = True\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "# optimizer configurations\n",
    "LEARNING_RATE= 5e-5\n",
    "\n",
    "# data configurations\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"gold_label\"\n",
    "\n",
    "# CACHE_DIR = TemporaryDirectory().name\n",
    "CACHE_DIR = \"./temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "The MultiNLI dataset comes with three subsets: train, dev_matched, dev_mismatched. The dev_matched dataset are from the same genres as the train dataset, while the dev_mismatched dataset are from genres not seen in the training dataset.   \n",
    "The `load_pandas_df` function downloads and extracts the zip files if they don't already exist in `local_cache_path` and returns the data subset specified by `file_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_pandas_df(local_cache_path=CACHE_DIR, file_split=\"train\")\n",
    "dev_df_matched = load_pandas_df(local_cache_path=CACHE_DIR, file_split=\"dev_matched\")\n",
    "dev_df_mismatched = load_pandas_df(local_cache_path=CACHE_DIR, file_split=\"dev_mismatched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_matched = dev_df_matched.loc[dev_df_matched['gold_label'] != '-']\n",
    "dev_df_mismatched = dev_df_mismatched.loc[dev_df_mismatched['gold_label'] != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 392702\n",
      "Development (matched) dataset size: 9815\n",
      "Development (mismatched) dataset size: 9832\n",
      "\n",
      "   gold_label                                          sentence1  \\\n",
      "0     neutral  Conceptually cream skimming has two basic dime...   \n",
      "1  entailment  you know during the season and i guess at at y...   \n",
      "2  entailment  One of our number will carry out your instruct...   \n",
      "3  entailment  How do you know? All this is their information...   \n",
      "4     neutral  yeah i tell you what though if you go price so...   \n",
      "\n",
      "                                           sentence2  \n",
      "0  Product and geography are what make cream skim...  \n",
      "1  You lose the things to the following level if ...  \n",
      "2  A member of my team will execute your orders w...  \n",
      "3                  This information belongs to them.  \n",
      "4           The tennis shoes have a range of prices.  \n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset size: {}\".format(train_df.shape[0]))\n",
    "print(\"Development (matched) dataset size: {}\".format(dev_df_matched.shape[0]))\n",
    "print(\"Development (mismatched) dataset size: {}\".format(dev_df_mismatched.shape[0]))\n",
    "print()\n",
    "print(train_df[['gold_label', 'sentence1', 'sentence2']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the first and second sentences to form the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(Conceptually cream skimming has two basic dim...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(you know during the season and i guess at at ...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(One of our number will carry out your instruc...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(How do you know? All this is their informatio...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(yeah i tell you what though if you go price s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  gold_label\n",
       "0  (Conceptually cream skimming has two basic dim...     neutral\n",
       "1  (you know during the season and i guess at at ...  entailment\n",
       "2  (One of our number will carry out your instruc...  entailment\n",
       "3  (How do you know? All this is their informatio...  entailment\n",
       "4  (yeah i tell you what though if you go price s...     neutral"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[TEXT_COL] = list(zip(train_df['sentence1'], train_df['sentence2']))\n",
    "dev_df_matched[TEXT_COL] = list(zip(dev_df_matched['sentence1'], dev_df_matched['sentence2']))\n",
    "dev_df_mismatched[TEXT_COL] = list(zip(dev_df_mismatched['sentence1'], dev_df_mismatched['sentence2']))\n",
    "train_df[[TEXT_COL, LABEL_COL]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=TRAIN_DATA_USED_PERCENT).reset_index(drop=True)\n",
    "dev_df_matched = dev_df_matched.sample(frac=DEV_DATA_USED_PERCENT).reset_index(drop=True)\n",
    "dev_df_mismatched = dev_df_mismatched.sample(frac=DEV_DATA_USED_PERCENT).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_df[LABEL_COL])\n",
    "num_labels = len(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Preprocess\n",
    "Before training, we tokenize the sentence texts and convert them to lists of tokens. The following steps instantiate a BERT tokenizer given the language, and tokenize the text of the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1107 22:12:45.331787 139623268476672 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "100%|██████████| 393/393 [00:00<00:00, 1733.76it/s]\n",
      "100%|██████████| 98/98 [00:00<00:00, 1693.88it/s]\n",
      "100%|██████████| 98/98 [00:00<00:00, 1700.61it/s]\n"
     ]
    }
   ],
   "source": [
    "processor = Processor(model_name=MODEL_NAME, cache_dir=CACHE_DIR)\n",
    "train_dataset = processor.preprocess_sentence_pair(\n",
    "    train_df[TEXT_COL], train_labels, max_len=MAX_SEQ_LENGTH\n",
    ")\n",
    "dev_dataset_matched = processor.preprocess_sentence_pair(dev_df_matched[TEXT_COL], None, max_len=MAX_SEQ_LENGTH)\n",
    "dev_dataset_mismatched = processor.preprocess_sentence_pair(dev_df_mismatched[TEXT_COL], None, max_len=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we perform the following preprocessing steps in the cell below:\n",
    "\n",
    "* Convert the tokens into token indices corresponding to the BERT tokenizer's vocabulary\n",
    "* Add the special tokens [CLS] and [SEP] to mark the beginning and end of a sentence\n",
    "* Pad or truncate the token lists to the specified max length\n",
    "* Return mask lists that indicate paddings' positions\n",
    "* Return token type id lists that indicate which sentence the tokens belong to\n",
    "\n",
    "*See the original [implementation](https://github.com/google-research/bert/blob/master/run_classifier.py) for more information on BERT's input format.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1107 22:23:48.046394 139623268476672 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpbj409coy\n",
      "100%|██████████| 313/313 [00:00<00:00, 250442.04B/s]\n",
      "I1107 22:23:48.082683 139623268476672 file_utils.py:309] copying /tmp/tmpbj409coy to cache at ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1107 22:23:48.083700 139623268476672 file_utils.py:313] creating metadata file for ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1107 22:23:48.084568 139623268476672 file_utils.py:322] removing temp file /tmp/tmpbj409coy\n",
      "I1107 22:23:48.085379 139623268476672 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1107 22:23:48.086218 139623268476672 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 3,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1107 22:23:48.119390 139623268476672 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpw0tppp02\n",
      "100%|██████████| 440473133/440473133 [00:07<00:00, 59645059.56B/s]\n",
      "I1107 22:23:55.552124 139623268476672 file_utils.py:309] copying /tmp/tmpw0tppp02 to cache at ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I1107 22:23:56.026107 139623268476672 file_utils.py:313] creating metadata file for ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I1107 22:23:56.027407 139623268476672 file_utils.py:322] removing temp file /tmp/tmpw0tppp02\n",
      "I1107 22:23:56.093449 139623268476672 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I1107 22:23:59.488332 139623268476672 modeling_utils.py:405] Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1107 22:23:59.489248 139623268476672 modeling_utils.py:408] Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "classifier = SequenceClassifier(\n",
    "    model_name=MODEL_NAME, num_labels=num_labels, cache_dir=CACHE_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                                            it/s]\u001b[A\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]     \n",
      "Iteration:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.037395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|▊         | 1/13 [00:01<00:19,  1.59s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 2/13 [00:02<00:16,  1.53s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 3/13 [00:04<00:14,  1.50s/it]\u001b[A\n",
      "Iteration:  31%|███       | 4/13 [00:05<00:13,  1.47s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 5/13 [00:07<00:11,  1.45s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 6/13 [00:08<00:10,  1.44s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 7/13 [00:10<00:08,  1.43s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 8/13 [00:11<00:07,  1.42s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 9/13 [00:12<00:05,  1.41s/it]\u001b[A\n",
      "                                            04,  1.41s/it]\u001b[A\n",
      "Epoch:   0%|          | 0/1 [00:14<?, ?it/s]              \n",
      "Iteration:  77%|███████▋  | 10/13 [00:14<00:04,  1.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.034597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  85%|████████▍ | 11/13 [00:15<00:02,  1.41s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 12/13 [00:17<00:01,  1.41s/it]\u001b[A\n",
      "Epoch: 100%|██████████| 1/1 [00:17<00:00, 17.97s/it]3s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0.005 hrs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    classifier.fit(\n",
    "            train_dataset,\n",
    "            num_epochs=NUM_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )\n",
    "\n",
    "print(\"Training time : {:.3f} hrs\".format(t.interval / 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:01<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time : 0.000 hrs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    predictions_matched = classifier.predict(dev_dataset_matched, batch_size=BATCH_SIZE)\n",
    "print(\"Prediction time : {:.3f} hrs\".format(t.interval / 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:01<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time : 0.000 hrs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    predictions_mismatched = classifier.predict(dev_dataset_mismatched, batch_size=BATCH_SIZE)\n",
    "print(\"Prediction time : {:.3f} hrs\".format(t.interval / 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.000     0.000     0.000        34\n",
      "   entailment      0.351     0.971     0.515        35\n",
      "      neutral      0.000     0.000     0.000        29\n",
      "\n",
      "    micro avg      0.347     0.347     0.347        98\n",
      "    macro avg      0.117     0.324     0.172        98\n",
      " weighted avg      0.125     0.347     0.184        98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predictions_matched = label_encoder.inverse_transform(predictions_matched)\n",
    "print(classification_report(dev_df_matched[LABEL_COL], predictions_matched, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.000     0.000     0.000        47\n",
      "   entailment      0.278     1.000     0.435        27\n",
      "      neutral      0.000     0.000     0.000        24\n",
      "\n",
      "    micro avg      0.276     0.276     0.276        98\n",
      "    macro avg      0.093     0.333     0.145        98\n",
      " weighted avg      0.077     0.276     0.120        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_mismatched = label_encoder.inverse_transform(predictions_mismatched)\n",
    "print(classification_report(dev_df_mismatched[LABEL_COL], predictions_mismatched, digits=3))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "nlp_gpu",
   "language": "python",
   "name": "nlp_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
