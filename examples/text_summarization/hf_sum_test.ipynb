{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. \n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Abstractive Summarization Generation Using Pretrained BertAbs Model \n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "This notebook demonstrates how to generate abstractive summarization using HuggingFace's pretrained BertAbs model. The BertAbs algorithm is original published in [Text Summarization with Pretrained Encoders](https://arxiv.org/abs/1908.08345) and the code base was release at https://github.com/nlpyang/PreSumm. HuggingFace's transformer library has included a wrapper for the code base and most of the model is contained in https://github.com/huggingface/transformers/blob/master/examples/summarization/modeling_bertabs.py\n",
    "\n",
    "Utility functions and classes in the NLP Best Practices repo are used to facilitate data preprocessing, model training, model scoring, result postprocessing, and model evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daden/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "I0116 04:44:45.409288 140119874643776 file_utils.py:35] PyTorch version 1.3.0 available.\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/python3\n",
    "from collections import namedtuple\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "nlp_path = os.path.abspath(\"../../\")\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "\n",
    "from utils_nlp.common.pytorch_utils import get_device\n",
    "from utils_nlp.eval.evaluate_summarization import get_rouge\n",
    "from utils_nlp.dataset.cnndm import CNNDMAbsSumDataset\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "## BertAbs import\n",
    "sys.path.insert(0, \"./transformers/examples/summarization\")\n",
    "from modeling_bertabs import BertAbs, build_predictor\n",
    "\n",
    "from utils_summarization import (\n",
    "    build_mask,\n",
    "    compute_token_type_ids,\n",
    "    encode_for_summarization,\n",
    "    fit_to_block_size,\n",
    ")\n",
    "from run_summarization import format_rouge_scores, format_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0116 04:44:46.520054 140119874643776 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/daden/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/tmp/tmpvifv52a8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUICK_RUN = False\n",
    "# the data path used to save the downloaded data file\n",
    "# DATA_PATH = TemporaryDirectory().name\n",
    "# The number of lines at the head of data file used for preprocessing. -1 means all the lines.\n",
    "TOP_N = 100\n",
    "CHUNK_SIZE=200\n",
    "if not QUICK_RUN:\n",
    "    TOP_N = -1\n",
    "    CHUNK_SIZE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class AbsSumDataset(Dataset):\n",
    "    def __init__(self, source, target=None):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.source[idx], self.target[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Download CNN/DM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0116 04:44:47.887421 140119874643776 utils.py:173] Opening tar file /tmp/tmpvifv52a8/cnndm.tar.gz.\n",
      "I0116 04:44:47.888628 140119874643776 utils.py:181] /tmp/tmpvifv52a8/test.txt.src already extracted.\n",
      "I0116 04:44:48.178355 140119874643776 utils.py:181] /tmp/tmpvifv52a8/test.txt.tgt.tagged already extracted.\n",
      "I0116 04:44:48.204983 140119874643776 utils.py:181] /tmp/tmpvifv52a8/train.txt.src already extracted.\n",
      "I0116 04:44:55.672668 140119874643776 utils.py:181] /tmp/tmpvifv52a8/train.txt.tgt.tagged already extracted.\n",
      "I0116 04:44:56.290420 140119874643776 utils.py:181] /tmp/tmpvifv52a8/val.txt.src already extracted.\n",
      "I0116 04:44:56.624392 140119874643776 utils.py:181] /tmp/tmpvifv52a8/val.txt.tgt.tagged already extracted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11490"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset = CNNDMAbsSumDataset(top_n=TOP_N, local_cache_path=DATA_PATH)\n",
    "data = list(test_dataset.get_source()), list(test_dataset.get_target())\n",
    "test_sum_dataset = AbsSumDataset(data[0], data[1])\n",
    "len(test_sum_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainBatch = namedtuple(\"Batch\", [ \"batch_size\", \"src\", \"segs\", \"mask_src\", \"tgt\", \"tgt_segs\", \"mask_tgt\", \"tgt_str\"])\n",
    "TestBatch = namedtuple(\"Batch\", [ \"batch_size\", \"src\", \"segs\", \"mask_src\", \"tgt_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### added max_len argument\n",
    "def encode_for_summarization(story_lines, summary_lines, tokenizer, max_len=512):\n",
    "    \"\"\" Encode the story and summary lines, and join them\n",
    "    as specified in [1] by using `[SEP] [CLS]` tokens to separate\n",
    "    sentences.\n",
    "    \"\"\"\n",
    "    story_lines_token_ids = [tokenizer.encode(line, max_length=max_len) for line in story_lines]\n",
    "    story_token_ids = [token for sentence in story_lines_token_ids for token in sentence]\n",
    "    summary_lines_token_ids = [tokenizer.encode(line, max_length=max_len) for line in summary_lines]\n",
    "    summary_token_ids = [token for sentence in summary_lines_token_ids for token in sentence]\n",
    "\n",
    "    return story_token_ids, summary_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(data, tokenizer, block_size, device):\n",
    "    \"\"\" Collate formats the data passed to the data loader.\n",
    "    In particular we tokenize the data batch after batch to avoid keeping them\n",
    "    all in memory. We output the data as a namedtuple to fit the original BertAbs's\n",
    "    API.\n",
    "    \"\"\"\n",
    "    data = [x for x in data if not len(x[1]) == 0]  # remove empty_files\n",
    "    #print(data)\n",
    "    #names = [name for name, _, _ in data]\n",
    "    # summaries = [\" \".join(summary_list) for _, _, summary_list in data]\n",
    "    summaries = [\" \".join(summary_list) for _, summary_list in data]\n",
    "  \n",
    "\n",
    "    encoded_text = [encode_for_summarization(story, summary, tokenizer, block_size) for story, summary in data]\n",
    "    \n",
    "    \n",
    "    #\"\"\"\"\"\"\n",
    "    encoded_stories = torch.tensor(\n",
    "        [fit_to_block_size(story, block_size, tokenizer.pad_token_id) for story, _ in encoded_text]\n",
    "    )\n",
    "    encoder_token_type_ids = compute_token_type_ids(encoded_stories, tokenizer.cls_token_id)\n",
    "    encoder_mask = build_mask(encoded_stories, tokenizer.pad_token_id)\n",
    "    #\"\"\"\n",
    "\n",
    "\n",
    "    batch = TestBatch(\n",
    "        #document_names=None,\n",
    "        batch_size=len(encoded_stories),\n",
    "        src=encoded_stories.to(device),\n",
    "        segs=encoder_token_type_ids.to(device),\n",
    "        mask_src=encoder_mask.to(device),\n",
    "        tgt_str=summaries,\n",
    "    )\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_iterator(dataset, tokenizer, batch_size=16, device='cuda', max_len=512):\n",
    "   \n",
    "    sampler = SequentialSampler(dataset)\n",
    "\n",
    "    def collate_fn(data):\n",
    "        return collate(data, tokenizer, block_size=max_len, device=device)\n",
    "\n",
    "    iterator = DataLoader(dataset, sampler=sampler, batch_size=batch_size, collate_fn=collate_fn,)\n",
    "\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_nlp.common.pytorch_utils import get_device\n",
    "#device, num_gpus = get_device(num_gpus=1, local_rank=-1)\n",
    "device=\"cuda:0\"\n",
    "torch.cuda.set_device(device)\n",
    "data_iterator = build_data_iterator(test_sum_dataset, tokenizer, batch_size=64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0116 04:44:58.548022 140119874643776 configuration_utils.py:185] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/remi/bertabs-finetuned-cnndm-extractive-abstractive-summarization-config.json from cache at /home/daden/.cache/torch/transformers/7ebb4ac81007d10b400cb6c2968d4c8f1275a3e0cc3bab7f20f81913198b542c.df616398f4c84def6fca83d755543b01cb445db4ddd218d3efeded8ded68332f\n",
      "I0116 04:44:58.548912 140119874643776 configuration_utils.py:199] Model config {\n",
      "  \"dec_dropout\": 0.2,\n",
      "  \"dec_ff_size\": 2048,\n",
      "  \"dec_heads\": 8,\n",
      "  \"dec_hidden_size\": 768,\n",
      "  \"dec_layers\": 6,\n",
      "  \"enc_dropout\": 0.2,\n",
      "  \"enc_ff_size\": 512,\n",
      "  \"enc_heads\": 8,\n",
      "  \"enc_hidden_size\": 512,\n",
      "  \"enc_layers\": 6,\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"max_pos\": 512,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0116 04:44:58.694125 140119874643776 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/remi/bertabs-finetuned-cnndm-extractive-abstractive-summarization-pytorch_model.bin from cache at /home/daden/.cache/torch/transformers/6f1af625ee57a9fbf093ef0863fb774fbdae89fa99fea7a213c08ad26f0724c0.ef06f4d767c6fad3c61125520f9dbb0f219834539c0369980ee5ecb9d1ef5542\n",
      "I0116 04:44:58.844523 140119874643776 configuration_utils.py:185] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/daden/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I0116 04:44:58.845278 140119874643776 configuration_utils.py:199] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertAbs.from_pretrained(\"bertabs-finetuned-cnndm\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "symbols = {\n",
    "    \"BOS\": tokenizer.vocab[\"[unused0]\"],\n",
    "    \"EOS\": tokenizer.vocab[\"[unused1]\"],\n",
    "    \"PAD\": tokenizer.vocab[\"[PAD]\"],\n",
    "}\n",
    "from utils_nlp.models.transformers.extractive_summarization import Bunch\n",
    "args = Bunch({\"block_trigram\":True, \"alpha\": 0.95, \"beam_size\": 5, \"min_length\": 50, \"max_length\": 200})\n",
    "predictor = build_predictor(args, tokenizer, symbols, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_summaries = []\n",
    "generated_summaries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/180 [00:01<03:43,  1.25s/it]\u001b[A\n",
      "  1%|          | 2/180 [00:02<03:31,  1.19s/it]\u001b[A\n",
      "  2%|▏         | 3/180 [00:03<03:31,  1.20s/it]\u001b[A\n",
      "  2%|▏         | 4/180 [00:04<03:26,  1.18s/it]\u001b[A\n",
      "  3%|▎         | 5/180 [00:05<03:21,  1.15s/it]\u001b[A\n",
      "  3%|▎         | 6/180 [00:06<03:20,  1.15s/it]\u001b[A\n",
      "  4%|▍         | 7/180 [00:08<03:35,  1.25s/it]\u001b[A\n",
      "  4%|▍         | 8/180 [00:09<03:36,  1.26s/it]\u001b[A\n",
      "  5%|▌         | 9/180 [00:10<03:34,  1.25s/it]\u001b[A\n",
      "  6%|▌         | 10/180 [00:12<03:36,  1.28s/it]\u001b[A\n",
      "  6%|▌         | 11/180 [00:13<03:34,  1.27s/it]\u001b[A\n",
      "  7%|▋         | 12/180 [00:14<03:34,  1.28s/it]\u001b[A\n",
      "  7%|▋         | 13/180 [00:16<03:43,  1.34s/it]\u001b[A\n",
      "  8%|▊         | 14/180 [00:17<03:47,  1.37s/it]\u001b[A\n",
      "  8%|▊         | 15/180 [00:19<03:51,  1.40s/it]\u001b[A\n",
      "  9%|▉         | 16/180 [00:20<03:44,  1.37s/it]\u001b[A\n",
      "  9%|▉         | 17/180 [00:21<03:36,  1.33s/it]\u001b[A\n",
      " 10%|█         | 18/180 [00:22<03:20,  1.24s/it]\u001b[A\n",
      " 11%|█         | 19/180 [00:23<03:14,  1.21s/it]\u001b[A\n",
      " 11%|█         | 20/180 [00:24<02:59,  1.12s/it]\u001b[A\n",
      " 12%|█▏        | 21/180 [00:25<02:54,  1.10s/it]\u001b[A\n",
      " 12%|█▏        | 22/180 [00:26<02:48,  1.06s/it]\u001b[A\n",
      " 13%|█▎        | 23/180 [00:27<02:51,  1.09s/it]\u001b[A\n",
      " 13%|█▎        | 24/180 [00:29<02:52,  1.11s/it]\u001b[A\n",
      " 14%|█▍        | 25/180 [00:30<02:52,  1.11s/it]\u001b[A\n",
      " 14%|█▍        | 26/180 [00:31<02:49,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 27/180 [00:32<02:50,  1.12s/it]\u001b[A\n",
      " 16%|█▌        | 28/180 [00:33<02:51,  1.13s/it]\u001b[A\n",
      " 16%|█▌        | 29/180 [00:34<02:47,  1.11s/it]\u001b[A\n",
      " 17%|█▋        | 30/180 [00:35<02:42,  1.09s/it]\u001b[A\n",
      " 17%|█▋        | 31/180 [00:36<02:41,  1.08s/it]\u001b[A\n",
      " 18%|█▊        | 32/180 [00:37<02:44,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 33/180 [00:39<02:44,  1.12s/it]\u001b[A\n",
      " 19%|█▉        | 34/180 [00:40<02:44,  1.13s/it]\u001b[A\n",
      " 19%|█▉        | 35/180 [00:41<02:45,  1.14s/it]\u001b[A\n",
      " 20%|██        | 36/180 [00:42<02:43,  1.14s/it]\u001b[A\n",
      " 21%|██        | 37/180 [00:43<02:38,  1.11s/it]\u001b[A\n",
      " 21%|██        | 38/180 [00:44<02:38,  1.11s/it]\u001b[A\n",
      " 22%|██▏       | 39/180 [00:45<02:42,  1.15s/it]\u001b[A\n",
      " 22%|██▏       | 40/180 [00:47<02:38,  1.13s/it]\u001b[A\n",
      " 23%|██▎       | 41/180 [00:48<02:40,  1.15s/it]\u001b[A\n",
      " 23%|██▎       | 42/180 [00:49<02:44,  1.19s/it]\u001b[A\n",
      " 24%|██▍       | 43/180 [00:50<02:37,  1.15s/it]\u001b[A\n",
      " 24%|██▍       | 44/180 [00:51<02:32,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 45/180 [00:52<02:26,  1.08s/it]\u001b[A\n",
      " 26%|██▌       | 46/180 [00:53<02:28,  1.11s/it]\u001b[A\n",
      " 26%|██▌       | 47/180 [00:54<02:25,  1.10s/it]\u001b[A\n",
      " 27%|██▋       | 48/180 [00:56<02:30,  1.14s/it]\u001b[A\n",
      " 27%|██▋       | 49/180 [00:57<02:25,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 50/180 [00:58<02:22,  1.09s/it]\u001b[A\n",
      " 28%|██▊       | 51/180 [00:59<02:26,  1.14s/it]\u001b[A\n",
      " 29%|██▉       | 52/180 [01:00<02:30,  1.17s/it]\u001b[A\n",
      " 29%|██▉       | 53/180 [01:01<02:19,  1.10s/it]\u001b[A\n",
      " 30%|███       | 54/180 [01:02<02:21,  1.12s/it]\u001b[A\n",
      " 31%|███       | 55/180 [01:03<02:19,  1.12s/it]\u001b[A\n",
      " 31%|███       | 56/180 [01:05<02:20,  1.13s/it]\u001b[A\n",
      " 32%|███▏      | 57/180 [01:06<02:21,  1.15s/it]\u001b[A\n",
      " 32%|███▏      | 58/180 [01:07<02:22,  1.17s/it]\u001b[A\n",
      " 33%|███▎      | 59/180 [01:08<02:13,  1.11s/it]\u001b[A\n",
      " 33%|███▎      | 60/180 [01:09<02:08,  1.07s/it]\u001b[A\n",
      " 34%|███▍      | 61/180 [01:10<02:06,  1.06s/it]\u001b[A\n",
      " 34%|███▍      | 62/180 [01:11<02:08,  1.09s/it]\u001b[A\n",
      " 35%|███▌      | 63/180 [01:12<02:10,  1.12s/it]\u001b[A\n",
      " 36%|███▌      | 64/180 [01:13<02:10,  1.13s/it]\u001b[A\n",
      " 36%|███▌      | 65/180 [01:15<02:09,  1.13s/it]\u001b[A\n",
      " 37%|███▋      | 66/180 [01:16<02:18,  1.22s/it]\u001b[A\n",
      " 37%|███▋      | 67/180 [01:17<02:18,  1.22s/it]\u001b[A\n",
      " 38%|███▊      | 68/180 [01:19<02:22,  1.27s/it]\u001b[A\n",
      " 38%|███▊      | 69/180 [01:20<02:21,  1.27s/it]\u001b[A\n",
      " 39%|███▉      | 70/180 [01:21<02:26,  1.33s/it]\u001b[A\n",
      " 39%|███▉      | 71/180 [01:23<02:28,  1.36s/it]\u001b[A\n",
      " 40%|████      | 72/180 [01:24<02:17,  1.28s/it]\u001b[A\n",
      " 41%|████      | 73/180 [01:25<02:19,  1.30s/it]\u001b[A\n",
      " 41%|████      | 74/180 [01:27<02:20,  1.33s/it]\u001b[A\n",
      " 42%|████▏     | 75/180 [01:28<02:33,  1.46s/it]\u001b[A\n",
      " 42%|████▏     | 76/180 [01:30<02:28,  1.43s/it]\u001b[A\n",
      " 43%|████▎     | 77/180 [01:31<02:29,  1.45s/it]\u001b[A\n",
      " 43%|████▎     | 78/180 [01:33<02:29,  1.47s/it]\u001b[A\n",
      " 44%|████▍     | 79/180 [01:34<02:29,  1.48s/it]\u001b[A\n",
      " 44%|████▍     | 80/180 [01:36<02:29,  1.49s/it]\u001b[A\n",
      " 45%|████▌     | 81/180 [01:37<02:28,  1.50s/it]\u001b[A\n",
      " 46%|████▌     | 82/180 [01:39<02:26,  1.50s/it]\u001b[A\n",
      " 46%|████▌     | 83/180 [01:40<02:27,  1.52s/it]\u001b[A\n",
      " 47%|████▋     | 84/180 [01:42<02:26,  1.52s/it]\u001b[A\n",
      " 47%|████▋     | 85/180 [01:43<02:22,  1.50s/it]\u001b[A\n",
      " 48%|████▊     | 86/180 [01:45<02:17,  1.46s/it]\u001b[A\n",
      " 48%|████▊     | 87/180 [01:46<02:15,  1.46s/it]\u001b[A\n",
      " 49%|████▉     | 88/180 [01:48<02:11,  1.43s/it]\u001b[A\n",
      " 49%|████▉     | 89/180 [01:49<02:11,  1.45s/it]\u001b[A\n",
      " 50%|█████     | 90/180 [01:50<02:05,  1.40s/it]\u001b[A\n",
      " 51%|█████     | 91/180 [01:52<02:07,  1.43s/it]\u001b[A\n",
      " 51%|█████     | 92/180 [01:53<02:06,  1.44s/it]\u001b[A\n",
      " 52%|█████▏    | 93/180 [01:55<02:07,  1.46s/it]\u001b[A\n",
      " 52%|█████▏    | 94/180 [01:56<02:06,  1.47s/it]\u001b[A\n",
      " 53%|█████▎    | 95/180 [01:58<02:06,  1.49s/it]\u001b[A\n",
      " 53%|█████▎    | 96/180 [01:59<02:04,  1.48s/it]\u001b[A\n",
      " 54%|█████▍    | 97/180 [02:01<02:05,  1.51s/it]\u001b[A\n",
      " 54%|█████▍    | 98/180 [02:02<02:00,  1.47s/it]\u001b[A\n",
      " 55%|█████▌    | 99/180 [02:04<02:03,  1.53s/it]\u001b[A\n",
      " 56%|█████▌    | 100/180 [02:05<02:03,  1.54s/it]\u001b[A\n",
      " 56%|█████▌    | 101/180 [02:07<01:58,  1.50s/it]\u001b[A\n",
      " 57%|█████▋    | 102/180 [02:08<01:58,  1.51s/it]\u001b[A\n",
      " 57%|█████▋    | 103/180 [02:10<01:58,  1.54s/it]\u001b[A\n",
      " 58%|█████▊    | 104/180 [02:11<01:52,  1.49s/it]\u001b[A\n",
      " 58%|█████▊    | 105/180 [02:13<01:52,  1.51s/it]\u001b[A\n",
      " 59%|█████▉    | 106/180 [02:14<01:51,  1.51s/it]\u001b[A\n",
      " 59%|█████▉    | 107/180 [02:16<01:50,  1.52s/it]\u001b[A\n",
      " 60%|██████    | 108/180 [02:18<01:50,  1.53s/it]\u001b[A\n",
      " 61%|██████    | 109/180 [02:19<01:48,  1.53s/it]\u001b[A\n",
      " 61%|██████    | 110/180 [02:20<01:44,  1.49s/it]\u001b[A\n",
      " 62%|██████▏   | 111/180 [02:22<01:41,  1.47s/it]\u001b[A\n",
      " 62%|██████▏   | 112/180 [02:23<01:38,  1.45s/it]\u001b[A\n",
      " 63%|██████▎   | 113/180 [02:25<01:40,  1.50s/it]\u001b[A\n",
      " 63%|██████▎   | 114/180 [02:26<01:39,  1.51s/it]\u001b[A\n",
      " 64%|██████▍   | 115/180 [02:28<01:36,  1.48s/it]\u001b[A\n",
      " 64%|██████▍   | 116/180 [02:29<01:36,  1.50s/it]\u001b[A\n",
      " 65%|██████▌   | 117/180 [02:31<01:33,  1.48s/it]\u001b[A\n",
      " 66%|██████▌   | 118/180 [02:32<01:34,  1.52s/it]\u001b[A\n",
      " 66%|██████▌   | 119/180 [02:34<01:31,  1.50s/it]\u001b[A\n",
      " 67%|██████▋   | 120/180 [02:35<01:29,  1.50s/it]\u001b[A\n",
      " 67%|██████▋   | 121/180 [02:37<01:28,  1.49s/it]\u001b[A\n",
      " 68%|██████▊   | 122/180 [02:38<01:26,  1.50s/it]\u001b[A\n",
      " 68%|██████▊   | 123/180 [02:40<01:26,  1.51s/it]\u001b[A\n",
      " 69%|██████▉   | 124/180 [02:41<01:23,  1.50s/it]\u001b[A\n",
      " 69%|██████▉   | 125/180 [02:43<01:20,  1.47s/it]\u001b[A\n",
      " 70%|███████   | 126/180 [02:44<01:19,  1.47s/it]\u001b[A\n",
      " 71%|███████   | 127/180 [02:46<01:16,  1.45s/it]\u001b[A\n",
      " 71%|███████   | 128/180 [02:47<01:14,  1.43s/it]\u001b[A\n",
      " 72%|███████▏  | 129/180 [02:49<01:13,  1.44s/it]\u001b[A\n",
      " 72%|███████▏  | 130/180 [02:50<01:13,  1.47s/it]\u001b[A\n",
      " 73%|███████▎  | 131/180 [02:52<01:12,  1.48s/it]\u001b[A\n",
      " 73%|███████▎  | 132/180 [02:53<01:10,  1.47s/it]\u001b[A\n",
      " 74%|███████▍  | 133/180 [02:54<01:09,  1.47s/it]\u001b[A\n",
      " 74%|███████▍  | 134/180 [02:56<01:07,  1.48s/it]\u001b[A\n",
      " 75%|███████▌  | 135/180 [02:58<01:09,  1.53s/it]\u001b[A\n",
      " 76%|███████▌  | 136/180 [02:59<01:07,  1.54s/it]\u001b[A\n",
      " 76%|███████▌  | 137/180 [03:01<01:06,  1.54s/it]\u001b[A\n",
      " 77%|███████▋  | 138/180 [03:02<01:03,  1.50s/it]\u001b[A\n",
      " 77%|███████▋  | 139/180 [03:04<01:00,  1.49s/it]\u001b[A\n",
      " 78%|███████▊  | 140/180 [03:05<00:59,  1.48s/it]\u001b[A\n",
      " 78%|███████▊  | 141/180 [03:07<00:57,  1.46s/it]\u001b[A\n",
      " 79%|███████▉  | 142/180 [03:08<00:55,  1.46s/it]\u001b[A\n",
      " 79%|███████▉  | 143/180 [03:10<00:55,  1.49s/it]\u001b[A\n",
      " 80%|████████  | 144/180 [03:11<00:54,  1.51s/it]\u001b[A\n",
      " 81%|████████  | 145/180 [03:13<00:53,  1.52s/it]\u001b[A\n",
      " 81%|████████  | 146/180 [03:14<00:51,  1.52s/it]\u001b[A\n",
      " 82%|████████▏ | 147/180 [03:16<00:50,  1.54s/it]\u001b[A\n",
      " 82%|████████▏ | 148/180 [03:17<00:48,  1.52s/it]\u001b[A\n",
      " 83%|████████▎ | 149/180 [03:19<00:46,  1.51s/it]\u001b[A\n",
      " 83%|████████▎ | 150/180 [03:20<00:44,  1.49s/it]\u001b[A\n",
      " 84%|████████▍ | 151/180 [03:22<00:44,  1.53s/it]\u001b[A\n",
      " 84%|████████▍ | 152/180 [03:23<00:42,  1.52s/it]\u001b[A\n",
      " 85%|████████▌ | 153/180 [03:25<00:39,  1.45s/it]\u001b[A\n",
      " 86%|████████▌ | 154/180 [03:26<00:38,  1.47s/it]\u001b[A\n",
      " 86%|████████▌ | 155/180 [03:27<00:36,  1.46s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 156/180 [03:29<00:35,  1.48s/it]\u001b[A\n",
      " 87%|████████▋ | 157/180 [03:31<00:34,  1.50s/it]\u001b[A\n",
      " 88%|████████▊ | 158/180 [03:32<00:33,  1.54s/it]\u001b[A\n",
      " 88%|████████▊ | 159/180 [03:34<00:32,  1.53s/it]\u001b[A\n",
      " 89%|████████▉ | 160/180 [03:35<00:31,  1.55s/it]\u001b[A\n",
      " 89%|████████▉ | 161/180 [03:37<00:29,  1.57s/it]\u001b[A\n",
      " 90%|█████████ | 162/180 [03:38<00:27,  1.56s/it]\u001b[A\n",
      " 91%|█████████ | 163/180 [03:40<00:26,  1.57s/it]\u001b[A\n",
      " 91%|█████████ | 164/180 [03:42<00:24,  1.55s/it]\u001b[A\n",
      " 92%|█████████▏| 165/180 [03:43<00:23,  1.57s/it]\u001b[A\n",
      " 92%|█████████▏| 166/180 [03:45<00:22,  1.61s/it]\u001b[A\n",
      " 93%|█████████▎| 167/180 [03:46<00:20,  1.58s/it]\u001b[A\n",
      " 93%|█████████▎| 168/180 [03:48<00:18,  1.56s/it]\u001b[A\n",
      " 94%|█████████▍| 169/180 [03:49<00:16,  1.52s/it]\u001b[A\n",
      " 94%|█████████▍| 170/180 [03:51<00:15,  1.51s/it]\u001b[A\n",
      " 95%|█████████▌| 171/180 [03:52<00:13,  1.49s/it]\u001b[A\n",
      " 96%|█████████▌| 172/180 [03:54<00:11,  1.47s/it]\u001b[A\n",
      " 96%|█████████▌| 173/180 [03:55<00:10,  1.46s/it]\u001b[A\n",
      " 97%|█████████▋| 174/180 [03:56<00:08,  1.43s/it]\u001b[A\n",
      " 97%|█████████▋| 175/180 [03:58<00:07,  1.44s/it]\u001b[A\n",
      " 98%|█████████▊| 176/180 [03:59<00:05,  1.44s/it]\u001b[A\n",
      " 98%|█████████▊| 177/180 [04:01<00:04,  1.50s/it]\u001b[A\n",
      " 99%|█████████▉| 178/180 [04:02<00:02,  1.49s/it]\u001b[A\n",
      " 99%|█████████▉| 179/180 [04:04<00:01,  1.50s/it]\u001b[A\n",
      "100%|██████████| 180/180 [04:05<00:00,  1.30s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(data_iterator):\n",
    "    \n",
    "    batch_data = predictor.translate_batch(batch)\n",
    "    translations = predictor.from_batch(batch_data)\n",
    "    summaries = [format_summary(t) for t in translations]\n",
    "    \n",
    "    reference_summaries += batch.tgt_str\n",
    "    generated_summaries += summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_summaries = []\n",
    "for i in data[1]:\n",
    "    reference_summaries.append(i[0].replace('<q>', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_list_to_file(list_items, filename):\n",
    "    with open(filename, \"w\") as filehandle:\n",
    "        # for cnt, line in enumerate(filehandle):\n",
    "        for item in list_items:\n",
    "            filehandle.write(\"%s\\n\" % item)\n",
    "\"\"\"\n",
    "_write_list_to_file(generated_summaries, \"./generated_summaries\")\n",
    "generated_summaries = []\n",
    "with open(\"./generated_summaries\", \"r\") as filehandle:\n",
    "    for cnt, line in enumerate(filehandle):\n",
    "        generated_summaries.append(line)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prosecutor brice robin : \" so far no videos were used in the crash investigation \". robin \\'s comments follow claims by two magazines , german daily bild and french paris match. all 150 on board germanwings flight 9525 were killed\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./generated_summaries\", \"r\") as filehandle:\n",
    "    for cnt, line in enumerate(filehandle):\n",
    "        generated_summaries.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(generated_summaries)==len(reference_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daden/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import rouge\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "rouge_evaluator = rouge.Rouge(\n",
    "    metrics=[\"rouge-n\", \"rouge-l\"],\n",
    "    max_n=2,\n",
    "    limit_length=True,\n",
    "    length_limit=args.beam_size,\n",
    "    length_limit_type=\"words\",\n",
    "    apply_avg=True,\n",
    "    apply_best=False,\n",
    "    alpha=0.5,  # Default F1_score\n",
    "    weight_factor=1.2,\n",
    "    stemming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****** ROUGE SCORES ******\n",
      "\n",
      "** ROUGE 1\n",
      "F1        >> 0.355\n",
      "Precision >> 0.365\n",
      "Recall    >> 0.351\n",
      "\n",
      "** ROUGE 2\n",
      "F1        >> 0.242\n",
      "Precision >> 0.251\n",
      "Recall    >> 0.238\n",
      "\n",
      "** ROUGE L\n",
      "F1        >> 0.385\n",
      "Precision >> 0.394\n",
      "Recall    >> 0.381\n"
     ]
    }
   ],
   "source": [
    "scores = rouge_evaluator.get_scores(generated_summaries, reference_summaries)\n",
    "str_scores = format_rouge_scores(scores)\n",
    "print(str_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6 cm3",
   "language": "python",
   "name": "cm3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
