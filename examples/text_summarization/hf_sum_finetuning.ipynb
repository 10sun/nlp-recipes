{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0108 21:29:54.515745 140163355588416 file_utils.py:35] PyTorch version 1.3.0 available.\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/python3\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "#\n",
    "from transformers import BertTokenizer\n",
    "#from transformers import BertAbs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/dadendev/transformers/examples/summarization\")\n",
    "from modeling_bertabs import BertAbs, build_predictor\n",
    "\n",
    "from utils_summarization import (\n",
    "    #SummarizationDataset,\n",
    "    build_mask,\n",
    "    compute_token_type_ids,\n",
    "    encode_for_summarization,\n",
    "    fit_to_block_size,\n",
    ")\n",
    "from run_summarization import format_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0108 21:27:26.882526 139788440540992 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/daden/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'BertAbs' has no attribute 'from_pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f99b92e45b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertAbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bertabs-finetuned-cnndm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'BertAbs' has no attribute 'from_pretrained'"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "model = BertAbs.from_pretrained(\"bertabs-finetuned-cnndm\")\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "symbols = {\n",
    "    \"BOS\": tokenizer.vocab[\"[unused0]\"],\n",
    "    \"EOS\": tokenizer.vocab[\"[unused1]\"],\n",
    "    \"PAD\": tokenizer.vocab[\"[PAD]\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_path = os.path.abspath(\"../../\")\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "from utils_nlp.models.transformers.extractive_summarization import Bunch\n",
    "args = Bunch({\"block_trigram\":True, \"alpha\": 0.95, \"beam_size\": 5, \"min_length\": 20, \"max_length\": 200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'symbols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-06bf76f410c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'symbols' is not defined"
     ]
    }
   ],
   "source": [
    "predictor = build_predictor(args, tokenizer, symbols, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daden/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch\n",
    "\n",
    "nlp_path = os.path.abspath(\"../../\")\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "\n",
    "from utils_nlp.common.pytorch_utils import get_device\n",
    "from utils_nlp.dataset.cnndm import CNNDMBertSumProcessedData, CNNDMSummarizationDataset\n",
    "from utils_nlp.eval.evaluate_summarization import get_rouge\n",
    "from utils_nlp.models.transformers.extractive_summarization import (\n",
    "    ExtractiveSummarizer,\n",
    "    ExtSumProcessedData,\n",
    "    ExtSumProcessor,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scrapbook as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils_nlp.models.transformers.datasets import SummarizationDataset\n",
    "from utils_nlp.dataset.cnndm import CNNDMAbsSumDataset, CNNDMSummarizationDataset\n",
    "#def build_data_iterator(args, tokenizer):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/tmp/tmpsh6mbj3g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUICK_RUN = True\n",
    "# the data path used to save the downloaded data file\n",
    "# DATA_PATH = TemporaryDirectory().name\n",
    "# The number of lines at the head of data file used for preprocessing. -1 means all the lines.\n",
    "TOP_N = 4\n",
    "CHUNK_SIZE=200\n",
    "if not QUICK_RUN:\n",
    "    TOP_N = -1\n",
    "    CHUNK_SIZE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, source, target=None):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.source[idx], self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0108 21:30:09.018494 140163355588416 utils.py:173] Opening tar file /tmp/tmpsh6mbj3g/cnndm.tar.gz.\n",
      "I0108 21:30:09.020582 140163355588416 utils.py:181] /tmp/tmpsh6mbj3g/test.txt.src already extracted.\n",
      "I0108 21:30:09.306402 140163355588416 utils.py:181] /tmp/tmpsh6mbj3g/test.txt.tgt.tagged already extracted.\n",
      "I0108 21:30:09.332876 140163355588416 utils.py:181] /tmp/tmpsh6mbj3g/train.txt.src already extracted.\n",
      "I0108 21:30:16.825703 140163355588416 utils.py:181] /tmp/tmpsh6mbj3g/train.txt.tgt.tagged already extracted.\n",
      "I0108 21:30:17.439162 140163355588416 utils.py:181] /tmp/tmpsh6mbj3g/val.txt.src already extracted.\n",
      "I0108 21:30:17.773054 140163355588416 utils.py:181] /tmp/tmpsh6mbj3g/val.txt.tgt.tagged already extracted.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = CNNDMAbsSumDataset(top_n=TOP_N, local_cache_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(test_dataset.get_source()), list(test_dataset.get_target())\n",
    "test_sum_dataset = SummarizationDataset(data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(train_dataset.get_source()), list(train_dataset.get_target())\n",
    "train_sum_dataset = SummarizationDataset(data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = namedtuple(\"Batch\", [ \"batch_size\", \"src\", \"segs\", \"mask_src\", \"tgt\", \"tgt_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(data, tokenizer, block_size, device):\n",
    "    \"\"\" Collate formats the data passed to the data loader.\n",
    "    In particular we tokenize the data batch after batch to avoid keeping them\n",
    "    all in memory. We output the data as a namedtuple to fit the original BertAbs's\n",
    "    API.\n",
    "    \"\"\"\n",
    "    data = [x for x in data if not len(x[1]) == 0]  # remove empty_files\n",
    "    #print(data)\n",
    "    #names = [name for name, _, _ in data]\n",
    "    # summaries = [\" \".join(summary_list) for _, _, summary_list in data]\n",
    "    summaries = [\" \".join(summary_list) for _, summary_list in data]\n",
    "  \n",
    "\n",
    "    encoded_text = [encode_for_summarization(story, summary, tokenizer) for story, summary in data]\n",
    "    \n",
    "    \n",
    "    #\"\"\"\"\"\"\n",
    "    encoded_stories = torch.tensor(\n",
    "        [fit_to_block_size(story, block_size, tokenizer.pad_token_id) for story, _ in encoded_text]\n",
    "    )\n",
    "    encoder_token_type_ids = compute_token_type_ids(encoded_stories, tokenizer.cls_token_id)\n",
    "    encoder_mask = build_mask(encoded_stories, tokenizer.pad_token_id)\n",
    "    #\"\"\"\n",
    "    encoded_summaries= torch.tensor(\n",
    "        [fit_to_block_size(summary, block_size, tokenizer.pad_token_id) for _, summary in encoded_text]\n",
    "    )\n",
    "    \n",
    "    print(len(encoded_stories))\n",
    "\n",
    "    batch = Batch(\n",
    "        #document_names=None,\n",
    "        batch_size=len(encoded_stories),\n",
    "        src=encoded_stories.to(device),\n",
    "        segs=encoder_token_type_ids.to(device),\n",
    "        mask_src=encoder_mask.to(device),\n",
    "        tgt=encoded_summaries.to(device),\n",
    "        tgt_str=summaries,\n",
    "    )\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_for_summarization(story_lines, summary_lines, tokenizer, max_len=512):\n",
    "    \"\"\" Encode the story and summary lines, and join them\n",
    "    as specified in [1] by using `[SEP] [CLS]` tokens to separate\n",
    "    sentences.\n",
    "    \"\"\"\n",
    "    story_lines_token_ids = [tokenizer.encode(line, max_length=max_len) for line in story_lines]\n",
    "    story_token_ids = [token for sentence in story_lines_token_ids for token in sentence]\n",
    "    summary_lines_token_ids = [tokenizer.encode(line, max_length=max_len) for line in summary_lines]\n",
    "    summary_token_ids = [token for sentence in summary_lines_token_ids for token in sentence]\n",
    "\n",
    "    return story_token_ids, summary_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_iterator(dataset, tokenizer, batch_size=16, device='cuda'):\n",
    "   \n",
    "    sampler = SequentialSampler(dataset)\n",
    "\n",
    "    def collate_fn(data):\n",
    "        return collate(data, tokenizer, block_size=512, device=device)\n",
    "\n",
    "    iterator = DataLoader(dataset, sampler=sampler, batch_size=batch_size, collate_fn=collate_fn,)\n",
    "\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_nlp.common.pytorch_utils import get_device\n",
    "device, num_gpus = get_device(num_gpus=4, local_rank=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = build_data_iterator(train_sum_dataset, tokenizer, batch_size=64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from modeling_bertabs import BertSumOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0108 21:30:22.247485 140163355588416 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/daden/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name_or_path, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0108 21:30:23.292389 140163355588416 configuration_utils.py:185] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/daden/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I0108 21:30:23.293292 140163355588416 configuration_utils.py:199] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertForMaskedLM,\n",
    "    BertConfig,\n",
    "    PreTrainedEncoderDecoder,\n",
    "    Model2Model,\n",
    ")\n",
    "config = BertConfig.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "args= Bunch({ \"max_pos\": 512,\n",
    "            \"dec_layers\": 6,\n",
    "            \"dec_hidden_size\": 768,\n",
    "            \"dec_heads\": 8,\n",
    "            \"dec_ff_size\": 2048,\n",
    "            \"dec_dropout\": 0.2,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0108 21:30:25.595635 140163355588416 configuration_utils.py:185] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/daden/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I0108 21:30:25.596414 140163355588416 configuration_utils.py:199] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model = BertAbs.from_pretrained(\"bertabs-finetuned-cnndm\")\n",
    "model = BertAbs(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the optimizer\n",
    "lr = {\"encoder\": 0.002, \"decoder\": 0.2}\n",
    "warmup_steps = {\"encoder\": 20000, \"decoder\": 10000}\n",
    "optimizer = BertSumOptimizer(model, lr, warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_dataset,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    per_gpu_train_batch_size,\n",
    "    n_gpus,\n",
    "    device,\n",
    "    max_steps,\n",
    "    optimizer,\n",
    "    gradient_accumulation_steps,\n",
    "    num_train_epochs,\n",
    "    max_grad_norm\n",
    "):\n",
    "    \"\"\" Fine-tune the pretrained model on the corpus. \"\"\"\n",
    "    # Load the data\n",
    "    train_batch_size = per_gpu_train_batch_size * max(1, n_gpu)\n",
    "\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    model_collate_fn = functools.partial(collate, tokenizer=tokenizer, block_size=512)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=train_sampler,\n",
    "        batch_size=train_batch_size,\n",
    "        collate_fn=model_collate_fn,\n",
    "    )\n",
    "\n",
    "    # Training schedule\n",
    "    if max_steps > 0:\n",
    "        num_train_epochs = max_steps // (\n",
    "            len(train_dataloader) // gradient_accumulation_steps + 1\n",
    "        )\n",
    "    else:\n",
    "        max_steps = (\n",
    "            len(train_dataloader) // gradient_accumulation_steps * num_train_epochs\n",
    "        )\n",
    "\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(args.num_train_epochs, desc=\"Epoch\", disable=True)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss = 0.0\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=True)\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "           \n",
    "            source = batch.src\n",
    "            target = batch.tgt\n",
    "            encoder_token_type_ids = batch.segs\n",
    "            encoder_mask = batch.mask_src\n",
    "            \n",
    "            model.train()\n",
    "            outputs = model(\n",
    "                source,\n",
    "                target,\n",
    "                encoder_token_type_ids,\n",
    "                encoder_mask,\n",
    "                None,\n",
    "            )\n",
    "\n",
    "            loss = outputs[0]\n",
    "            print(loss)\n",
    "            if gradient_accumulation_steps > 1:\n",
    "                loss /= gradient_accumulation_steps\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(),max_grad_norm)\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "            if max_steps > 0 and global_step > max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "\n",
    "        if max_steps > 0 and global_step > max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n"
     ]
    }
   ],
   "source": [
    "   train(\n",
    "    train_dataset,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    per_gpu_train_batch_size,\n",
    "    n_gpus,\n",
    "    device,\n",
    "    max_steps,\n",
    "    optimizer,\n",
    "    gradient_accumulation_steps,\n",
    "    num_train_epochs,\n",
    "    max_grad_norm\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prosecutor brice robin : \" so far no videos were used in the crash investigation \". robin \\'s comments follow claims by two magazines , german daily bild and french paris match. all 150 on board germanwings flight 9525 were killed'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' marseille prosecutor says \" so far no videos were used in the crash investigation \" despite media reports . <q>  journalists at bild and paris match are \" very confident \" the video clip is real , an editor says . <q>  andreas lubitz had informed his lufthansa training school of an episode of severe depression , airline says . <q>\\n']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_summaries = []\n",
    "for i in data[1]:\n",
    "    reference_summaries.append(i[0].replace('<q>', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def _write_list_to_file(list_items, filename):\n",
    "        with open(filename, \"w\") as filehandle:\n",
    "            # for cnt, line in enumerate(filehandle):\n",
    "            for item in list_items:\n",
    "                filehandle.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_write_list_to_file(generated_summaries, \"./generated_summaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summaries = []\n",
    "with open(\"./generated_summaries\", \"r\") as filehandle:\n",
    "    for cnt, line in enumerate(filehandle):\n",
    "        generated_summaries.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11490"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prosecutor brice robin : \" so far no videos were used in the crash investigation \". robin \\'s comments follow claims by two magazines , german daily bild and french paris match. all 150 on board germanwings flight 9525 were killed\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' marseille prosecutor says \" so far no videos were used in the crash investigation \" despite media reports .   journalists at bild and paris match are \" very confident \" the video clip is real , an editor says .   andreas lubitz had informed his lufthansa training school of an episode of severe depression , airline says . \\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daden/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import rouge\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "rouge_evaluator = rouge.Rouge(\n",
    "    metrics=[\"rouge-n\", \"rouge-l\"],\n",
    "    max_n=2,\n",
    "    limit_length=True,\n",
    "    length_limit=args.beam_size,\n",
    "    length_limit_type=\"words\",\n",
    "    apply_avg=True,\n",
    "    apply_best=False,\n",
    "    alpha=0.5,  # Default F1_score\n",
    "    weight_factor=1.2,\n",
    "    stemming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = rouge_evaluator.get_scores(generated_summaries, reference_summaries)\n",
    "#str_scores = format_rouge_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6 cm3",
   "language": "python",
   "name": "cm3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
