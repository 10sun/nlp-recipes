{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "nlp_path = os.path.abspath(\"../../\")\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "sys.path.insert(0, \"./\")\n",
    "sys.path.insert(0, \"./BertSum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daden/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils_nlp.dataset.cnndm import CNNDMSummarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0lines [00:00, ?lines/s]\n",
      "0lines [00:00, ?lines/s]\n",
      "0lines [00:00, ?lines/s]\n",
      "0lines [00:00, ?lines/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = CNNDMSummarization(top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['marseille',\n",
       "  ',',\n",
       "  'france',\n",
       "  '(',\n",
       "  'cnn',\n",
       "  ')',\n",
       "  'the',\n",
       "  'french',\n",
       "  'prosecutor',\n",
       "  'leading',\n",
       "  'an',\n",
       "  'investigation',\n",
       "  'into',\n",
       "  'the',\n",
       "  'crash',\n",
       "  'of',\n",
       "  'germanwings',\n",
       "  'flight',\n",
       "  '9525',\n",
       "  'insisted',\n",
       "  'wednesday',\n",
       "  'that',\n",
       "  'he',\n",
       "  'was',\n",
       "  'not',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'any',\n",
       "  'video',\n",
       "  'footage',\n",
       "  'from',\n",
       "  'on',\n",
       "  'board',\n",
       "  'the',\n",
       "  'plane',\n",
       "  '.'],\n",
       " ['marseille',\n",
       "  'prosecutor',\n",
       "  'brice',\n",
       "  'robin',\n",
       "  'told',\n",
       "  'cnn',\n",
       "  'that',\n",
       "  '``',\n",
       "  'so',\n",
       "  'far',\n",
       "  'no',\n",
       "  'videos',\n",
       "  'were',\n",
       "  'used',\n",
       "  'in',\n",
       "  'the',\n",
       "  'crash',\n",
       "  'investigation',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['he',\n",
       "  'added',\n",
       "  ',',\n",
       "  '``',\n",
       "  'a',\n",
       "  'person',\n",
       "  'who',\n",
       "  'has',\n",
       "  'such',\n",
       "  'a',\n",
       "  'video',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'immediately',\n",
       "  'give',\n",
       "  'it',\n",
       "  'to',\n",
       "  'the',\n",
       "  'investigators',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['robin',\n",
       "  \"'s\",\n",
       "  'comments',\n",
       "  'follow',\n",
       "  'claims',\n",
       "  'by',\n",
       "  'two',\n",
       "  'magazines',\n",
       "  ',',\n",
       "  'german',\n",
       "  'daily',\n",
       "  'bild',\n",
       "  'and',\n",
       "  'french',\n",
       "  'paris',\n",
       "  'match',\n",
       "  ',',\n",
       "  'of',\n",
       "  'a',\n",
       "  'cell',\n",
       "  'phone',\n",
       "  'video',\n",
       "  'showing',\n",
       "  'the',\n",
       "  'harrowing',\n",
       "  'final',\n",
       "  'seconds',\n",
       "  'from',\n",
       "  'on',\n",
       "  'board',\n",
       "  'germanwings',\n",
       "  'flight',\n",
       "  '9525',\n",
       "  'as',\n",
       "  'it',\n",
       "  'crashed',\n",
       "  'into',\n",
       "  'the',\n",
       "  'french',\n",
       "  'alps',\n",
       "  '.'],\n",
       " ['all', '150', 'on', 'board', 'were', 'killed', '.'],\n",
       " ['paris',\n",
       "  'match',\n",
       "  'and',\n",
       "  'bild',\n",
       "  'reported',\n",
       "  'that',\n",
       "  'the',\n",
       "  'video',\n",
       "  'was',\n",
       "  'recovered',\n",
       "  'from',\n",
       "  'a',\n",
       "  'phone',\n",
       "  'at',\n",
       "  'the',\n",
       "  'wreckage',\n",
       "  'site',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'two',\n",
       "  'publications',\n",
       "  'described',\n",
       "  'the',\n",
       "  'supposed',\n",
       "  'video',\n",
       "  ',',\n",
       "  'but',\n",
       "  'did',\n",
       "  'not',\n",
       "  'post',\n",
       "  'it',\n",
       "  'on',\n",
       "  'their',\n",
       "  'websites',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'publications',\n",
       "  'said',\n",
       "  'that',\n",
       "  'they',\n",
       "  'watched',\n",
       "  'the',\n",
       "  'video',\n",
       "  ',',\n",
       "  'which',\n",
       "  'was',\n",
       "  'found',\n",
       "  'by',\n",
       "  'a',\n",
       "  'source',\n",
       "  'close',\n",
       "  'to',\n",
       "  'the',\n",
       "  'investigation',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['one',\n",
       "  'can',\n",
       "  'hear',\n",
       "  'cries',\n",
       "  'of',\n",
       "  '`',\n",
       "  'my',\n",
       "  'god',\n",
       "  \"'\",\n",
       "  'in',\n",
       "  'several',\n",
       "  'languages',\n",
       "  ',',\n",
       "  '``',\n",
       "  'paris',\n",
       "  'match',\n",
       "  'reported',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['metallic',\n",
       "  'banging',\n",
       "  'can',\n",
       "  'also',\n",
       "  'be',\n",
       "  'heard',\n",
       "  'more',\n",
       "  'than',\n",
       "  'three',\n",
       "  'times',\n",
       "  ',',\n",
       "  'perhaps',\n",
       "  'of',\n",
       "  'the',\n",
       "  'pilot',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'open',\n",
       "  'the',\n",
       "  'cockpit',\n",
       "  'door',\n",
       "  'with',\n",
       "  'a',\n",
       "  'heavy',\n",
       "  'object',\n",
       "  '.'],\n",
       " ['towards',\n",
       "  'the',\n",
       "  'end',\n",
       "  ',',\n",
       "  'after',\n",
       "  'a',\n",
       "  'heavy',\n",
       "  'shake',\n",
       "  ',',\n",
       "  'stronger',\n",
       "  'than',\n",
       "  'the',\n",
       "  'others',\n",
       "  ',',\n",
       "  'the',\n",
       "  'screaming',\n",
       "  'intensifies',\n",
       "  '.'],\n",
       " ['then', 'nothing', '.', '``'],\n",
       " ['``',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'very',\n",
       "  'disturbing',\n",
       "  'scene',\n",
       "  ',',\n",
       "  '``',\n",
       "  'said',\n",
       "  'julian',\n",
       "  'reichelt',\n",
       "  ',',\n",
       "  'editor-in-chief',\n",
       "  'of',\n",
       "  'bild',\n",
       "  'online',\n",
       "  '.'],\n",
       " ['an',\n",
       "  'official',\n",
       "  'with',\n",
       "  'france',\n",
       "  \"'s\",\n",
       "  'accident',\n",
       "  'investigation',\n",
       "  'agency',\n",
       "  ',',\n",
       "  'the',\n",
       "  'bea',\n",
       "  ',',\n",
       "  'said',\n",
       "  'the',\n",
       "  'agency',\n",
       "  'is',\n",
       "  'not',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'any',\n",
       "  'such',\n",
       "  'video',\n",
       "  '.'],\n",
       " ['lt.',\n",
       "  'col.',\n",
       "  'jean-marc',\n",
       "  'menichini',\n",
       "  ',',\n",
       "  'a',\n",
       "  'french',\n",
       "  'gendarmerie',\n",
       "  'spokesman',\n",
       "  'in',\n",
       "  'charge',\n",
       "  'of',\n",
       "  'communications',\n",
       "  'on',\n",
       "  'rescue',\n",
       "  'efforts',\n",
       "  'around',\n",
       "  'the',\n",
       "  'germanwings',\n",
       "  'crash',\n",
       "  'site',\n",
       "  ',',\n",
       "  'told',\n",
       "  'cnn',\n",
       "  'that',\n",
       "  'the',\n",
       "  'reports',\n",
       "  'were',\n",
       "  '``',\n",
       "  'completely',\n",
       "  'wrong',\n",
       "  '``',\n",
       "  'and',\n",
       "  '``',\n",
       "  'unwarranted',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['cell',\n",
       "  'phones',\n",
       "  'have',\n",
       "  'been',\n",
       "  'collected',\n",
       "  'at',\n",
       "  'the',\n",
       "  'site',\n",
       "  ',',\n",
       "  'he',\n",
       "  'said',\n",
       "  ',',\n",
       "  'but',\n",
       "  'that',\n",
       "  'they',\n",
       "  '``',\n",
       "  'had',\n",
       "  \"n't\",\n",
       "  'been',\n",
       "  'exploited',\n",
       "  'yet',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['menichini',\n",
       "  'said',\n",
       "  'he',\n",
       "  'believed',\n",
       "  'the',\n",
       "  'cell',\n",
       "  'phones',\n",
       "  'would',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'sent',\n",
       "  'to',\n",
       "  'the',\n",
       "  'criminal',\n",
       "  'research',\n",
       "  'institute',\n",
       "  'in',\n",
       "  'rosny',\n",
       "  'sous-bois',\n",
       "  ',',\n",
       "  'near',\n",
       "  'paris',\n",
       "  ',',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'be',\n",
       "  'analyzed',\n",
       "  'by',\n",
       "  'specialized',\n",
       "  'technicians',\n",
       "  'working',\n",
       "  'hand-in-hand',\n",
       "  'with',\n",
       "  'investigators',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'none',\n",
       "  'of',\n",
       "  'the',\n",
       "  'cell',\n",
       "  'phones',\n",
       "  'found',\n",
       "  'so',\n",
       "  'far',\n",
       "  'have',\n",
       "  'been',\n",
       "  'sent',\n",
       "  'to',\n",
       "  'the',\n",
       "  'institute',\n",
       "  ',',\n",
       "  'menichini',\n",
       "  'said',\n",
       "  '.'],\n",
       " ['asked',\n",
       "  'whether',\n",
       "  'staff',\n",
       "  'involved',\n",
       "  'in',\n",
       "  'the',\n",
       "  'search',\n",
       "  'could',\n",
       "  'have',\n",
       "  'leaked',\n",
       "  'a',\n",
       "  'memory',\n",
       "  'card',\n",
       "  'to',\n",
       "  'the',\n",
       "  'media',\n",
       "  ',',\n",
       "  'menichini',\n",
       "  'answered',\n",
       "  'with',\n",
       "  'a',\n",
       "  'categorical',\n",
       "  '``',\n",
       "  'no',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['reichelt',\n",
       "  'told',\n",
       "  '``',\n",
       "  'erin',\n",
       "  'burnett',\n",
       "  ':',\n",
       "  'outfront',\n",
       "  '``',\n",
       "  'that',\n",
       "  'he',\n",
       "  'had',\n",
       "  'watched',\n",
       "  'the',\n",
       "  'video',\n",
       "  'and',\n",
       "  'stood',\n",
       "  'by',\n",
       "  'the',\n",
       "  'report',\n",
       "  ',',\n",
       "  'saying',\n",
       "  'bild',\n",
       "  'and',\n",
       "  'paris',\n",
       "  'match',\n",
       "  'are',\n",
       "  '``',\n",
       "  'very',\n",
       "  'confident',\n",
       "  '``',\n",
       "  'that',\n",
       "  'the',\n",
       "  'clip',\n",
       "  'is',\n",
       "  'real',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'noted',\n",
       "  'that',\n",
       "  'investigators',\n",
       "  'only',\n",
       "  'revealed',\n",
       "  'they',\n",
       "  \"'d\",\n",
       "  'recovered',\n",
       "  'cell',\n",
       "  'phones',\n",
       "  'from',\n",
       "  'the',\n",
       "  'crash',\n",
       "  'site',\n",
       "  'after',\n",
       "  'bild',\n",
       "  'and',\n",
       "  'paris',\n",
       "  'match',\n",
       "  'published',\n",
       "  'their',\n",
       "  'reports',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['that', 'is', 'something', 'we', 'did', 'not', 'know', 'before', '.'],\n",
       " ['...',\n",
       "  'overall',\n",
       "  'we',\n",
       "  'can',\n",
       "  'say',\n",
       "  'many',\n",
       "  'things',\n",
       "  'of',\n",
       "  'the',\n",
       "  'investigation',\n",
       "  'were',\n",
       "  \"n't\",\n",
       "  'revealed',\n",
       "  'by',\n",
       "  'the',\n",
       "  'investigation',\n",
       "  'at',\n",
       "  'the',\n",
       "  'beginning',\n",
       "  ',',\n",
       "  '``',\n",
       "  'he',\n",
       "  'said',\n",
       "  '.'],\n",
       " ['what', 'was', 'mental', 'state', 'of', 'germanwings', 'co-pilot', '?'],\n",
       " ['german',\n",
       "  'airline',\n",
       "  'lufthansa',\n",
       "  'confirmed',\n",
       "  'tuesday',\n",
       "  'that',\n",
       "  'co-pilot',\n",
       "  'andreas',\n",
       "  'lubitz',\n",
       "  'had',\n",
       "  'battled',\n",
       "  'depression',\n",
       "  'years',\n",
       "  'before',\n",
       "  'he',\n",
       "  'took',\n",
       "  'the',\n",
       "  'controls',\n",
       "  'of',\n",
       "  'germanwings',\n",
       "  'flight',\n",
       "  '9525',\n",
       "  ',',\n",
       "  'which',\n",
       "  'he',\n",
       "  \"'s\",\n",
       "  'accused',\n",
       "  'of',\n",
       "  'deliberately',\n",
       "  'crashing',\n",
       "  'last',\n",
       "  'week',\n",
       "  'in',\n",
       "  'the',\n",
       "  'french',\n",
       "  'alps',\n",
       "  '.'],\n",
       " ['lubitz',\n",
       "  'told',\n",
       "  'his',\n",
       "  'lufthansa',\n",
       "  'flight',\n",
       "  'training',\n",
       "  'school',\n",
       "  'in',\n",
       "  '2009',\n",
       "  'that',\n",
       "  'he',\n",
       "  'had',\n",
       "  'a',\n",
       "  '``',\n",
       "  'previous',\n",
       "  'episode',\n",
       "  'of',\n",
       "  'severe',\n",
       "  'depression',\n",
       "  ',',\n",
       "  '``',\n",
       "  'the',\n",
       "  'airline',\n",
       "  'said',\n",
       "  'tuesday',\n",
       "  '.'],\n",
       " ['email',\n",
       "  'correspondence',\n",
       "  'between',\n",
       "  'lubitz',\n",
       "  'and',\n",
       "  'the',\n",
       "  'school',\n",
       "  'discovered',\n",
       "  'in',\n",
       "  'an',\n",
       "  'internal',\n",
       "  'investigation',\n",
       "  ',',\n",
       "  'lufthansa',\n",
       "  'said',\n",
       "  ',',\n",
       "  'included',\n",
       "  'medical',\n",
       "  'documents',\n",
       "  'he',\n",
       "  'submitted',\n",
       "  'in',\n",
       "  'connection',\n",
       "  'with',\n",
       "  'resuming',\n",
       "  'his',\n",
       "  'flight',\n",
       "  'training',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'announcement',\n",
       "  'indicates',\n",
       "  'that',\n",
       "  'lufthansa',\n",
       "  ',',\n",
       "  'the',\n",
       "  'parent',\n",
       "  'company',\n",
       "  'of',\n",
       "  'germanwings',\n",
       "  ',',\n",
       "  'knew',\n",
       "  'of',\n",
       "  'lubitz',\n",
       "  \"'s\",\n",
       "  'battle',\n",
       "  'with',\n",
       "  'depression',\n",
       "  ',',\n",
       "  'allowed',\n",
       "  'him',\n",
       "  'to',\n",
       "  'continue',\n",
       "  'training',\n",
       "  'and',\n",
       "  'ultimately',\n",
       "  'put',\n",
       "  'him',\n",
       "  'in',\n",
       "  'the',\n",
       "  'cockpit',\n",
       "  '.'],\n",
       " ['lufthansa',\n",
       "  ',',\n",
       "  'whose',\n",
       "  'ceo',\n",
       "  'carsten',\n",
       "  'spohr',\n",
       "  'previously',\n",
       "  'said',\n",
       "  'lubitz',\n",
       "  'was',\n",
       "  '100',\n",
       "  '%',\n",
       "  'fit',\n",
       "  'to',\n",
       "  'fly',\n",
       "  ',',\n",
       "  'described',\n",
       "  'its',\n",
       "  'statement',\n",
       "  'tuesday',\n",
       "  'as',\n",
       "  'a',\n",
       "  '``',\n",
       "  'swift',\n",
       "  'and',\n",
       "  'seamless',\n",
       "  'clarification',\n",
       "  '``',\n",
       "  'and',\n",
       "  'said',\n",
       "  'it',\n",
       "  'was',\n",
       "  'sharing',\n",
       "  'the',\n",
       "  'information',\n",
       "  'and',\n",
       "  'documents',\n",
       "  '--',\n",
       "  'including',\n",
       "  'training',\n",
       "  'and',\n",
       "  'medical',\n",
       "  'records',\n",
       "  '--',\n",
       "  'with',\n",
       "  'public',\n",
       "  'prosecutors',\n",
       "  '.'],\n",
       " ['spohr',\n",
       "  'traveled',\n",
       "  'to',\n",
       "  'the',\n",
       "  'crash',\n",
       "  'site',\n",
       "  'wednesday',\n",
       "  ',',\n",
       "  'where',\n",
       "  'recovery',\n",
       "  'teams',\n",
       "  'have',\n",
       "  'been',\n",
       "  'working',\n",
       "  'for',\n",
       "  'the',\n",
       "  'past',\n",
       "  'week',\n",
       "  'to',\n",
       "  'recover',\n",
       "  'human',\n",
       "  'remains',\n",
       "  'and',\n",
       "  'plane',\n",
       "  'debris',\n",
       "  'scattered',\n",
       "  'across',\n",
       "  'a',\n",
       "  'steep',\n",
       "  'mountainside',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'saw',\n",
       "  'the',\n",
       "  'crisis',\n",
       "  'center',\n",
       "  'set',\n",
       "  'up',\n",
       "  'in',\n",
       "  'seyne-les-alpes',\n",
       "  ',',\n",
       "  'laid',\n",
       "  'a',\n",
       "  'wreath',\n",
       "  'in',\n",
       "  'the',\n",
       "  'village',\n",
       "  'of',\n",
       "  'le',\n",
       "  'vernet',\n",
       "  ',',\n",
       "  'closer',\n",
       "  'to',\n",
       "  'the',\n",
       "  'crash',\n",
       "  'site',\n",
       "  ',',\n",
       "  'where',\n",
       "  'grieving',\n",
       "  'families',\n",
       "  'have',\n",
       "  'left',\n",
       "  'flowers',\n",
       "  'at',\n",
       "  'a',\n",
       "  'simple',\n",
       "  'stone',\n",
       "  'memorial',\n",
       "  '.'],\n",
       " ['menichini',\n",
       "  'told',\n",
       "  'cnn',\n",
       "  'late',\n",
       "  'tuesday',\n",
       "  'that',\n",
       "  'no',\n",
       "  'visible',\n",
       "  'human',\n",
       "  'remains',\n",
       "  'were',\n",
       "  'left',\n",
       "  'at',\n",
       "  'the',\n",
       "  'site',\n",
       "  'but',\n",
       "  'recovery',\n",
       "  'teams',\n",
       "  'would',\n",
       "  'keep',\n",
       "  'searching',\n",
       "  '.'],\n",
       " ['french',\n",
       "  'president',\n",
       "  'francois',\n",
       "  'hollande',\n",
       "  ',',\n",
       "  'speaking',\n",
       "  'tuesday',\n",
       "  ',',\n",
       "  'said',\n",
       "  'that',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'possible',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'all',\n",
       "  'the',\n",
       "  'victims',\n",
       "  'using',\n",
       "  'dna',\n",
       "  'analysis',\n",
       "  'by',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'week',\n",
       "  ',',\n",
       "  'sooner',\n",
       "  'than',\n",
       "  'authorities',\n",
       "  'had',\n",
       "  'previously',\n",
       "  'suggested',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'meantime',\n",
       "  ',',\n",
       "  'the',\n",
       "  'recovery',\n",
       "  'of',\n",
       "  'the',\n",
       "  'victims',\n",
       "  \"'\",\n",
       "  'personal',\n",
       "  'belongings',\n",
       "  'will',\n",
       "  'start',\n",
       "  'wednesday',\n",
       "  ',',\n",
       "  'menichini',\n",
       "  'said',\n",
       "  '.'],\n",
       " ['among',\n",
       "  'those',\n",
       "  'personal',\n",
       "  'belongings',\n",
       "  'could',\n",
       "  'be',\n",
       "  'more',\n",
       "  'cell',\n",
       "  'phones',\n",
       "  'belonging',\n",
       "  'to',\n",
       "  'the',\n",
       "  '144',\n",
       "  'passengers',\n",
       "  'and',\n",
       "  'six',\n",
       "  'crew',\n",
       "  'on',\n",
       "  'board',\n",
       "  '.'],\n",
       " ['check', 'out', 'the', 'latest', 'from', 'our', 'correspondents', '.'],\n",
       " ['the',\n",
       "  'details',\n",
       "  'about',\n",
       "  'lubitz',\n",
       "  \"'s\",\n",
       "  'correspondence',\n",
       "  'with',\n",
       "  'the',\n",
       "  'flight',\n",
       "  'school',\n",
       "  'during',\n",
       "  'his',\n",
       "  'training',\n",
       "  'were',\n",
       "  'among',\n",
       "  'several',\n",
       "  'developments',\n",
       "  'as',\n",
       "  'investigators',\n",
       "  'continued',\n",
       "  'to',\n",
       "  'delve',\n",
       "  'into',\n",
       "  'what',\n",
       "  'caused',\n",
       "  'the',\n",
       "  'crash',\n",
       "  'and',\n",
       "  'lubitz',\n",
       "  \"'s\",\n",
       "  'possible',\n",
       "  'motive',\n",
       "  'for',\n",
       "  'downing',\n",
       "  'the',\n",
       "  'jet',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'lufthansa',\n",
       "  'spokesperson',\n",
       "  'told',\n",
       "  'cnn',\n",
       "  'on',\n",
       "  'tuesday',\n",
       "  'that',\n",
       "  'lubitz',\n",
       "  'had',\n",
       "  'a',\n",
       "  'valid',\n",
       "  'medical',\n",
       "  'certificate',\n",
       "  ',',\n",
       "  'had',\n",
       "  'passed',\n",
       "  'all',\n",
       "  'his',\n",
       "  'examinations',\n",
       "  'and',\n",
       "  '``',\n",
       "  'held',\n",
       "  'all',\n",
       "  'the',\n",
       "  'licenses',\n",
       "  'required',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['earlier',\n",
       "  ',',\n",
       "  'a',\n",
       "  'spokesman',\n",
       "  'for',\n",
       "  'the',\n",
       "  'prosecutor',\n",
       "  \"'s\",\n",
       "  'office',\n",
       "  'in',\n",
       "  'dusseldorf',\n",
       "  ',',\n",
       "  'christoph',\n",
       "  'kumpa',\n",
       "  ',',\n",
       "  'said',\n",
       "  'medical',\n",
       "  'records',\n",
       "  'reveal',\n",
       "  'lubitz',\n",
       "  'suffered',\n",
       "  'from',\n",
       "  'suicidal',\n",
       "  'tendencies',\n",
       "  'at',\n",
       "  'some',\n",
       "  'point',\n",
       "  'before',\n",
       "  'his',\n",
       "  'aviation',\n",
       "  'career',\n",
       "  'and',\n",
       "  'underwent',\n",
       "  'psychotherapy',\n",
       "  'before',\n",
       "  'he',\n",
       "  'got',\n",
       "  'his',\n",
       "  'pilot',\n",
       "  \"'s\",\n",
       "  'license',\n",
       "  '.'],\n",
       " ['kumpa',\n",
       "  'emphasized',\n",
       "  'there',\n",
       "  \"'s\",\n",
       "  'no',\n",
       "  'evidence',\n",
       "  'suggesting',\n",
       "  'lubitz',\n",
       "  'was',\n",
       "  'suicidal',\n",
       "  'or',\n",
       "  'acting',\n",
       "  'aggressively',\n",
       "  'before',\n",
       "  'the',\n",
       "  'crash',\n",
       "  '.'],\n",
       " ['investigators',\n",
       "  'are',\n",
       "  'looking',\n",
       "  'into',\n",
       "  'whether',\n",
       "  'lubitz',\n",
       "  'feared',\n",
       "  'his',\n",
       "  'medical',\n",
       "  'condition',\n",
       "  'would',\n",
       "  'cause',\n",
       "  'him',\n",
       "  'to',\n",
       "  'lose',\n",
       "  'his',\n",
       "  'pilot',\n",
       "  \"'s\",\n",
       "  'license',\n",
       "  ',',\n",
       "  'a',\n",
       "  'european',\n",
       "  'government',\n",
       "  'official',\n",
       "  'briefed',\n",
       "  'on',\n",
       "  'the',\n",
       "  'investigation',\n",
       "  'told',\n",
       "  'cnn',\n",
       "  'on',\n",
       "  'tuesday',\n",
       "  '.'],\n",
       " ['while',\n",
       "  'flying',\n",
       "  'was',\n",
       "  '``',\n",
       "  'a',\n",
       "  'big',\n",
       "  'part',\n",
       "  'of',\n",
       "  'his',\n",
       "  'life',\n",
       "  ',',\n",
       "  '``',\n",
       "  'the',\n",
       "  'source',\n",
       "  'said',\n",
       "  ',',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'only',\n",
       "  'one',\n",
       "  'theory',\n",
       "  'being',\n",
       "  'considered',\n",
       "  '.'],\n",
       " ['another',\n",
       "  'source',\n",
       "  ',',\n",
       "  'a',\n",
       "  'law',\n",
       "  'enforcement',\n",
       "  'official',\n",
       "  'briefed',\n",
       "  'on',\n",
       "  'the',\n",
       "  'investigation',\n",
       "  ',',\n",
       "  'also',\n",
       "  'told',\n",
       "  'cnn',\n",
       "  'that',\n",
       "  'authorities',\n",
       "  'believe',\n",
       "  'the',\n",
       "  'primary',\n",
       "  'motive',\n",
       "  'for',\n",
       "  'lubitz',\n",
       "  'to',\n",
       "  'bring',\n",
       "  'down',\n",
       "  'the',\n",
       "  'plane',\n",
       "  'was',\n",
       "  'that',\n",
       "  'he',\n",
       "  'feared',\n",
       "  'he',\n",
       "  'would',\n",
       "  'not',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'fly',\n",
       "  'because',\n",
       "  'of',\n",
       "  'his',\n",
       "  'medical',\n",
       "  'problems',\n",
       "  '.'],\n",
       " ['lubitz',\n",
       "  \"'s\",\n",
       "  'girlfriend',\n",
       "  'told',\n",
       "  'investigators',\n",
       "  'he',\n",
       "  'had',\n",
       "  'seen',\n",
       "  'an',\n",
       "  'eye',\n",
       "  'doctor',\n",
       "  'and',\n",
       "  'a',\n",
       "  'neuropsychologist',\n",
       "  ',',\n",
       "  'both',\n",
       "  'of',\n",
       "  'whom',\n",
       "  'deemed',\n",
       "  'him',\n",
       "  'unfit',\n",
       "  'to',\n",
       "  'work',\n",
       "  'recently',\n",
       "  'and',\n",
       "  'concluded',\n",
       "  'he',\n",
       "  'had',\n",
       "  'psychological',\n",
       "  'issues',\n",
       "  ',',\n",
       "  'the',\n",
       "  'european',\n",
       "  'government',\n",
       "  'official',\n",
       "  'said',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'no',\n",
       "  'matter',\n",
       "  'what',\n",
       "  'details',\n",
       "  'emerge',\n",
       "  'about',\n",
       "  'his',\n",
       "  'previous',\n",
       "  'mental',\n",
       "  'health',\n",
       "  'struggles',\n",
       "  ',',\n",
       "  'there',\n",
       "  \"'s\",\n",
       "  'more',\n",
       "  'to',\n",
       "  'the',\n",
       "  'story',\n",
       "  ',',\n",
       "  'said',\n",
       "  'brian',\n",
       "  'russell',\n",
       "  ',',\n",
       "  'a',\n",
       "  'forensic',\n",
       "  'psychologist',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['psychology',\n",
       "  'can',\n",
       "  'explain',\n",
       "  'why',\n",
       "  'somebody',\n",
       "  'would',\n",
       "  'turn',\n",
       "  'rage',\n",
       "  'inward',\n",
       "  'on',\n",
       "  'themselves',\n",
       "  'about',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'maybe',\n",
       "  'they',\n",
       "  'were',\n",
       "  \"n't\",\n",
       "  'going',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'doing',\n",
       "  'their',\n",
       "  'job',\n",
       "  'and',\n",
       "  'they',\n",
       "  \"'re\",\n",
       "  'upset',\n",
       "  'about',\n",
       "  'that',\n",
       "  'and',\n",
       "  'so',\n",
       "  'they',\n",
       "  \"'re\",\n",
       "  'suicidal',\n",
       "  ',',\n",
       "  '``',\n",
       "  'he',\n",
       "  'said',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['but',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'mental',\n",
       "  'illness',\n",
       "  'that',\n",
       "  'explains',\n",
       "  'why',\n",
       "  'somebody',\n",
       "  'then',\n",
       "  'feels',\n",
       "  'entitled',\n",
       "  'to',\n",
       "  'also',\n",
       "  'take',\n",
       "  'that',\n",
       "  'rage',\n",
       "  'and',\n",
       "  'turn',\n",
       "  'it',\n",
       "  'outward',\n",
       "  'on',\n",
       "  '149',\n",
       "  'other',\n",
       "  'people',\n",
       "  'who',\n",
       "  'had',\n",
       "  'nothing',\n",
       "  'to',\n",
       "  'do',\n",
       "  'with',\n",
       "  'the',\n",
       "  'person',\n",
       "  \"'s\",\n",
       "  'problems',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['germanwings', 'crash', 'compensation', ':', 'what', 'we', 'know', '.'],\n",
       " ['who', 'was', 'the', 'captain', 'of', 'germanwings', 'flight', '9525', '?'],\n",
       " ['cnn',\n",
       "  \"'s\",\n",
       "  'margot',\n",
       "  'haddad',\n",
       "  'reported',\n",
       "  'from',\n",
       "  'marseille',\n",
       "  'and',\n",
       "  'pamela',\n",
       "  'brown',\n",
       "  'from',\n",
       "  'dusseldorf',\n",
       "  ',',\n",
       "  'while',\n",
       "  'laura',\n",
       "  'smith-spark',\n",
       "  'wrote',\n",
       "  'from',\n",
       "  'london',\n",
       "  '.'],\n",
       " ['cnn',\n",
       "  \"'s\",\n",
       "  'frederik',\n",
       "  'pleitgen',\n",
       "  ',',\n",
       "  'pamela',\n",
       "  'boykoff',\n",
       "  ',',\n",
       "  'antonia',\n",
       "  'mortensen',\n",
       "  ',',\n",
       "  'sandrine',\n",
       "  'amiel',\n",
       "  'and',\n",
       "  'anna-maja',\n",
       "  'rappard',\n",
       "  'contributed',\n",
       "  'to',\n",
       "  'this',\n",
       "  'report',\n",
       "  '.']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1024 20:41:43.713167 140449625069376 file_utils.py:39] PyTorch version 1.2.0 available.\n",
      "I1024 20:41:43.746781 140449625069376 modeling_xlnet.py:194] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I1024 20:41:43.753849 140449625069376 modeling.py:230] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "from utils_nlp.models.transformers.extractive_summarization import ExtSumProcessor, ExtractiveSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1024 20:41:43.980694 140449625069376 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at ./5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "processor = ExtSumProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_sum_train = processor.preprocess(list(train_dataset), list(train_dataset.get_target()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_sum_test = processor.preprocess(list(test_dataset), list(test_dataset.get_target()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utils_nlp.models.transformers.extractive_summarization.ExtSumIterableDataset"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ext_sum_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utils_nlp.models.transformers.extractive_summarization.ExtSumData"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ext_sum_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_sum_train[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(ext_sum_test.clss.size(1)))*len(ext_sum_test.clss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1024 20:41:45.197966 140449625069376 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at ./b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I1024 20:41:45.200124 140449625069376 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I1024 20:41:45.342200 140449625069376 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at ./35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "I1024 20:41:48.732301 140449625069376 modeling_utils.py:405] Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1024 20:41:48.733542 140449625069376 modeling_utils.py:408] Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1024 20:41:48.868890 140449625069376 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at ./b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I1024 20:41:48.870221 140449625069376 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I1024 20:41:48.990102 140449625069376 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at ./35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "I1024 20:41:52.468241 140449625069376 modeling_utils.py:405] Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1024 20:41:52.471548 140449625069376 modeling_utils.py:408] Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "summarizer = ExtractiveSummarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook parameters\n",
    "DATA_FOLDER = \"./temp\"\n",
    "CACHE_DIR = \"./temp\"\n",
    "DEVICE = \"cuda\"\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "NUM_GPUS = 2\n",
    "MAX_LEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A/dadendev/anaconda3/envs/cm3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:12<?, ?it/s]\n",
      "Iteration: 0it [00:12, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.098849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:12, 12.42s/it]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:12<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.104650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.46it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:12<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.098288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.46it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:13<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.092516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.40it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:13<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.094773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.39it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:14<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.098362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.47it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:14<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.095246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.48it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:15<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.097674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.49it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:15<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.102338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.45it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:16<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.101050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.47it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:16<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.098637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils_nlp.common.timer import Timer\n",
    "with Timer() as t:\n",
    "    summarizer.fit(\n",
    "            ext_sum_train,\n",
    "            device=DEVICE,\n",
    "            num_epochs=NUM_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_gpus=NUM_GPUS,\n",
    "            max_steps=1e1,\n",
    "            verbose=True,\n",
    "        )\n",
    "train_time = t.interval / 3600    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 1it [00:00, 20.03it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = summarizer.predict(ext_sum_test,\n",
    "                               device=DEVICE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metallic banging can also be heard more than three times , perhaps of the pilot trying to open the cockpit door with a heavy object .<q>but none of the cell phones found so far have been sent to the institute , menichini said .<q>`` it is a very disturbing scene , `` said julian reichelt , editor-in-chief of bild online .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.argsort(negative, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort([0,1,2,0.3,0.2], 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ext_sum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6 cm3",
   "language": "python",
   "name": "cm3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
