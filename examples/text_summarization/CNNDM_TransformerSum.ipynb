{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "nlp_path = os.path.abspath(\"../../\")\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "sys.path.insert(0, \"./\")\n",
    "sys.path.insert(0, \"/dadendev/nlp/examples/text_summarization/BertSum/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/dadendev/nlp/examples/text_summarization/BertSum/', './', '/dadendev/nlp', '/dadendev/anaconda3/envs/cm3/lib/python36.zip', '/dadendev/anaconda3/envs/cm3/lib/python3.6', '/dadendev/anaconda3/envs/cm3/lib/python3.6/lib-dynload', '', '/home/daden/.local/lib/python3.6/site-packages', '/dadendev/anaconda3/envs/cm3/lib/python3.6/site-packages', '/dadendev/anaconda3/envs/cm3/lib/python3.6/site-packages/pyrouge-0.1.3-py3.6.egg', '/dadendev/anaconda3/envs/cm3/lib/python3.6/site-packages/IPython/extensions', '/home/daden/.ipython']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daden/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "0lines [00:00, ?lines/s]\n",
      "0lines [00:00, ?lines/s]\n",
      "0lines [00:00, ?lines/s]\n",
      "0lines [00:00, ?lines/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['marseille',\n",
       "  ',',\n",
       "  'france',\n",
       "  '(',\n",
       "  'cnn',\n",
       "  ')',\n",
       "  'the',\n",
       "  'french',\n",
       "  'prosecutor',\n",
       "  'leading',\n",
       "  'an',\n",
       "  'investigation',\n",
       "  'into',\n",
       "  'the',\n",
       "  'crash',\n",
       "  'of',\n",
       "  'germanwings',\n",
       "  'flight',\n",
       "  '9525',\n",
       "  'insisted',\n",
       "  'wednesday',\n",
       "  'that',\n",
       "  'he',\n",
       "  'was',\n",
       "  'not',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'any',\n",
       "  'video',\n",
       "  'footage',\n",
       "  'from',\n",
       "  'on',\n",
       "  'board',\n",
       "  'the',\n",
       "  'plane',\n",
       "  '.'],\n",
       " ['marseille',\n",
       "  'prosecutor',\n",
       "  'brice',\n",
       "  'robin',\n",
       "  'told',\n",
       "  'cnn',\n",
       "  'that',\n",
       "  '``',\n",
       "  'so',\n",
       "  'far',\n",
       "  'no',\n",
       "  'videos',\n",
       "  'were',\n",
       "  'used',\n",
       "  'in',\n",
       "  'the',\n",
       "  'crash',\n",
       "  'investigation',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['he',\n",
       "  'added',\n",
       "  ',',\n",
       "  '``',\n",
       "  'a',\n",
       "  'person',\n",
       "  'who',\n",
       "  'has',\n",
       "  'such',\n",
       "  'a',\n",
       "  'video',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'immediately',\n",
       "  'give',\n",
       "  'it',\n",
       "  'to',\n",
       "  'the',\n",
       "  'investigators',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['robin',\n",
       "  \"'s\",\n",
       "  'comments',\n",
       "  'follow',\n",
       "  'claims',\n",
       "  'by',\n",
       "  'two',\n",
       "  'magazines',\n",
       "  ',',\n",
       "  'german',\n",
       "  'daily',\n",
       "  'bild',\n",
       "  'and',\n",
       "  'french',\n",
       "  'paris',\n",
       "  'match',\n",
       "  ',',\n",
       "  'of',\n",
       "  'a',\n",
       "  'cell',\n",
       "  'phone',\n",
       "  'video',\n",
       "  'showing',\n",
       "  'the',\n",
       "  'harrowing',\n",
       "  'final',\n",
       "  'seconds',\n",
       "  'from',\n",
       "  'on',\n",
       "  'board',\n",
       "  'germanwings',\n",
       "  'flight',\n",
       "  '9525',\n",
       "  'as',\n",
       "  'it',\n",
       "  'crashed',\n",
       "  'into',\n",
       "  'the',\n",
       "  'french',\n",
       "  'alps',\n",
       "  '.'],\n",
       " ['all', '150', 'on', 'board', 'were', 'killed', '.'],\n",
       " ['paris',\n",
       "  'match',\n",
       "  'and',\n",
       "  'bild',\n",
       "  'reported',\n",
       "  'that',\n",
       "  'the',\n",
       "  'video',\n",
       "  'was',\n",
       "  'recovered',\n",
       "  'from',\n",
       "  'a',\n",
       "  'phone',\n",
       "  'at',\n",
       "  'the',\n",
       "  'wreckage',\n",
       "  'site',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'two',\n",
       "  'publications',\n",
       "  'described',\n",
       "  'the',\n",
       "  'supposed',\n",
       "  'video',\n",
       "  ',',\n",
       "  'but',\n",
       "  'did',\n",
       "  'not',\n",
       "  'post',\n",
       "  'it',\n",
       "  'on',\n",
       "  'their',\n",
       "  'websites',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'publications',\n",
       "  'said',\n",
       "  'that',\n",
       "  'they',\n",
       "  'watched',\n",
       "  'the',\n",
       "  'video',\n",
       "  ',',\n",
       "  'which',\n",
       "  'was',\n",
       "  'found',\n",
       "  'by',\n",
       "  'a',\n",
       "  'source',\n",
       "  'close',\n",
       "  'to',\n",
       "  'the',\n",
       "  'investigation',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['one',\n",
       "  'can',\n",
       "  'hear',\n",
       "  'cries',\n",
       "  'of',\n",
       "  '`',\n",
       "  'my',\n",
       "  'god',\n",
       "  \"'\",\n",
       "  'in',\n",
       "  'several',\n",
       "  'languages',\n",
       "  ',',\n",
       "  '``',\n",
       "  'paris',\n",
       "  'match',\n",
       "  'reported',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['metallic',\n",
       "  'banging',\n",
       "  'can',\n",
       "  'also',\n",
       "  'be',\n",
       "  'heard',\n",
       "  'more',\n",
       "  'than',\n",
       "  'three',\n",
       "  'times',\n",
       "  ',',\n",
       "  'perhaps',\n",
       "  'of',\n",
       "  'the',\n",
       "  'pilot',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'open',\n",
       "  'the',\n",
       "  'cockpit',\n",
       "  'door',\n",
       "  'with',\n",
       "  'a',\n",
       "  'heavy',\n",
       "  'object',\n",
       "  '.'],\n",
       " ['towards',\n",
       "  'the',\n",
       "  'end',\n",
       "  ',',\n",
       "  'after',\n",
       "  'a',\n",
       "  'heavy',\n",
       "  'shake',\n",
       "  ',',\n",
       "  'stronger',\n",
       "  'than',\n",
       "  'the',\n",
       "  'others',\n",
       "  ',',\n",
       "  'the',\n",
       "  'screaming',\n",
       "  'intensifies',\n",
       "  '.'],\n",
       " ['then', 'nothing', '.', '``'],\n",
       " ['``',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'very',\n",
       "  'disturbing',\n",
       "  'scene',\n",
       "  ',',\n",
       "  '``',\n",
       "  'said',\n",
       "  'julian',\n",
       "  'reichelt',\n",
       "  ',',\n",
       "  'editor-in-chief',\n",
       "  'of',\n",
       "  'bild',\n",
       "  'online',\n",
       "  '.'],\n",
       " ['an',\n",
       "  'official',\n",
       "  'with',\n",
       "  'france',\n",
       "  \"'s\",\n",
       "  'accident',\n",
       "  'investigation',\n",
       "  'agency',\n",
       "  ',',\n",
       "  'the',\n",
       "  'bea',\n",
       "  ',',\n",
       "  'said',\n",
       "  'the',\n",
       "  'agency',\n",
       "  'is',\n",
       "  'not',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'any',\n",
       "  'such',\n",
       "  'video',\n",
       "  '.'],\n",
       " ['lt.',\n",
       "  'col.',\n",
       "  'jean-marc',\n",
       "  'menichini',\n",
       "  ',',\n",
       "  'a',\n",
       "  'french',\n",
       "  'gendarmerie',\n",
       "  'spokesman',\n",
       "  'in',\n",
       "  'charge',\n",
       "  'of',\n",
       "  'communications',\n",
       "  'on',\n",
       "  'rescue',\n",
       "  'efforts',\n",
       "  'around',\n",
       "  'the',\n",
       "  'germanwings',\n",
       "  'crash',\n",
       "  'site',\n",
       "  ',',\n",
       "  'told',\n",
       "  'cnn',\n",
       "  'that',\n",
       "  'the',\n",
       "  'reports',\n",
       "  'were',\n",
       "  '``',\n",
       "  'completely',\n",
       "  'wrong',\n",
       "  '``',\n",
       "  'and',\n",
       "  '``',\n",
       "  'unwarranted',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['cell',\n",
       "  'phones',\n",
       "  'have',\n",
       "  'been',\n",
       "  'collected',\n",
       "  'at',\n",
       "  'the',\n",
       "  'site',\n",
       "  ',',\n",
       "  'he',\n",
       "  'said',\n",
       "  ',',\n",
       "  'but',\n",
       "  'that',\n",
       "  'they',\n",
       "  '``',\n",
       "  'had',\n",
       "  \"n't\",\n",
       "  'been',\n",
       "  'exploited',\n",
       "  'yet',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['menichini',\n",
       "  'said',\n",
       "  'he',\n",
       "  'believed',\n",
       "  'the',\n",
       "  'cell',\n",
       "  'phones',\n",
       "  'would',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'sent',\n",
       "  'to',\n",
       "  'the',\n",
       "  'criminal',\n",
       "  'research',\n",
       "  'institute',\n",
       "  'in',\n",
       "  'rosny',\n",
       "  'sous-bois',\n",
       "  ',',\n",
       "  'near',\n",
       "  'paris',\n",
       "  ',',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'be',\n",
       "  'analyzed',\n",
       "  'by',\n",
       "  'specialized',\n",
       "  'technicians',\n",
       "  'working',\n",
       "  'hand-in-hand',\n",
       "  'with',\n",
       "  'investigators',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'none',\n",
       "  'of',\n",
       "  'the',\n",
       "  'cell',\n",
       "  'phones',\n",
       "  'found',\n",
       "  'so',\n",
       "  'far',\n",
       "  'have',\n",
       "  'been',\n",
       "  'sent',\n",
       "  'to',\n",
       "  'the',\n",
       "  'institute',\n",
       "  ',',\n",
       "  'menichini',\n",
       "  'said',\n",
       "  '.'],\n",
       " ['asked',\n",
       "  'whether',\n",
       "  'staff',\n",
       "  'involved',\n",
       "  'in',\n",
       "  'the',\n",
       "  'search',\n",
       "  'could',\n",
       "  'have',\n",
       "  'leaked',\n",
       "  'a',\n",
       "  'memory',\n",
       "  'card',\n",
       "  'to',\n",
       "  'the',\n",
       "  'media',\n",
       "  ',',\n",
       "  'menichini',\n",
       "  'answered',\n",
       "  'with',\n",
       "  'a',\n",
       "  'categorical',\n",
       "  '``',\n",
       "  'no',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['reichelt',\n",
       "  'told',\n",
       "  '``',\n",
       "  'erin',\n",
       "  'burnett',\n",
       "  ':',\n",
       "  'outfront',\n",
       "  '``',\n",
       "  'that',\n",
       "  'he',\n",
       "  'had',\n",
       "  'watched',\n",
       "  'the',\n",
       "  'video',\n",
       "  'and',\n",
       "  'stood',\n",
       "  'by',\n",
       "  'the',\n",
       "  'report',\n",
       "  ',',\n",
       "  'saying',\n",
       "  'bild',\n",
       "  'and',\n",
       "  'paris',\n",
       "  'match',\n",
       "  'are',\n",
       "  '``',\n",
       "  'very',\n",
       "  'confident',\n",
       "  '``',\n",
       "  'that',\n",
       "  'the',\n",
       "  'clip',\n",
       "  'is',\n",
       "  'real',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'noted',\n",
       "  'that',\n",
       "  'investigators',\n",
       "  'only',\n",
       "  'revealed',\n",
       "  'they',\n",
       "  \"'d\",\n",
       "  'recovered',\n",
       "  'cell',\n",
       "  'phones',\n",
       "  'from',\n",
       "  'the',\n",
       "  'crash',\n",
       "  'site',\n",
       "  'after',\n",
       "  'bild',\n",
       "  'and',\n",
       "  'paris',\n",
       "  'match',\n",
       "  'published',\n",
       "  'their',\n",
       "  'reports',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['that', 'is', 'something', 'we', 'did', 'not', 'know', 'before', '.'],\n",
       " ['...',\n",
       "  'overall',\n",
       "  'we',\n",
       "  'can',\n",
       "  'say',\n",
       "  'many',\n",
       "  'things',\n",
       "  'of',\n",
       "  'the',\n",
       "  'investigation',\n",
       "  'were',\n",
       "  \"n't\",\n",
       "  'revealed',\n",
       "  'by',\n",
       "  'the',\n",
       "  'investigation',\n",
       "  'at',\n",
       "  'the',\n",
       "  'beginning',\n",
       "  ',',\n",
       "  '``',\n",
       "  'he',\n",
       "  'said',\n",
       "  '.'],\n",
       " ['what', 'was', 'mental', 'state', 'of', 'germanwings', 'co-pilot', '?'],\n",
       " ['german',\n",
       "  'airline',\n",
       "  'lufthansa',\n",
       "  'confirmed',\n",
       "  'tuesday',\n",
       "  'that',\n",
       "  'co-pilot',\n",
       "  'andreas',\n",
       "  'lubitz',\n",
       "  'had',\n",
       "  'battled',\n",
       "  'depression',\n",
       "  'years',\n",
       "  'before',\n",
       "  'he',\n",
       "  'took',\n",
       "  'the',\n",
       "  'controls',\n",
       "  'of',\n",
       "  'germanwings',\n",
       "  'flight',\n",
       "  '9525',\n",
       "  ',',\n",
       "  'which',\n",
       "  'he',\n",
       "  \"'s\",\n",
       "  'accused',\n",
       "  'of',\n",
       "  'deliberately',\n",
       "  'crashing',\n",
       "  'last',\n",
       "  'week',\n",
       "  'in',\n",
       "  'the',\n",
       "  'french',\n",
       "  'alps',\n",
       "  '.'],\n",
       " ['lubitz',\n",
       "  'told',\n",
       "  'his',\n",
       "  'lufthansa',\n",
       "  'flight',\n",
       "  'training',\n",
       "  'school',\n",
       "  'in',\n",
       "  '2009',\n",
       "  'that',\n",
       "  'he',\n",
       "  'had',\n",
       "  'a',\n",
       "  '``',\n",
       "  'previous',\n",
       "  'episode',\n",
       "  'of',\n",
       "  'severe',\n",
       "  'depression',\n",
       "  ',',\n",
       "  '``',\n",
       "  'the',\n",
       "  'airline',\n",
       "  'said',\n",
       "  'tuesday',\n",
       "  '.'],\n",
       " ['email',\n",
       "  'correspondence',\n",
       "  'between',\n",
       "  'lubitz',\n",
       "  'and',\n",
       "  'the',\n",
       "  'school',\n",
       "  'discovered',\n",
       "  'in',\n",
       "  'an',\n",
       "  'internal',\n",
       "  'investigation',\n",
       "  ',',\n",
       "  'lufthansa',\n",
       "  'said',\n",
       "  ',',\n",
       "  'included',\n",
       "  'medical',\n",
       "  'documents',\n",
       "  'he',\n",
       "  'submitted',\n",
       "  'in',\n",
       "  'connection',\n",
       "  'with',\n",
       "  'resuming',\n",
       "  'his',\n",
       "  'flight',\n",
       "  'training',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'announcement',\n",
       "  'indicates',\n",
       "  'that',\n",
       "  'lufthansa',\n",
       "  ',',\n",
       "  'the',\n",
       "  'parent',\n",
       "  'company',\n",
       "  'of',\n",
       "  'germanwings',\n",
       "  ',',\n",
       "  'knew',\n",
       "  'of',\n",
       "  'lubitz',\n",
       "  \"'s\",\n",
       "  'battle',\n",
       "  'with',\n",
       "  'depression',\n",
       "  ',',\n",
       "  'allowed',\n",
       "  'him',\n",
       "  'to',\n",
       "  'continue',\n",
       "  'training',\n",
       "  'and',\n",
       "  'ultimately',\n",
       "  'put',\n",
       "  'him',\n",
       "  'in',\n",
       "  'the',\n",
       "  'cockpit',\n",
       "  '.'],\n",
       " ['lufthansa',\n",
       "  ',',\n",
       "  'whose',\n",
       "  'ceo',\n",
       "  'carsten',\n",
       "  'spohr',\n",
       "  'previously',\n",
       "  'said',\n",
       "  'lubitz',\n",
       "  'was',\n",
       "  '100',\n",
       "  '%',\n",
       "  'fit',\n",
       "  'to',\n",
       "  'fly',\n",
       "  ',',\n",
       "  'described',\n",
       "  'its',\n",
       "  'statement',\n",
       "  'tuesday',\n",
       "  'as',\n",
       "  'a',\n",
       "  '``',\n",
       "  'swift',\n",
       "  'and',\n",
       "  'seamless',\n",
       "  'clarification',\n",
       "  '``',\n",
       "  'and',\n",
       "  'said',\n",
       "  'it',\n",
       "  'was',\n",
       "  'sharing',\n",
       "  'the',\n",
       "  'information',\n",
       "  'and',\n",
       "  'documents',\n",
       "  '--',\n",
       "  'including',\n",
       "  'training',\n",
       "  'and',\n",
       "  'medical',\n",
       "  'records',\n",
       "  '--',\n",
       "  'with',\n",
       "  'public',\n",
       "  'prosecutors',\n",
       "  '.'],\n",
       " ['spohr',\n",
       "  'traveled',\n",
       "  'to',\n",
       "  'the',\n",
       "  'crash',\n",
       "  'site',\n",
       "  'wednesday',\n",
       "  ',',\n",
       "  'where',\n",
       "  'recovery',\n",
       "  'teams',\n",
       "  'have',\n",
       "  'been',\n",
       "  'working',\n",
       "  'for',\n",
       "  'the',\n",
       "  'past',\n",
       "  'week',\n",
       "  'to',\n",
       "  'recover',\n",
       "  'human',\n",
       "  'remains',\n",
       "  'and',\n",
       "  'plane',\n",
       "  'debris',\n",
       "  'scattered',\n",
       "  'across',\n",
       "  'a',\n",
       "  'steep',\n",
       "  'mountainside',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'saw',\n",
       "  'the',\n",
       "  'crisis',\n",
       "  'center',\n",
       "  'set',\n",
       "  'up',\n",
       "  'in',\n",
       "  'seyne-les-alpes',\n",
       "  ',',\n",
       "  'laid',\n",
       "  'a',\n",
       "  'wreath',\n",
       "  'in',\n",
       "  'the',\n",
       "  'village',\n",
       "  'of',\n",
       "  'le',\n",
       "  'vernet',\n",
       "  ',',\n",
       "  'closer',\n",
       "  'to',\n",
       "  'the',\n",
       "  'crash',\n",
       "  'site',\n",
       "  ',',\n",
       "  'where',\n",
       "  'grieving',\n",
       "  'families',\n",
       "  'have',\n",
       "  'left',\n",
       "  'flowers',\n",
       "  'at',\n",
       "  'a',\n",
       "  'simple',\n",
       "  'stone',\n",
       "  'memorial',\n",
       "  '.'],\n",
       " ['menichini',\n",
       "  'told',\n",
       "  'cnn',\n",
       "  'late',\n",
       "  'tuesday',\n",
       "  'that',\n",
       "  'no',\n",
       "  'visible',\n",
       "  'human',\n",
       "  'remains',\n",
       "  'were',\n",
       "  'left',\n",
       "  'at',\n",
       "  'the',\n",
       "  'site',\n",
       "  'but',\n",
       "  'recovery',\n",
       "  'teams',\n",
       "  'would',\n",
       "  'keep',\n",
       "  'searching',\n",
       "  '.'],\n",
       " ['french',\n",
       "  'president',\n",
       "  'francois',\n",
       "  'hollande',\n",
       "  ',',\n",
       "  'speaking',\n",
       "  'tuesday',\n",
       "  ',',\n",
       "  'said',\n",
       "  'that',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'possible',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'all',\n",
       "  'the',\n",
       "  'victims',\n",
       "  'using',\n",
       "  'dna',\n",
       "  'analysis',\n",
       "  'by',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'week',\n",
       "  ',',\n",
       "  'sooner',\n",
       "  'than',\n",
       "  'authorities',\n",
       "  'had',\n",
       "  'previously',\n",
       "  'suggested',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'meantime',\n",
       "  ',',\n",
       "  'the',\n",
       "  'recovery',\n",
       "  'of',\n",
       "  'the',\n",
       "  'victims',\n",
       "  \"'\",\n",
       "  'personal',\n",
       "  'belongings',\n",
       "  'will',\n",
       "  'start',\n",
       "  'wednesday',\n",
       "  ',',\n",
       "  'menichini',\n",
       "  'said',\n",
       "  '.'],\n",
       " ['among',\n",
       "  'those',\n",
       "  'personal',\n",
       "  'belongings',\n",
       "  'could',\n",
       "  'be',\n",
       "  'more',\n",
       "  'cell',\n",
       "  'phones',\n",
       "  'belonging',\n",
       "  'to',\n",
       "  'the',\n",
       "  '144',\n",
       "  'passengers',\n",
       "  'and',\n",
       "  'six',\n",
       "  'crew',\n",
       "  'on',\n",
       "  'board',\n",
       "  '.'],\n",
       " ['check', 'out', 'the', 'latest', 'from', 'our', 'correspondents', '.'],\n",
       " ['the',\n",
       "  'details',\n",
       "  'about',\n",
       "  'lubitz',\n",
       "  \"'s\",\n",
       "  'correspondence',\n",
       "  'with',\n",
       "  'the',\n",
       "  'flight',\n",
       "  'school',\n",
       "  'during',\n",
       "  'his',\n",
       "  'training',\n",
       "  'were',\n",
       "  'among',\n",
       "  'several',\n",
       "  'developments',\n",
       "  'as',\n",
       "  'investigators',\n",
       "  'continued',\n",
       "  'to',\n",
       "  'delve',\n",
       "  'into',\n",
       "  'what',\n",
       "  'caused',\n",
       "  'the',\n",
       "  'crash',\n",
       "  'and',\n",
       "  'lubitz',\n",
       "  \"'s\",\n",
       "  'possible',\n",
       "  'motive',\n",
       "  'for',\n",
       "  'downing',\n",
       "  'the',\n",
       "  'jet',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'lufthansa',\n",
       "  'spokesperson',\n",
       "  'told',\n",
       "  'cnn',\n",
       "  'on',\n",
       "  'tuesday',\n",
       "  'that',\n",
       "  'lubitz',\n",
       "  'had',\n",
       "  'a',\n",
       "  'valid',\n",
       "  'medical',\n",
       "  'certificate',\n",
       "  ',',\n",
       "  'had',\n",
       "  'passed',\n",
       "  'all',\n",
       "  'his',\n",
       "  'examinations',\n",
       "  'and',\n",
       "  '``',\n",
       "  'held',\n",
       "  'all',\n",
       "  'the',\n",
       "  'licenses',\n",
       "  'required',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['earlier',\n",
       "  ',',\n",
       "  'a',\n",
       "  'spokesman',\n",
       "  'for',\n",
       "  'the',\n",
       "  'prosecutor',\n",
       "  \"'s\",\n",
       "  'office',\n",
       "  'in',\n",
       "  'dusseldorf',\n",
       "  ',',\n",
       "  'christoph',\n",
       "  'kumpa',\n",
       "  ',',\n",
       "  'said',\n",
       "  'medical',\n",
       "  'records',\n",
       "  'reveal',\n",
       "  'lubitz',\n",
       "  'suffered',\n",
       "  'from',\n",
       "  'suicidal',\n",
       "  'tendencies',\n",
       "  'at',\n",
       "  'some',\n",
       "  'point',\n",
       "  'before',\n",
       "  'his',\n",
       "  'aviation',\n",
       "  'career',\n",
       "  'and',\n",
       "  'underwent',\n",
       "  'psychotherapy',\n",
       "  'before',\n",
       "  'he',\n",
       "  'got',\n",
       "  'his',\n",
       "  'pilot',\n",
       "  \"'s\",\n",
       "  'license',\n",
       "  '.'],\n",
       " ['kumpa',\n",
       "  'emphasized',\n",
       "  'there',\n",
       "  \"'s\",\n",
       "  'no',\n",
       "  'evidence',\n",
       "  'suggesting',\n",
       "  'lubitz',\n",
       "  'was',\n",
       "  'suicidal',\n",
       "  'or',\n",
       "  'acting',\n",
       "  'aggressively',\n",
       "  'before',\n",
       "  'the',\n",
       "  'crash',\n",
       "  '.'],\n",
       " ['investigators',\n",
       "  'are',\n",
       "  'looking',\n",
       "  'into',\n",
       "  'whether',\n",
       "  'lubitz',\n",
       "  'feared',\n",
       "  'his',\n",
       "  'medical',\n",
       "  'condition',\n",
       "  'would',\n",
       "  'cause',\n",
       "  'him',\n",
       "  'to',\n",
       "  'lose',\n",
       "  'his',\n",
       "  'pilot',\n",
       "  \"'s\",\n",
       "  'license',\n",
       "  ',',\n",
       "  'a',\n",
       "  'european',\n",
       "  'government',\n",
       "  'official',\n",
       "  'briefed',\n",
       "  'on',\n",
       "  'the',\n",
       "  'investigation',\n",
       "  'told',\n",
       "  'cnn',\n",
       "  'on',\n",
       "  'tuesday',\n",
       "  '.'],\n",
       " ['while',\n",
       "  'flying',\n",
       "  'was',\n",
       "  '``',\n",
       "  'a',\n",
       "  'big',\n",
       "  'part',\n",
       "  'of',\n",
       "  'his',\n",
       "  'life',\n",
       "  ',',\n",
       "  '``',\n",
       "  'the',\n",
       "  'source',\n",
       "  'said',\n",
       "  ',',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'only',\n",
       "  'one',\n",
       "  'theory',\n",
       "  'being',\n",
       "  'considered',\n",
       "  '.'],\n",
       " ['another',\n",
       "  'source',\n",
       "  ',',\n",
       "  'a',\n",
       "  'law',\n",
       "  'enforcement',\n",
       "  'official',\n",
       "  'briefed',\n",
       "  'on',\n",
       "  'the',\n",
       "  'investigation',\n",
       "  ',',\n",
       "  'also',\n",
       "  'told',\n",
       "  'cnn',\n",
       "  'that',\n",
       "  'authorities',\n",
       "  'believe',\n",
       "  'the',\n",
       "  'primary',\n",
       "  'motive',\n",
       "  'for',\n",
       "  'lubitz',\n",
       "  'to',\n",
       "  'bring',\n",
       "  'down',\n",
       "  'the',\n",
       "  'plane',\n",
       "  'was',\n",
       "  'that',\n",
       "  'he',\n",
       "  'feared',\n",
       "  'he',\n",
       "  'would',\n",
       "  'not',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'fly',\n",
       "  'because',\n",
       "  'of',\n",
       "  'his',\n",
       "  'medical',\n",
       "  'problems',\n",
       "  '.'],\n",
       " ['lubitz',\n",
       "  \"'s\",\n",
       "  'girlfriend',\n",
       "  'told',\n",
       "  'investigators',\n",
       "  'he',\n",
       "  'had',\n",
       "  'seen',\n",
       "  'an',\n",
       "  'eye',\n",
       "  'doctor',\n",
       "  'and',\n",
       "  'a',\n",
       "  'neuropsychologist',\n",
       "  ',',\n",
       "  'both',\n",
       "  'of',\n",
       "  'whom',\n",
       "  'deemed',\n",
       "  'him',\n",
       "  'unfit',\n",
       "  'to',\n",
       "  'work',\n",
       "  'recently',\n",
       "  'and',\n",
       "  'concluded',\n",
       "  'he',\n",
       "  'had',\n",
       "  'psychological',\n",
       "  'issues',\n",
       "  ',',\n",
       "  'the',\n",
       "  'european',\n",
       "  'government',\n",
       "  'official',\n",
       "  'said',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'no',\n",
       "  'matter',\n",
       "  'what',\n",
       "  'details',\n",
       "  'emerge',\n",
       "  'about',\n",
       "  'his',\n",
       "  'previous',\n",
       "  'mental',\n",
       "  'health',\n",
       "  'struggles',\n",
       "  ',',\n",
       "  'there',\n",
       "  \"'s\",\n",
       "  'more',\n",
       "  'to',\n",
       "  'the',\n",
       "  'story',\n",
       "  ',',\n",
       "  'said',\n",
       "  'brian',\n",
       "  'russell',\n",
       "  ',',\n",
       "  'a',\n",
       "  'forensic',\n",
       "  'psychologist',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['psychology',\n",
       "  'can',\n",
       "  'explain',\n",
       "  'why',\n",
       "  'somebody',\n",
       "  'would',\n",
       "  'turn',\n",
       "  'rage',\n",
       "  'inward',\n",
       "  'on',\n",
       "  'themselves',\n",
       "  'about',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'maybe',\n",
       "  'they',\n",
       "  'were',\n",
       "  \"n't\",\n",
       "  'going',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'doing',\n",
       "  'their',\n",
       "  'job',\n",
       "  'and',\n",
       "  'they',\n",
       "  \"'re\",\n",
       "  'upset',\n",
       "  'about',\n",
       "  'that',\n",
       "  'and',\n",
       "  'so',\n",
       "  'they',\n",
       "  \"'re\",\n",
       "  'suicidal',\n",
       "  ',',\n",
       "  '``',\n",
       "  'he',\n",
       "  'said',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['but',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'mental',\n",
       "  'illness',\n",
       "  'that',\n",
       "  'explains',\n",
       "  'why',\n",
       "  'somebody',\n",
       "  'then',\n",
       "  'feels',\n",
       "  'entitled',\n",
       "  'to',\n",
       "  'also',\n",
       "  'take',\n",
       "  'that',\n",
       "  'rage',\n",
       "  'and',\n",
       "  'turn',\n",
       "  'it',\n",
       "  'outward',\n",
       "  'on',\n",
       "  '149',\n",
       "  'other',\n",
       "  'people',\n",
       "  'who',\n",
       "  'had',\n",
       "  'nothing',\n",
       "  'to',\n",
       "  'do',\n",
       "  'with',\n",
       "  'the',\n",
       "  'person',\n",
       "  \"'s\",\n",
       "  'problems',\n",
       "  '.',\n",
       "  '``'],\n",
       " ['germanwings', 'crash', 'compensation', ':', 'what', 'we', 'know', '.'],\n",
       " ['who', 'was', 'the', 'captain', 'of', 'germanwings', 'flight', '9525', '?'],\n",
       " ['cnn',\n",
       "  \"'s\",\n",
       "  'margot',\n",
       "  'haddad',\n",
       "  'reported',\n",
       "  'from',\n",
       "  'marseille',\n",
       "  'and',\n",
       "  'pamela',\n",
       "  'brown',\n",
       "  'from',\n",
       "  'dusseldorf',\n",
       "  ',',\n",
       "  'while',\n",
       "  'laura',\n",
       "  'smith-spark',\n",
       "  'wrote',\n",
       "  'from',\n",
       "  'london',\n",
       "  '.'],\n",
       " ['cnn',\n",
       "  \"'s\",\n",
       "  'frederik',\n",
       "  'pleitgen',\n",
       "  ',',\n",
       "  'pamela',\n",
       "  'boykoff',\n",
       "  ',',\n",
       "  'antonia',\n",
       "  'mortensen',\n",
       "  ',',\n",
       "  'sandrine',\n",
       "  'amiel',\n",
       "  'and',\n",
       "  'anna-maja',\n",
       "  'rappard',\n",
       "  'contributed',\n",
       "  'to',\n",
       "  'this',\n",
       "  'report',\n",
       "  '.']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"\"\"\n",
    "from utils_nlp.dataset.cnndm import CNNDMSummarization\n",
    "\n",
    "train_dataset, test_dataset = CNNDMSummarization(top_n=5)\n",
    "\n",
    "len(train_dataset)\n",
    "\n",
    "len(test_dataset)\n",
    "\n",
    "test_dataset[0]\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1026 04:15:41.799360 140372391651136 file_utils.py:39] PyTorch version 1.2.0 available.\n",
      "I1026 04:15:41.833203 140372391651136 modeling_xlnet.py:194] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I1026 04:15:41.849030 140372391651136 modeling.py:230] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "from utils_nlp.models.transformers.extractive_summarization import ExtSumProcessor, ExtractiveSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1026 04:15:42.053747 140372391651136 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at ./5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "processor = ExtSumProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "ext_sum_train = processor.preprocess(list(train_dataset), list(train_dataset.get_target()))\n",
    "\n",
    "ext_sum_test = processor.preprocess(list(test_dataset), list(test_dataset.get_target()))\n",
    "\n",
    "#type(ext_sum_train)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "BERT_DATA_PATH = BERT_DATA_PATH=\"./bert_data/\"\n",
    "pts = sorted(glob.glob(BERT_DATA_PATH + 'cnndm.train' + '.[0-9]*.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./bert_data/cnndm.train.0.bert.pt', './bert_data/cnndm.train.1.bert.pt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def get_dataset(file_list):\n",
    "    #random.shuffle(file_list)\n",
    "    for file in file_list:\n",
    "        yield torch.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertsum.models.data_loader  import DataIterator\n",
    "from bertsum.models import  model_builder, data_loader\n",
    "class Bunch(object):\n",
    "    \"\"\" Class which convert a dictionary to an object \"\"\"\n",
    "\n",
    "    def __init__(self, adict):\n",
    "        self.__dict__.update(adict)\n",
    "def get_data_loader(data_files, device, is_labeled=False, batch_size=3000):\n",
    "    \"\"\"\n",
    "    Function to get data iterator over a list of data objects.\n",
    "\n",
    "    Args:\n",
    "        dataset (list of objects): a list of data objects.\n",
    "        is_test (bool): it specifies whether the data objects are labeled data.\n",
    "        batch_size (int): number of tokens per batch.\n",
    "        \n",
    "    Returns:\n",
    "        DataIterator\n",
    "\n",
    "    \"\"\"\n",
    "    args = Bunch({})\n",
    "    args.use_interval = True\n",
    "    args.batch_size = batch_size\n",
    "    data_iter = None\n",
    "    data_iter  = data_loader.Dataloader(args, get_dataset(data_files), args.batch_size,device, shuffle=False, is_test=is_labeled)\n",
    "    return data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:{}\".format(0)) \n",
    "def train_iter_func():\n",
    "    return get_data_loader(pts, device, is_labeled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1026 04:15:42.579849 140372391651136 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at ./a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.1ccd1a11c9ff276830e114ea477ea2407100f4a3be7bdc45d37be9e37fa71c7e\n",
      "I1026 04:15:42.581028 140372391651136 configuration_utils.py:168] Model config {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1026 04:15:42.699048 140372391651136 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin from cache at ./7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedModel,  PretrainedConfig, DistilBertModel, BertModel, DistilBertConfig\n",
    "summarizer = None\n",
    "summarizer = ExtractiveSummarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook parameters\n",
    "DATA_FOLDER = \"./temp\"\n",
    "CACHE_DIR = \"./temp\"\n",
    "DEVICE = \"cuda\"\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "NUM_GPUS = 1\n",
    "MAX_LEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.468674, time: 0.35, step 0.000000 out of total 10000.000000\n",
      "loss: 49.510865, time: 12.12, step 100.000000 out of total 10000.000000\n",
      "loss: 50.368191, time: 11.75, step 200.000000 out of total 10000.000000\n",
      "loss: 51.135715, time: 11.72, step 300.000000 out of total 10000.000000\n",
      "loss: 50.651170, time: 12.08, step 400.000000 out of total 10000.000000\n",
      "loss: 49.099066, time: 11.69, step 500.000000 out of total 10000.000000\n",
      "loss: 49.710841, time: 11.70, step 600.000000 out of total 10000.000000\n",
      "loss: 50.249900, time: 11.67, step 700.000000 out of total 10000.000000\n",
      "loss: 50.779532, time: 12.02, step 800.000000 out of total 10000.000000\n",
      "loss: 49.899698, time: 11.74, step 900.000000 out of total 10000.000000\n",
      "loss: 49.757523, time: 11.90, step 1000.000000 out of total 10000.000000\n",
      "loss: 49.934256, time: 11.73, step 1100.000000 out of total 10000.000000\n",
      "loss: 50.296925, time: 12.03, step 1200.000000 out of total 10000.000000\n",
      "loss: 49.834056, time: 11.74, step 1300.000000 out of total 10000.000000\n",
      "loss: 50.779539, time: 11.66, step 1400.000000 out of total 10000.000000\n",
      "loss: 50.480450, time: 11.65, step 1500.000000 out of total 10000.000000\n",
      "loss: 50.691425, time: 12.04, step 1600.000000 out of total 10000.000000\n",
      "loss: 49.424853, time: 11.63, step 1700.000000 out of total 10000.000000\n",
      "loss: 48.981549, time: 11.63, step 1800.000000 out of total 10000.000000\n",
      "loss: 49.660170, time: 11.62, step 1900.000000 out of total 10000.000000\n",
      "loss: 50.527066, time: 11.98, step 2000.000000 out of total 10000.000000\n",
      "loss: 50.611742, time: 12.13, step 2100.000000 out of total 10000.000000\n",
      "loss: 49.533881, time: 11.61, step 2200.000000 out of total 10000.000000\n",
      "loss: 50.405275, time: 11.57, step 2300.000000 out of total 10000.000000\n",
      "loss: 51.558690, time: 12.03, step 2400.000000 out of total 10000.000000\n",
      "loss: 50.927835, time: 11.88, step 2500.000000 out of total 10000.000000\n",
      "loss: 48.684750, time: 12.09, step 2600.000000 out of total 10000.000000\n",
      "loss: 51.471593, time: 12.10, step 2700.000000 out of total 10000.000000\n",
      "loss: 50.115394, time: 12.23, step 2800.000000 out of total 10000.000000\n",
      "loss: 50.202430, time: 11.97, step 2900.000000 out of total 10000.000000\n",
      "loss: 48.978926, time: 12.18, step 3000.000000 out of total 10000.000000\n",
      "loss: 50.624867, time: 12.00, step 3100.000000 out of total 10000.000000\n",
      "loss: 50.878479, time: 12.12, step 3200.000000 out of total 10000.000000\n",
      "loss: 50.980690, time: 11.63, step 3300.000000 out of total 10000.000000\n",
      "loss: 49.794728, time: 12.20, step 3400.000000 out of total 10000.000000\n",
      "loss: 50.396956, time: 12.11, step 3500.000000 out of total 10000.000000\n",
      "loss: 50.533176, time: 12.28, step 3600.000000 out of total 10000.000000\n",
      "loss: 50.699350, time: 12.13, step 3700.000000 out of total 10000.000000\n"
     ]
    }
   ],
   "source": [
    "### from utils_nlp.common.timer import Timer\n",
    "\n",
    "    summarizer.fit(\n",
    "            train_iter_func,\n",
    "            device= DEVICE,\n",
    "            num_epochs=NUM_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_gpus=NUM_GPUS,\n",
    "            max_steps=1e4,\n",
    "            learning_rate=1e-3,\n",
    "            warmup_steps=1e4*0.3,\n",
    "            verbose=True,\n",
    "            report_every=100,\n",
    "        )\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils_nlp.models.bert.extractive_text_summarization import get_data_iter\n",
    "import os\n",
    "\n",
    "test_dataset=[]\n",
    "for i in range(0,6):\n",
    "    filename = os.path.join(BERT_DATA_PATH, \"cnndm.test.{0}.bert.pt\".format(i))\n",
    "    test_dataset.extend(torch.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = summarizer.predict(get_data_iter(test_dataset),\n",
    "                               device=DEVICE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [test_dataset[i]['tgt_txt'] for i in range(len(test_dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_nlp.eval.evaluate_summarization import get_rouge\n",
    "rouge_baseline = get_rouge(prediction, target, \"./results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[0]['tgt_txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6 cm3",
   "language": "python",
   "name": "cm3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
