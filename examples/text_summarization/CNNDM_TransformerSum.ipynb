{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive Summarization on CNN/DM Dataset using Transformer Version of BertSum\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "This notebook demonstrates how to fine tune Transformers for extractive text summarization. Utility functions and classes in the NLP Best Practices repo are used to facilitate data preprocessing, model training, model scoring, result postprocessing, and model evaluation.\n",
    "\n",
    "BertSum refers to  [Fine-tune BERT for Extractive Summarization (https://arxiv.org/pdf/1903.10318.pdf) with [published example](https://github.com/nlpyang/BertSum/). And the Transformer version of Bertsum refers to our modification of BertSum and the source code can be accessed at (https://github.com/daden-ms/BertSum/). \n",
    "\n",
    "Extractive summarization are usually used in document summarization where each input document consists of mutiple sentences. The preprocessing of the input training data involves assigning label 0 or 1 to the document sentences based on the give summary. The summarization problem is also simplfied to classifying whether each document sentence should be included in the summary. \n",
    "\n",
    "The figure below illustrates how BERTSum can be fine tuned for extractive summarization task. Each sentence is inserted with [CLS] token at the beginning and  [SEP] at the end. Interval segment embedding and positional embedding are added upon the token embedding before input the BERT model. The [CLS] token representation is used as sentence embedding and only the [CLS] tokens are used as input for the summarization model. The summarization layer predicts whether the probability of each each sentence token should be included in the summary or not. Techniques like trigram blocking can be used to improve model accuarcy.   \n",
    "\n",
    "<img src=\"https://nlpbp.blob.core.windows.net/images/BertSum.PNG\">\n",
    "\n",
    "\n",
    "### Before You Start\n",
    "\n",
    "The running time shown in this notebook is on a Standard_NC24s_v3 Azure Deep Learning Virtual Machine with 4 NVIDIA Tesla V100 GPUs. \n",
    "> **Tip**: If you want to run through the notebook quickly, you can set the **`QUICK_RUN`** flag in the cell below to **`True`** to run the notebook on a small subset of the data and a smaller number of epochs. \n",
    "\n",
    "On a machine with 1 NVIDIA Tesla V100 GPUs, 16GB GPU memory configuration,\n",
    "- for data preprocessing, it takes around 10 minutes the data preprocessing for quick run. Otherwise it takes ~2 hours to finish the data preprocessing. This time estimation assumes the chosen transformer model is \"distilbert-base-uncased\" and the sentence selection method is \"greedy\", which is the default. The preprocessing time can be significantly longer if the sentence selection method is \"combination\", which can achieve better model performance.\n",
    "\n",
    "- for model fine tuning, it takes around 30 minutes for quick run. Otherwise, it takes around ~3 hours to finish. This estimation assume the chosen encoder method is \"transformer\". The model fine tuning time can be shorter if other encoder method is chosen, which may result in worse model performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set QUICK_RUN = True to run the notebook on a small subset of data and a smaller number of epochs.\n",
    "QUICK_RUN = True\n",
    "## Set USE_PREPROCSSED_DATA = True to skip the data preprocessing\n",
    "USE_PREPROCSSED_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Before we start the notebook, we should set the environment variable to make sure you can access the GPUs on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daden/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "I1213 03:39:34.879140 139876939843392 file_utils.py:39] PyTorch version 1.2.0 available.\n",
      "I1213 03:39:34.914063 139876939843392 modeling_xlnet.py:194] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I1213 03:39:34.929385 139876939843392 modeling.py:230] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch\n",
    "\n",
    "nlp_path = os.path.abspath(\"../../\")\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "\n",
    "from utils_nlp.common.pytorch_utils import get_device\n",
    "from utils_nlp.dataset.cnndm import CNNDMBertSumProcessedData, CNNDMSummarization\n",
    "from utils_nlp.eval.evaluate_summarization import get_rouge\n",
    "from utils_nlp.models.transformers.extractive_summarization import (\n",
    "    get_cycled_dataset,\n",
    "    get_dataloader,\n",
    "    get_sequential_dataloader,\n",
    "    ExtractiveSummarizer,\n",
    "    ExtSumProcessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration: choose the transformer model to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model being used\n",
    "MODEL_NAME = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we need to install the dependencies for pyrouge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dependencies for ROUGE-1.5.5.pl\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install expat\n",
    "!sudo apt-get install libexpat-dev -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command in your terminal to install pre-requiste for using pyrouge.\n",
    "1. sudo cpan install XML::Parser\n",
    "1. sudo cpan install XML::Parser::PerlSAX\n",
    "1. sudo cpan install XML::DOM\n",
    "\n",
    "Download ROUGE-1.5.5 from https://github.com/andersjo/pyrouge/tree/master/tools/ROUGE-1.5.5.\n",
    "Run the following command in your terminal.\n",
    "* pyrouge_set_rouge_path $ABSOLUTE_DIRECTORY_TO_ROUGE-1.5.5.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprossing\n",
    "\n",
    "The dataset we used for this notebook is CNN/DM dataset which contains the documents and accompanying questions from the news articles of CNN and Daily mail. The highlights in each article are used as summary. The dataset consits of ~289K training examples, ~11K valiation and ~11K test dataset.  You can choose the [Option 1] below preprocess the data or [Option 2] to use the preprocessed version at [BERTSum published example](https://github.com/nlpyang/BertSum/). You don't need to manually download any of these two data sets as the code below will handle this part.  Since it takes up to 28 hours to preprocess the training data  to run on 10  Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz, we suggest you continue with set as True first and experiment with data preprocessing  with QUICKRUN set as True.\n",
    "\n",
    "##### Details of Data Preprocessing\n",
    "\n",
    "The purpose of preprocessing is to process the input articles to the format that BertSum takes.  Functions defined specific in harvardnlp_cnndm_preprocess function are unique to CNN/DM dataset that's processed by harvardnlp. However, it provides a skeleton of how to preprocessing data into the format that BertSum takes. Assuming you have all articles and target summery each in a file, line-breaker seperated, the steps to preprocess the data are:\n",
    "1. sentence tokenization\n",
    "2. word tokenization\n",
    "3. **label** the sentences in the article with 1 meaning the sentence is selected and 0 meaning the sentence is not selected. The options for the selection algorithms are \"greedy\" and \"combination\"\n",
    "3. convert each example to  BertSum format\n",
    "    - filter the sentences in the example based on the min_src_ntokens argument. If the lefted total sentence number is less than min_nsents, the example is discarded.\n",
    "    - truncate the sentences in the example if the length is greater than max_src_ntokens\n",
    "    - truncate the sentences in the example and the labels if the totle number of sentences is greater than max_nsents\n",
    "    - [CLS] and [SEP] are inserted before and after each sentence\n",
    "    - wordPiece tokenization\n",
    "    - truncate the example to 512 tokens\n",
    "    - convert the tokens into token indices corresponding to the BERT tokenizer's vocabulary.\n",
    "    - segment ids are generated\n",
    "    - [CLS] token positions are logged\n",
    "    - [CLS] token labels are truncated if it's greater than 512, which is the maximum input length that can be taken by the BERT model.\n",
    "    \n",
    "    \n",
    "Note that the original BERTSum paper use Stanford CoreNLP for data proprocessing, here we'll first how to use NLTK version, and then we also provide instruction of how to set up Stanford NLP and code examples of how to use Standford CoreNLP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Option 1] Preprocess  data\n",
    "The code in following cell will download the CNN/DM dataset listed at https://github.com/harvardnlp/sent-summary/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data path used to save the downloaded data file\n",
    "DATA_PATH = TemporaryDirectory().name\n",
    "# The number of lines at the head of data file used for preprocessing. -1 means all the lines.\n",
    "TOP_N = -1\n",
    "if QUICK_RUN:\n",
    "    TOP_N = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1213 03:55:05.144305 139876939843392 utils.py:173] Opening tar file /tmp/tmppp95fw67/cnndm.tar.gz.\n",
      "I1213 03:55:05.146239 139876939843392 utils.py:181] /tmp/tmppp95fw67/test.txt.src already extracted.\n",
      "I1213 03:55:05.440092 139876939843392 utils.py:181] /tmp/tmppp95fw67/test.txt.tgt.tagged already extracted.\n",
      "I1213 03:55:05.467360 139876939843392 utils.py:181] /tmp/tmppp95fw67/train.txt.src already extracted.\n",
      "I1213 03:55:12.985301 139876939843392 utils.py:181] /tmp/tmppp95fw67/train.txt.tgt.tagged already extracted.\n",
      "I1213 03:55:13.605381 139876939843392 utils.py:181] /tmp/tmppp95fw67/val.txt.src already extracted.\n",
      "I1213 03:55:13.941435 139876939843392 utils.py:181] /tmp/tmppp95fw67/val.txt.tgt.tagged already extracted.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = CNNDMSummarization(top_n=TOP_N, local_cache_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data and save the data to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1213 03:55:16.914798 139876939843392 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_nsents': 200, 'max_src_ntokens': 2000, 'min_nsents': 3, 'min_src_ntokens': 5, 'use_interval': True}\n"
     ]
    }
   ],
   "source": [
    "processor = ExtSumProcessor(model_name=MODEL_NAME)\n",
    "ext_sum_train = processor.preprocess(train_dataset, train_dataset.get_target())\n",
    "ext_sum_test = processor.preprocess(test_dataset, test_dataset.get_target())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(DATA_PATH, \"processed\")\n",
    "train_files = CNNDMBertSumProcessedData.save_data(\n",
    "    ext_sum_train, is_test=False, save_path=save_path, chunk_size=2000\n",
    ")\n",
    "test_files = CNNDMBertSumProcessedData.save_data(\n",
    "    ext_sum_test, is_test=True, save_path=save_path, chunk_size=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmppp95fw67/processed/0_train',\n",
       " '/tmp/tmppp95fw67/processed/1_train',\n",
       " '/tmp/tmppp95fw67/processed/2_train',\n",
       " '/tmp/tmppp95fw67/processed/3_train',\n",
       " '/tmp/tmppp95fw67/processed/4_train']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmppp95fw67/processed/0_test',\n",
       " '/tmp/tmppp95fw67/processed/1_test',\n",
       " '/tmp/tmppp95fw67/processed/2_test',\n",
       " '/tmp/tmppp95fw67/processed/3_test',\n",
       " '/tmp/tmppp95fw67/processed/4_test']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_generator, test_dataset_generator = CNNDMBertSumProcessedData().splits(root=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['src', 'labels', 'segs', 'clss', 'src_txt', 'tgt_txt'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "bert_format_data = torch.load(train_files[0])\n",
    "print(len(bert_format_data))\n",
    "bert_format_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_format_data[0]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Option 2] Reuse Preprocessed  data from [BERTSUM Repo](https://github.com/nlpyang/BertSum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data path used to downloaded the preprocessed data from BERTSUM Repo.\n",
    "# if you have downloaded the dataset, change the code to use that path where the dataset is.\n",
    "PROCESSED_DATA_PATH = TemporaryDirectory().name\n",
    "#data_path = \"./temp_data5/\"\n",
    "#PROCESSED_DATA_PATH = data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_PREPROCSSED_DATA:\n",
    "    CNNDMBertSumProcessedData.download(local_path=PROCESSED_DATA_PATH)\n",
    "    train_dataset_generator, test_dataset_generator = CNNDMBertSumProcessedData().splits(root=PROCESSED_DATA_PATH)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "To start model training, we need to create a instance of ExtractiveSummarizer.\n",
    "#### Choose the transformer model.\n",
    "Currently ExtractiveSummarizer support two models:\n",
    "- distilbert-base-uncase, \n",
    "- bert-base-uncase\n",
    "\n",
    "Potentionally, roberta-based model and xlnet can be supported but needs to be tested.\n",
    "#### Choose the encoder algorithm.\n",
    "There are four options:\n",
    "- baseline: it used a smaller transformer model to replace the bert model and with transformer summarization layer\n",
    "- classifier: it uses pretrained BERT and fine-tune BERT with **simple logistic classification** summarization layer\n",
    "- transformer: it uses pretrained BERT and fine-tune BERT with **transformer** summarization layer\n",
    "- RNN: it uses pretrained BERT and fine-tune BERT with **LSTM** summarization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook parameters\n",
    "# the cache data path during find tuning\n",
    "CACHE_DIR = TemporaryDirectory().name\n",
    "\n",
    "# batch size, unit is the number of tokens\n",
    "BATCH_SIZE = 3000\n",
    "\n",
    "# GPU used for training\n",
    "NUM_GPUS = 1\n",
    "\n",
    "# Encoder name. Options are: 1. baseline, classifier, transformer, rnn.\n",
    "ENCODER = \"transformer\"\n",
    "\n",
    "# Learning rate\n",
    "LEARNING_RATE=2e-3\n",
    "\n",
    "# How often the statistics reports show up in training, unit is step.\n",
    "REPORT_EVERY=100\n",
    "    \n",
    "if QUICK_RUN:\n",
    "    # total number of steps for training\n",
    "    MAX_STEPS=1e4\n",
    "    # number of steps for warm up\n",
    "    WARMUP_STEPS=5e3\n",
    "    \n",
    "else:\n",
    "    MAX_STEPS=5e4\n",
    "    WARMUP_STEPS=5e3\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1213 04:14:48.114811 139876939843392 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /tmp/tmpg7bj_es9/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.1ccd1a11c9ff276830e114ea477ea2407100f4a3be7bdc45d37be9e37fa71c7e\n",
      "I1213 04:14:48.116929 139876939843392 configuration_utils.py:168] Model config {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"num_labels\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1213 04:14:48.262818 139876939843392 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin from cache at /tmp/tmpg7bj_es9/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n",
      "I1213 04:14:49.502076 139876939843392 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /tmp/tmpg7bj_es9/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.1ccd1a11c9ff276830e114ea477ea2407100f4a3be7bdc45d37be9e37fa71c7e\n",
      "I1213 04:14:49.504857 139876939843392 configuration_utils.py:168] Model config {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1213 04:14:49.651111 139876939843392 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin from cache at /tmp/tmpg7bj_es9/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n"
     ]
    }
   ],
   "source": [
    "summarizer = ExtractiveSummarizer(MODEL_NAME, ENCODER, CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size is the number of tokens in a batch\n",
    "train_dataloader = get_dataloader(get_cycled_dataset(train_dataset_generator), is_labeled=True, batch_size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 88.754786, time: 20.951731, number of examples in current step: 5, step 100 out of total 10000\n",
      "loss: 36.882119, time: 21.328910, number of examples in current step: 6, step 200 out of total 10000\n",
      "loss: 33.818211, time: 21.043026, number of examples in current step: 5, step 300 out of total 10000\n",
      "loss: 33.178186, time: 21.439393, number of examples in current step: 5, step 400 out of total 10000\n",
      "loss: 31.748262, time: 21.135291, number of examples in current step: 5, step 500 out of total 10000\n",
      "loss: 31.267303, time: 21.471278, number of examples in current step: 5, step 600 out of total 10000\n",
      "loss: 30.590236, time: 20.769160, number of examples in current step: 5, step 700 out of total 10000\n",
      "loss: 30.571218, time: 21.310264, number of examples in current step: 5, step 800 out of total 10000\n",
      "loss: 30.320388, time: 20.892441, number of examples in current step: 5, step 900 out of total 10000\n",
      "loss: 30.693635, time: 21.319025, number of examples in current step: 5, step 1000 out of total 10000\n",
      "loss: 29.869854, time: 20.888089, number of examples in current step: 5, step 1100 out of total 10000\n",
      "loss: 29.814271, time: 21.192435, number of examples in current step: 5, step 1200 out of total 10000\n",
      "loss: 30.996187, time: 20.879288, number of examples in current step: 5, step 1300 out of total 10000\n",
      "loss: 30.241997, time: 21.297337, number of examples in current step: 5, step 1400 out of total 10000\n",
      "loss: 30.003000, time: 20.881403, number of examples in current step: 5, step 1500 out of total 10000\n",
      "loss: 30.334792, time: 21.294699, number of examples in current step: 5, step 1600 out of total 10000\n",
      "loss: 30.431408, time: 20.903196, number of examples in current step: 5, step 1700 out of total 10000\n",
      "loss: 30.320394, time: 21.275791, number of examples in current step: 5, step 1800 out of total 10000\n",
      "loss: 29.290867, time: 20.726989, number of examples in current step: 5, step 1900 out of total 10000\n",
      "loss: 29.915812, time: 21.298642, number of examples in current step: 5, step 2000 out of total 10000\n",
      "loss: 29.988247, time: 20.977722, number of examples in current step: 5, step 2100 out of total 10000\n",
      "loss: 29.949264, time: 21.694569, number of examples in current step: 5, step 2200 out of total 10000\n",
      "loss: 29.354079, time: 21.126164, number of examples in current step: 5, step 2300 out of total 10000\n",
      "loss: 29.072844, time: 21.375116, number of examples in current step: 5, step 2400 out of total 10000\n",
      "loss: 30.007804, time: 20.862795, number of examples in current step: 5, step 2500 out of total 10000\n",
      "loss: 29.358629, time: 21.262998, number of examples in current step: 5, step 2600 out of total 10000\n",
      "loss: 28.809233, time: 20.817608, number of examples in current step: 5, step 2700 out of total 10000\n",
      "loss: 29.315301, time: 21.373862, number of examples in current step: 5, step 2800 out of total 10000\n",
      "loss: 28.938501, time: 20.732085, number of examples in current step: 5, step 2900 out of total 10000\n",
      "loss: 27.712330, time: 21.343199, number of examples in current step: 9, step 3000 out of total 10000\n",
      "loss: 26.880391, time: 20.849095, number of examples in current step: 5, step 3100 out of total 10000\n",
      "loss: 27.959517, time: 21.365154, number of examples in current step: 5, step 3200 out of total 10000\n",
      "loss: 27.272303, time: 20.877340, number of examples in current step: 5, step 3300 out of total 10000\n",
      "loss: 28.370004, time: 21.302393, number of examples in current step: 5, step 3400 out of total 10000\n",
      "loss: 28.024233, time: 20.828965, number of examples in current step: 5, step 3500 out of total 10000\n",
      "loss: 28.247645, time: 21.309736, number of examples in current step: 5, step 3600 out of total 10000\n",
      "loss: 27.972933, time: 20.838102, number of examples in current step: 5, step 3700 out of total 10000\n",
      "loss: 28.294451, time: 21.448310, number of examples in current step: 5, step 3800 out of total 10000\n",
      "loss: 27.741210, time: 20.787410, number of examples in current step: 5, step 3900 out of total 10000\n",
      "loss: 26.264283, time: 21.463996, number of examples in current step: 5, step 4000 out of total 10000\n",
      "loss: 26.785949, time: 20.757461, number of examples in current step: 5, step 4100 out of total 10000\n",
      "loss: 23.891057, time: 21.447565, number of examples in current step: 5, step 4200 out of total 10000\n",
      "loss: 23.503414, time: 21.491435, number of examples in current step: 5, step 4300 out of total 10000\n",
      "loss: 26.111903, time: 20.952197, number of examples in current step: 5, step 4400 out of total 10000\n",
      "loss: 25.847385, time: 21.606991, number of examples in current step: 5, step 4500 out of total 10000\n",
      "loss: 25.242339, time: 20.952910, number of examples in current step: 5, step 4600 out of total 10000\n",
      "loss: 25.639983, time: 21.300644, number of examples in current step: 5, step 4700 out of total 10000\n",
      "loss: 25.580165, time: 21.028625, number of examples in current step: 6, step 4800 out of total 10000\n",
      "loss: 24.956763, time: 21.451853, number of examples in current step: 5, step 4900 out of total 10000\n",
      "loss: 22.947707, time: 20.945164, number of examples in current step: 5, step 5000 out of total 10000\n",
      "loss: 21.940077, time: 21.193297, number of examples in current step: 5, step 5100 out of total 10000\n",
      "loss: 20.905992, time: 20.959187, number of examples in current step: 5, step 5200 out of total 10000\n",
      "loss: 21.595713, time: 21.273485, number of examples in current step: 6, step 5300 out of total 10000\n",
      "loss: 21.711819, time: 20.754070, number of examples in current step: 10, step 5400 out of total 10000\n",
      "loss: 22.248907, time: 21.234232, number of examples in current step: 5, step 5500 out of total 10000\n",
      "loss: 20.103890, time: 20.774216, number of examples in current step: 5, step 5600 out of total 10000\n",
      "loss: 19.532415, time: 21.334376, number of examples in current step: 5, step 5700 out of total 10000\n",
      "loss: 18.081182, time: 20.794752, number of examples in current step: 5, step 5800 out of total 10000\n",
      "loss: 14.216780, time: 21.231076, number of examples in current step: 5, step 5900 out of total 10000\n",
      "loss: 11.227607, time: 20.866705, number of examples in current step: 5, step 6000 out of total 10000\n",
      "loss: 14.952144, time: 21.356342, number of examples in current step: 5, step 6100 out of total 10000\n",
      "loss: 17.077168, time: 20.971865, number of examples in current step: 5, step 6200 out of total 10000\n",
      "loss: 16.069756, time: 21.280266, number of examples in current step: 5, step 6300 out of total 10000\n",
      "loss: 14.240203, time: 20.879818, number of examples in current step: 5, step 6400 out of total 10000\n",
      "loss: 16.242687, time: 21.163145, number of examples in current step: 5, step 6500 out of total 10000\n",
      "loss: 16.056626, time: 20.869756, number of examples in current step: 5, step 6600 out of total 10000\n",
      "loss: 14.892075, time: 21.212637, number of examples in current step: 5, step 6700 out of total 10000\n",
      "loss: 14.568874, time: 20.763456, number of examples in current step: 8, step 6800 out of total 10000\n",
      "loss: 11.087236, time: 21.161869, number of examples in current step: 5, step 6900 out of total 10000\n",
      "loss: 9.980588, time: 21.035302, number of examples in current step: 11, step 7000 out of total 10000\n",
      "loss: 10.983412, time: 21.236146, number of examples in current step: 5, step 7100 out of total 10000\n",
      "loss: 10.584450, time: 20.912858, number of examples in current step: 5, step 7200 out of total 10000\n",
      "loss: 10.084562, time: 21.090037, number of examples in current step: 5, step 7300 out of total 10000\n",
      "loss: 7.981883, time: 20.801389, number of examples in current step: 5, step 7400 out of total 10000\n",
      "loss: 12.143881, time: 21.346035, number of examples in current step: 5, step 7500 out of total 10000\n",
      "loss: 11.222716, time: 20.727228, number of examples in current step: 5, step 7600 out of total 10000\n",
      "loss: 10.993808, time: 21.241568, number of examples in current step: 5, step 7700 out of total 10000\n",
      "loss: 9.972925, time: 20.832124, number of examples in current step: 5, step 7800 out of total 10000\n",
      "loss: 6.645168, time: 21.190613, number of examples in current step: 5, step 7900 out of total 10000\n",
      "loss: 5.353294, time: 20.852225, number of examples in current step: 5, step 8000 out of total 10000\n",
      "loss: 8.280886, time: 21.221246, number of examples in current step: 5, step 8100 out of total 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 7.391126, time: 21.281028, number of examples in current step: 5, step 8200 out of total 10000\n",
      "loss: 7.014486, time: 20.872972, number of examples in current step: 5, step 8300 out of total 10000\n",
      "loss: 6.995007, time: 21.202711, number of examples in current step: 5, step 8400 out of total 10000\n",
      "loss: 8.262606, time: 20.828412, number of examples in current step: 5, step 8500 out of total 10000\n",
      "loss: 8.004557, time: 21.268847, number of examples in current step: 5, step 8600 out of total 10000\n",
      "loss: 9.018328, time: 20.794796, number of examples in current step: 5, step 8700 out of total 10000\n",
      "loss: 7.782450, time: 21.159053, number of examples in current step: 5, step 8800 out of total 10000\n",
      "loss: 5.492205, time: 20.867897, number of examples in current step: 5, step 8900 out of total 10000\n",
      "loss: 4.996181, time: 21.160143, number of examples in current step: 5, step 9000 out of total 10000\n",
      "loss: 5.517623, time: 20.816377, number of examples in current step: 5, step 9100 out of total 10000\n",
      "loss: 5.617976, time: 21.158200, number of examples in current step: 5, step 9200 out of total 10000\n",
      "loss: 4.751842, time: 20.811119, number of examples in current step: 5, step 9300 out of total 10000\n",
      "loss: 4.913383, time: 21.135615, number of examples in current step: 5, step 9400 out of total 10000\n",
      "loss: 5.983083, time: 20.725634, number of examples in current step: 5, step 9500 out of total 10000\n",
      "loss: 6.014017, time: 21.134219, number of examples in current step: 5, step 9600 out of total 10000\n",
      "loss: 5.771280, time: 20.869199, number of examples in current step: 5, step 9700 out of total 10000\n",
      "loss: 4.872929, time: 21.151158, number of examples in current step: 5, step 9800 out of total 10000\n",
      "loss: 3.704411, time: 20.685062, number of examples in current step: 5, step 9900 out of total 10000\n",
      "loss: 4.233141, time: 21.225758, number of examples in current step: 5, step 10000 out of total 10000\n"
     ]
    }
   ],
   "source": [
    "summarizer.fit(\n",
    "            train_dataloader,\n",
    "            num_gpus=1,\n",
    "            gradient_accumulation_steps=2,\n",
    "            max_steps=MAX_STEPS,\n",
    "            lr=LEARNING_RATE,\n",
    "            warmup_steps=WARMUP_STEPS,\n",
    "            verbose=True,\n",
    "            report_every=REPORT_EVERY,\n",
    "            clip_grad_norm=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1213 04:51:20.777847 139876939843392 extractive_summarization.py:338] Saving model checkpoint to /tmp/tmpg7bj_es9/fine_tuned/extsum_modelname_distilbert-base-uncased_quickrun_True.pt\n"
     ]
    }
   ],
   "source": [
    "summarizer.save_model(\"extsum_modelname_{0}_quickrun_{1}.pt\".format(MODEL_NAME, QUICK_RUN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading a previous saved model\n",
    "#import torch\n",
    "#summarizer.model = torch.load(\"cnndm_transformersum_distilbert-base-uncased_bertsum_processed_data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "[ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)), or Recall-Oriented Understudy for Gisting Evaluation has been commonly used for evaluation text summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=[]\n",
    "for i in test_dataset_generator():\n",
    "    test_dataset.extend(i)\n",
    "target = [test_dataset[i]['tgt_txt'] for i in range(len(test_dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = summarizer.predict(get_sequential_dataloader(test_dataset))\n",
    "#prediction = summarizer.predict(get_dataloader(test_dataset_generator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11489\n",
      "11489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-13 03:30:31,880 [MainThread  ] [INFO ]  Writing summaries.\n",
      "I1213 03:30:31.880824 140367597561664 pyrouge.py:525] Writing summaries.\n",
      "2019-12-13 03:30:31,882 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./results/tmp9nzyeqtw/system and model files to ./results/tmp9nzyeqtw/model.\n",
      "I1213 03:30:31.882954 140367597561664 pyrouge.py:518] Processing summaries. Saving system files to ./results/tmp9nzyeqtw/system and model files to ./results/tmp9nzyeqtw/model.\n",
      "2019-12-13 03:30:31,884 [MainThread  ] [INFO ]  Processing files in ./results/rouge-tmp-2019-12-13-03-30-30/candidate/.\n",
      "I1213 03:30:31.884879 140367597561664 pyrouge.py:43] Processing files in ./results/rouge-tmp-2019-12-13-03-30-30/candidate/.\n",
      "2019-12-13 03:30:32,975 [MainThread  ] [INFO ]  Saved processed files to ./results/tmp9nzyeqtw/system.\n",
      "I1213 03:30:32.975462 140367597561664 pyrouge.py:53] Saved processed files to ./results/tmp9nzyeqtw/system.\n",
      "2019-12-13 03:30:32,976 [MainThread  ] [INFO ]  Processing files in ./results/rouge-tmp-2019-12-13-03-30-30/reference/.\n",
      "I1213 03:30:32.976979 140367597561664 pyrouge.py:43] Processing files in ./results/rouge-tmp-2019-12-13-03-30-30/reference/.\n",
      "2019-12-13 03:30:34,075 [MainThread  ] [INFO ]  Saved processed files to ./results/tmp9nzyeqtw/model.\n",
      "I1213 03:30:34.075453 140367597561664 pyrouge.py:53] Saved processed files to ./results/tmp9nzyeqtw/model.\n",
      "2019-12-13 03:30:34,154 [MainThread  ] [INFO ]  Written ROUGE configuration to ./results/tmpdhub5ogj/rouge_conf.xml\n",
      "I1213 03:30:34.154051 140367597561664 pyrouge.py:354] Written ROUGE configuration to ./results/tmpdhub5ogj/rouge_conf.xml\n",
      "2019-12-13 03:30:34,155 [MainThread  ] [INFO ]  Running ROUGE with command /dadendev/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /dadendev/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./results/tmpdhub5ogj/rouge_conf.xml\n",
      "I1213 03:30:34.155034 140367597561664 pyrouge.py:372] Running ROUGE with command /dadendev/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /dadendev/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./results/tmpdhub5ogj/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.53122 (95%-conf.int. 0.52844 - 0.53403)\n",
      "1 ROUGE-1 Average_P: 0.37302 (95%-conf.int. 0.37056 - 0.37539)\n",
      "1 ROUGE-1 Average_F: 0.42346 (95%-conf.int. 0.42127 - 0.42559)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.24412 (95%-conf.int. 0.24148 - 0.24699)\n",
      "1 ROUGE-2 Average_P: 0.17201 (95%-conf.int. 0.16981 - 0.17421)\n",
      "1 ROUGE-2 Average_F: 0.19468 (95%-conf.int. 0.19257 - 0.19690)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.48532 (95%-conf.int. 0.48245 - 0.48821)\n",
      "1 ROUGE-L Average_P: 0.34135 (95%-conf.int. 0.33890 - 0.34374)\n",
      "1 ROUGE-L Average_F: 0.38723 (95%-conf.int. 0.38509 - 0.38946)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rouge_transformer = get_rouge(prediction, target, \"./results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marseille prosecutor says `` so far no videos were used in the crash investigation `` despite media reports .<q>journalists at bild and paris match are `` very confident `` the video clip is real , an editor says .<q>andreas lubitz had informed his lufthansa training school of an episode of severe depression , airline says .<q>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]['tgt_txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paris match and bild reported that the video was recovered from a phone at the wreckage site .<q>all 150 on board were killed .<q>marseille , france ( cnn ) the french prosecutor leading an investigation into the crash of germanwings flight 9525 insisted wednesday that he was not aware of any video footage from on board the plane .'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marseille , france ( cnn ) the french prosecutor leading an investigation into the crash of germanwings flight 9525 insisted wednesday that he was not aware of any video footage from on board the plane .',\n",
       " 'marseille prosecutor brice robin told cnn that `` so far no videos were used in the crash investigation . ``',\n",
       " 'he added , `` a person who has such a video needs to immediately give it to the investigators . ``',\n",
       " \"robin 's comments follow claims by two magazines , german daily bild and french paris match , of a cell phone video showing the harrowing final seconds from on board germanwings flight 9525 as it crashed into the french alps .\",\n",
       " 'all 150 on board were killed .',\n",
       " 'paris match and bild reported that the video was recovered from a phone at the wreckage site .',\n",
       " 'the two publications described the supposed video , but did not post it on their websites .',\n",
       " 'the publications said that they watched the video , which was found by a source close to the investigation . ``',\n",
       " \"one can hear cries of ` my god ' in several languages , `` paris match reported . ``\",\n",
       " 'metallic banging can also be heard more than three times , perhaps of the pilot trying to open the cockpit door with a heavy object .',\n",
       " 'towards the end , after a heavy shake , stronger than the others , the screaming intensifies .',\n",
       " '`` it is a very disturbing scene , `` said julian reichelt , editor-in-chief of bild online .',\n",
       " \"an official with france 's accident investigation agency , the bea , said the agency is not aware of any such video .\",\n",
       " 'lt. col. jean-marc menichini , a french gendarmerie spokesman in charge of communications on rescue efforts around the germanwings crash site , told cnn that the reports were `` completely wrong `` and `` unwarranted . ``',\n",
       " \"cell phones have been collected at the site , he said , but that they `` had n't been exploited yet . ``\",\n",
       " 'menichini said he believed the cell phones would need to be sent to the criminal research institute in rosny sous-bois , near paris , in order to be analyzed by specialized technicians working hand-in-hand with investigators .',\n",
       " 'but none of the cell phones found so far have been sent to the institute , menichini said .',\n",
       " 'asked whether staff involved in the search could have leaked a memory card to the media , menichini answered with a categorical `` no . ``',\n",
       " 'reichelt told `` erin burnett : outfront `` that he had watched the video and stood by the report , saying bild and paris match are `` very confident `` that the clip is real .',\n",
       " \"he noted that investigators only revealed they 'd recovered cell phones from the crash site after bild and paris match published their reports . ``\",\n",
       " 'that is something we did not know before .',\n",
       " \"... overall we can say many things of the investigation were n't revealed by the investigation at the beginning , `` he said .\",\n",
       " 'what was mental state of germanwings co-pilot ?',\n",
       " \"german airline lufthansa confirmed tuesday that co-pilot andreas lubitz had battled depression years before he took the controls of germanwings flight 9525 , which he 's accused of deliberately crashing last week in the french alps .\",\n",
       " 'lubitz told his lufthansa flight training school in 2009 that he had a `` previous episode of severe depression , `` the airline said tuesday .',\n",
       " 'email correspondence between lubitz and the school discovered in an internal investigation , lufthansa said , included medical documents he submitted in connection with resuming his flight training .',\n",
       " \"the announcement indicates that lufthansa , the parent company of germanwings , knew of lubitz 's battle with depression , allowed him to continue training and ultimately put him in the cockpit .\",\n",
       " 'lufthansa , whose ceo carsten spohr previously said lubitz was 100 % fit to fly , described its statement tuesday as a `` swift and seamless clarification `` and said it was sharing the information and documents -- including training and medical records -- with public prosecutors .',\n",
       " 'spohr traveled to the crash site wednesday , where recovery teams have been working for the past week to recover human remains and plane debris scattered across a steep mountainside .',\n",
       " 'he saw the crisis center set up in seyne-les-alpes , laid a wreath in the village of le vernet , closer to the crash site , where grieving families have left flowers at a simple stone memorial .',\n",
       " 'menichini told cnn late tuesday that no visible human remains were left at the site but recovery teams would keep searching .',\n",
       " 'french president francois hollande , speaking tuesday , said that it should be possible to identify all the victims using dna analysis by the end of the week , sooner than authorities had previously suggested .',\n",
       " \"in the meantime , the recovery of the victims ' personal belongings will start wednesday , menichini said .\",\n",
       " 'among those personal belongings could be more cell phones belonging to the 144 passengers and six crew on board .',\n",
       " 'check out the latest from our correspondents .',\n",
       " \"the details about lubitz 's correspondence with the flight school during his training were among several developments as investigators continued to delve into what caused the crash and lubitz 's possible motive for downing the jet .\",\n",
       " 'a lufthansa spokesperson told cnn on tuesday that lubitz had a valid medical certificate , had passed all his examinations and `` held all the licenses required . ``',\n",
       " \"earlier , a spokesman for the prosecutor 's office in dusseldorf , christoph kumpa , said medical records reveal lubitz suffered from suicidal tendencies at some point before his aviation career and underwent psychotherapy before he got his pilot 's license .\",\n",
       " \"kumpa emphasized there 's no evidence suggesting lubitz was suicidal or acting aggressively before the crash .\",\n",
       " \"investigators are looking into whether lubitz feared his medical condition would cause him to lose his pilot 's license , a european government official briefed on the investigation told cnn on tuesday .\",\n",
       " \"while flying was `` a big part of his life , `` the source said , it 's only one theory being considered .\",\n",
       " 'another source , a law enforcement official briefed on the investigation , also told cnn that authorities believe the primary motive for lubitz to bring down the plane was that he feared he would not be allowed to fly because of his medical problems .',\n",
       " \"lubitz 's girlfriend told investigators he had seen an eye doctor and a neuropsychologist , both of whom deemed him unfit to work recently and concluded he had psychological issues , the european government official said .\",\n",
       " \"but no matter what details emerge about his previous mental health struggles , there 's more to the story , said brian russell , a forensic psychologist . ``\",\n",
       " \"psychology can explain why somebody would turn rage inward on themselves about the fact that maybe they were n't going to keep doing their job and they 're upset about that and so they 're suicidal , `` he said . ``\",\n",
       " \"but there is no mental illness that explains why somebody then feels entitled to also take that rage and turn it outward on 149 other people who had nothing to do with the person 's problems . ``\",\n",
       " 'germanwings crash compensation : what we know .',\n",
       " 'who was the captain of germanwings flight 9525 ?',\n",
       " \"cnn 's margot haddad reported from marseille and pamela brown from dusseldorf , while laura smith-spark wrote from london .\",\n",
       " \"cnn 's frederik pleitgen , pamela boykoff , antonia mortensen , sandrine amiel and anna-maja rappard contributed to this report .\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]['src_txt']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6 cm3",
   "language": "python",
   "name": "cm3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
