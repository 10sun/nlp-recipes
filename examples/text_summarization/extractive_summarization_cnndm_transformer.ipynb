{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive Summarization on CNN/DM Dataset using Transformer Version of BertSum\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "This notebook demonstrates how to fine tune Transformers for extractive text summarization. Utility functions and classes in the NLP Best Practices repo are used to facilitate data preprocessing, model training, model scoring, result postprocessing, and model evaluation.\n",
    "\n",
    "BertSum refers to  [Fine-tune BERT for Extractive Summarization (https://arxiv.org/pdf/1903.10318.pdf) with [published example](https://github.com/nlpyang/BertSum/). And the Transformer version of Bertsum refers to our modification of BertSum and the source code can be accessed at (https://github.com/daden-ms/BertSum/). \n",
    "\n",
    "Extractive summarization are usually used in document summarization where each input document consists of mutiple sentences. The preprocessing of the input training data involves assigning label 0 or 1 to the document sentences based on the give summary. The summarization problem is also simplfied to classifying whether each document sentence should be included in the summary. \n",
    "\n",
    "The figure below illustrates how BERTSum can be fine tuned for extractive summarization task. Each sentence is inserted with [CLS] token at the beginning and  [SEP] at the end. Interval segment embedding and positional embedding are added upon the token embedding before input the BERT model. The [CLS] token representation is used as sentence embedding and only the [CLS] tokens are used as input for the summarization model. The summarization layer predicts whether the probability of each each sentence token should be included in the summary or not. Techniques like trigram blocking can be used to improve model accuarcy.   \n",
    "\n",
    "<img src=\"https://nlpbp.blob.core.windows.net/images/BertSum.PNG\">\n",
    "\n",
    "\n",
    "### Before You Start\n",
    "\n",
    "The running time shown in this notebook is on a Standard_NC24s_v3 Azure Deep Learning Virtual Machine with 4 NVIDIA Tesla V100 GPUs. \n",
    "> **Tip**: If you want to run through the notebook quickly, you can set the **`QUICK_RUN`** flag in the cell below to **`True`** to run the notebook on a small subset of the data and a smaller number of epochs. \n",
    "\n",
    "On a machine with 1 NVIDIA Tesla V100 GPUs, 16GB GPU memory configuration,\n",
    "- for data preprocessing, it takes around 10 minutes the data preprocessing for quick run. Otherwise it takes ~2 hours to finish the data preprocessing. This time estimation assumes the chosen transformer model is \"distilbert-base-uncased\" and the sentence selection method is \"greedy\", which is the default. The preprocessing time can be significantly longer if the sentence selection method is \"combination\", which can achieve better model performance.\n",
    "\n",
    "- for model fine tuning, it takes around 30 minutes for quick run. Otherwise, it takes around ~3 hours to finish. This estimation assume the chosen encoder method is \"transformer\". The model fine tuning time can be shorter if other encoder method is chosen, which may result in worse model performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set QUICK_RUN = True to run the notebook on a small subset of data and a smaller number of epochs.\n",
    "QUICK_RUN = True\n",
    "## Set USE_PREPROCSSED_DATA = True to skip the data preprocessing\n",
    "USE_PREPROCSSED_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Before we start the notebook, we should set the environment variable to make sure you can access the GPUs on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daden/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "I1219 04:08:26.066413 139675858003776 file_utils.py:40] PyTorch version 1.2.0 available.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch\n",
    "\n",
    "nlp_path = os.path.abspath(\"../../\")\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "\n",
    "from utils_nlp.common.pytorch_utils import get_device\n",
    "from utils_nlp.dataset.cnndm import CNNDMBertSumProcessedData, CNNDMSummarization, ExtSumProcessedData\n",
    "from utils_nlp.eval.evaluate_summarization import get_rouge\n",
    "from utils_nlp.models.transformers.extractive_summarization import (\n",
    "    get_cycled_dataset,\n",
    "    get_dataloader,\n",
    "    get_sequential_dataloader,\n",
    "    ExtractiveSummarizer,\n",
    "    ExtSumProcessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration: choose the transformer model to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model being used\n",
    "MODEL_NAME = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we need to install the dependencies for pyrouge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dependencies for ROUGE-1.5.5.pl\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install expat\n",
    "!sudo apt-get install libexpat-dev -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command in your terminal to install pre-requiste for using pyrouge.\n",
    "1. sudo cpan install XML::Parser\n",
    "1. sudo cpan install XML::Parser::PerlSAX\n",
    "1. sudo cpan install XML::DOM\n",
    "\n",
    "Download ROUGE-1.5.5 from https://github.com/andersjo/pyrouge/tree/master/tools/ROUGE-1.5.5.\n",
    "Run the following command in your terminal.\n",
    "* pyrouge_set_rouge_path $ABSOLUTE_DIRECTORY_TO_ROUGE-1.5.5.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprossing\n",
    "\n",
    "The dataset we used for this notebook is CNN/DM dataset which contains the documents and accompanying questions from the news articles of CNN and Daily mail. The highlights in each article are used as summary. The dataset consits of ~289K training examples, ~11K valiation and ~11K test dataset.  You can choose the [Option 1] below preprocess the data or [Option 2] to use the preprocessed version at [BERTSum published example](https://github.com/nlpyang/BertSum/). You don't need to manually download any of these two data sets as the code below will handle this part.  Since it takes up to 28 hours to preprocess the training data  to run on 10  Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz, we suggest you continue with set as True first and experiment with data preprocessing  with QUICKRUN set as True.\n",
    "\n",
    "##### Details of Data Preprocessing\n",
    "\n",
    "The purpose of preprocessing is to process the input articles to the format that BertSum takes.  Functions defined specific in harvardnlp_cnndm_preprocess function are unique to CNN/DM dataset that's processed by harvardnlp. However, it provides a skeleton of how to preprocessing data into the format that BertSum takes. Assuming you have all articles and target summery each in a file, line-breaker seperated, the steps to preprocess the data are:\n",
    "1. sentence tokenization\n",
    "2. word tokenization\n",
    "3. **label** the sentences in the article with 1 meaning the sentence is selected and 0 meaning the sentence is not selected. The options for the selection algorithms are \"greedy\" and \"combination\"\n",
    "3. convert each example to  the desired format for extractive summarization\n",
    "    - filter the sentences in the example based on the min_src_ntokens argument. If the lefted total sentence number is less than min_nsents, the example is discarded.\n",
    "    - truncate the sentences in the example if the length is greater than max_src_ntokens\n",
    "    - truncate the sentences in the example and the labels if the totle number of sentences is greater than max_nsents\n",
    "    - [CLS] and [SEP] are inserted before and after each sentence\n",
    "    - wordPiece tokenization\n",
    "    - truncate the example to 512 tokens\n",
    "    - convert the tokens into token indices corresponding to the BERT tokenizer's vocabulary.\n",
    "    - segment ids are generated\n",
    "    - [CLS] token positions are logged\n",
    "    - [CLS] token labels are truncated if it's greater than 512, which is the maximum input length that can be taken by the BERT model.\n",
    "    \n",
    "    \n",
    "Note that the original BERTSum paper use Stanford CoreNLP for data proprocessing, here we'll first how to use NLTK version, and then we also provide instruction of how to set up Stanford NLP and code examples of how to use Standford CoreNLP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Option 1] Preprocess  data\n",
    "The code in following cell will download the CNN/DM dataset listed at https://github.com/harvardnlp/sent-summary/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data path used to save the downloaded data file\n",
    "DATA_PATH = TemporaryDirectory().name\n",
    "# The number of lines at the head of data file used for preprocessing. -1 means all the lines.\n",
    "TOP_N = -1\n",
    "if QUICK_RUN:\n",
    "    TOP_N = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489k/489k [00:07<00:00, 62.3kKB/s] \n",
      "I1217 18:37:26.811193 139802557667136 utils.py:173] Opening tar file /tmp/tmpy397314q/cnndm.tar.gz.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = CNNDMSummarization(top_n=TOP_N, local_cache_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data and save the data to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1217 18:37:38.230067 139802557667136 tokenization_utils.py:379] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_nsents': 200, 'max_src_ntokens': 2000, 'min_nsents': 3, 'min_src_ntokens': 5, 'use_interval': True}\n"
     ]
    }
   ],
   "source": [
    "processor = ExtSumProcessor(model_name=MODEL_NAME)\n",
    "ext_sum_train = processor.preprocess(train_dataset, train_dataset.get_target(), oracle_mode=\"greedy\")\n",
    "ext_sum_test = processor.preprocess(test_dataset, test_dataset.get_target(),oracle_mode=\"greedy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(DATA_PATH, \"processed\")\n",
    "train_files = ExtSumProcessedData.save_data(\n",
    "    ext_sum_train, is_test=False, save_path=save_path, chunk_size=2000\n",
    ")\n",
    "test_files = ExtSumProcessedData.save_data(\n",
    "    ext_sum_test, is_test=True, save_path=save_path, chunk_size=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmpy397314q/processed/0_train',\n",
       " '/tmp/tmpy397314q/processed/1_train',\n",
       " '/tmp/tmpy397314q/processed/2_train',\n",
       " '/tmp/tmpy397314q/processed/3_train',\n",
       " '/tmp/tmpy397314q/processed/4_train']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmpy397314q/processed/0_test',\n",
       " '/tmp/tmpy397314q/processed/1_test',\n",
       " '/tmp/tmpy397314q/processed/2_test',\n",
       " '/tmp/tmpy397314q/processed/3_test',\n",
       " '/tmp/tmpy397314q/processed/4_test']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_generator, test_dataset_generator = ExtSumProcessedData().splits(root=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['src', 'labels', 'segs', 'clss', 'src_txt', 'tgt_txt'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "bert_format_data = torch.load(train_files[0])\n",
    "print(len(bert_format_data))\n",
    "bert_format_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_format_data[0]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Option 2] Reuse Preprocessed  data from [BERTSUM Repo](https://github.com/nlpyang/BertSum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data path used to downloaded the preprocessed data from BERTSUM Repo.\n",
    "# if you have downloaded the dataset, change the code to use that path where the dataset is.\n",
    "PROCESSED_DATA_PATH = TemporaryDirectory().name\n",
    "data_path = \"./temp_data5/\"\n",
    "PROCESSED_DATA_PATH = data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_PREPROCSSED_DATA:\n",
    "    CNNDMBertSumProcessedData.download(local_path=PROCESSED_DATA_PATH)\n",
    "    train_dataset_generator, test_dataset_generator = ExtSumProcessedData().splits(root=PROCESSED_DATA_PATH)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "To start model training, we need to create a instance of ExtractiveSummarizer.\n",
    "#### Choose the transformer model.\n",
    "Currently ExtractiveSummarizer support two models:\n",
    "- distilbert-base-uncase, \n",
    "- bert-base-uncase\n",
    "\n",
    "Potentionally, roberta-based model and xlnet can be supported but needs to be tested.\n",
    "#### Choose the encoder algorithm.\n",
    "There are four options:\n",
    "- baseline: it used a smaller transformer model to replace the bert model and with transformer summarization layer\n",
    "- classifier: it uses pretrained BERT and fine-tune BERT with **simple logistic classification** summarization layer\n",
    "- transformer: it uses pretrained BERT and fine-tune BERT with **transformer** summarization layer\n",
    "- RNN: it uses pretrained BERT and fine-tune BERT with **LSTM** summarization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook parameters\n",
    "# the cache data path during find tuning\n",
    "CACHE_DIR = TemporaryDirectory().name\n",
    "\n",
    "# batch size, unit is the number of tokens\n",
    "BATCH_SIZE = 3000\n",
    "\n",
    "# GPU used for training\n",
    "NUM_GPUS = 1\n",
    "\n",
    "# Encoder name. Options are: 1. baseline, classifier, transformer, rnn.\n",
    "ENCODER = \"transformer\"\n",
    "\n",
    "# Learning rate\n",
    "LEARNING_RATE=2e-3\n",
    "\n",
    "# How often the statistics reports show up in training, unit is step.\n",
    "REPORT_EVERY=100\n",
    "    \n",
    "if QUICK_RUN:\n",
    "    # total number of steps for training\n",
    "    MAX_STEPS=1e4\n",
    "    # number of steps for warm up\n",
    "    WARMUP_STEPS=5e3\n",
    "    \n",
    "else:\n",
    "    MAX_STEPS=5e4\n",
    "    WARMUP_STEPS=5e3\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1219 04:09:29.497260 139675858003776 file_utils.py:319] https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpo59o7kse\n",
      "100%|██████████| 492/492 [00:00<00:00, 400776.38B/s]\n",
      "I1219 04:09:29.658666 139675858003776 file_utils.py:334] copying /tmp/tmpo59o7kse to cache at /tmp/tmpi99rn6ni/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.1ccd1a11c9ff276830e114ea477ea2407100f4a3be7bdc45d37be9e37fa71c7e\n",
      "I1219 04:09:29.662085 139675858003776 file_utils.py:338] creating metadata file for /tmp/tmpi99rn6ni/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.1ccd1a11c9ff276830e114ea477ea2407100f4a3be7bdc45d37be9e37fa71c7e\n",
      "I1219 04:09:29.663305 139675858003776 file_utils.py:347] removing temp file /tmp/tmpo59o7kse\n",
      "I1219 04:09:29.664099 139675858003776 configuration_utils.py:157] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /tmp/tmpi99rn6ni/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.1ccd1a11c9ff276830e114ea477ea2407100f4a3be7bdc45d37be9e37fa71c7e\n",
      "I1219 04:09:29.665112 139675858003776 configuration_utils.py:174] Model config {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"num_labels\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1219 04:09:29.807581 139675858003776 file_utils.py:319] https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpvlezuh0b\n",
      "100%|██████████| 267967963/267967963 [00:04<00:00, 62207368.71B/s]\n",
      "I1219 04:09:34.336824 139675858003776 file_utils.py:334] copying /tmp/tmpvlezuh0b to cache at /tmp/tmpi99rn6ni/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n",
      "I1219 04:09:34.634873 139675858003776 file_utils.py:338] creating metadata file for /tmp/tmpi99rn6ni/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n",
      "I1219 04:09:34.636206 139675858003776 file_utils.py:347] removing temp file /tmp/tmpvlezuh0b\n",
      "I1219 04:09:34.673409 139675858003776 modeling_utils.py:393] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin from cache at /tmp/tmpi99rn6ni/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n",
      "I1219 04:09:35.989183 139675858003776 configuration_utils.py:157] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /tmp/tmpi99rn6ni/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.1ccd1a11c9ff276830e114ea477ea2407100f4a3be7bdc45d37be9e37fa71c7e\n",
      "I1219 04:09:35.992045 139675858003776 configuration_utils.py:174] Model config {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1219 04:09:36.136521 139675858003776 modeling_utils.py:393] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin from cache at /tmp/tmpi99rn6ni/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n"
     ]
    }
   ],
   "source": [
    "summarizer = ExtractiveSummarizer(MODEL_NAME, ENCODER, CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size is the number of tokens in a batch\n",
    "train_dataloader = get_dataloader(get_cycled_dataset(train_dataset_generator), is_labeled=True, batch_size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 50.646378, time: 22.631160, number of examples in current step: 5, step 100 out of total 10000\n",
      "loss: 33.793594, time: 21.044874, number of examples in current step: 5, step 200 out of total 10000\n",
      "loss: 32.788770, time: 20.708551, number of examples in current step: 5, step 300 out of total 10000\n",
      "loss: 31.555956, time: 21.022777, number of examples in current step: 5, step 400 out of total 10000\n",
      "loss: 31.015303, time: 20.605717, number of examples in current step: 8, step 500 out of total 10000\n",
      "loss: 30.423153, time: 20.881066, number of examples in current step: 5, step 600 out of total 10000\n",
      "loss: 30.845548, time: 20.734294, number of examples in current step: 5, step 700 out of total 10000\n",
      "loss: 30.580163, time: 21.032496, number of examples in current step: 7, step 800 out of total 10000\n",
      "loss: 31.150659, time: 20.884736, number of examples in current step: 5, step 900 out of total 10000\n",
      "loss: 29.488281, time: 21.059112, number of examples in current step: 5, step 1000 out of total 10000\n",
      "loss: 30.541964, time: 20.708292, number of examples in current step: 5, step 1100 out of total 10000\n",
      "loss: 30.830110, time: 21.077800, number of examples in current step: 5, step 1200 out of total 10000\n",
      "loss: 29.623951, time: 20.632566, number of examples in current step: 5, step 1300 out of total 10000\n",
      "loss: 30.290076, time: 21.099526, number of examples in current step: 5, step 1400 out of total 10000\n",
      "loss: 29.993626, time: 20.555313, number of examples in current step: 5, step 1500 out of total 10000\n",
      "loss: 30.277067, time: 21.134893, number of examples in current step: 5, step 1600 out of total 10000\n",
      "loss: 30.136724, time: 21.092158, number of examples in current step: 5, step 1700 out of total 10000\n",
      "loss: 30.142018, time: 21.349204, number of examples in current step: 5, step 1800 out of total 10000\n",
      "loss: 30.408301, time: 20.947950, number of examples in current step: 5, step 1900 out of total 10000\n",
      "loss: 29.111500, time: 21.486748, number of examples in current step: 5, step 2000 out of total 10000\n",
      "loss: 30.184728, time: 20.846687, number of examples in current step: 5, step 2100 out of total 10000\n",
      "loss: 29.597505, time: 21.212236, number of examples in current step: 5, step 2200 out of total 10000\n",
      "loss: 29.868810, time: 20.714326, number of examples in current step: 5, step 2300 out of total 10000\n",
      "loss: 29.377431, time: 20.978430, number of examples in current step: 5, step 2400 out of total 10000\n",
      "loss: 29.541388, time: 20.640673, number of examples in current step: 5, step 2500 out of total 10000\n",
      "loss: 29.724207, time: 21.356356, number of examples in current step: 5, step 2600 out of total 10000\n",
      "loss: 29.390374, time: 21.234666, number of examples in current step: 5, step 2700 out of total 10000\n",
      "loss: 29.454847, time: 21.583781, number of examples in current step: 5, step 2800 out of total 10000\n",
      "loss: 28.447264, time: 20.967798, number of examples in current step: 5, step 2900 out of total 10000\n",
      "loss: 29.055359, time: 21.146016, number of examples in current step: 5, step 3000 out of total 10000\n",
      "loss: 28.194085, time: 20.727949, number of examples in current step: 5, step 3100 out of total 10000\n",
      "loss: 27.781719, time: 21.310647, number of examples in current step: 10, step 3200 out of total 10000\n",
      "loss: 26.309513, time: 20.805569, number of examples in current step: 5, step 3300 out of total 10000\n",
      "loss: 28.655566, time: 21.209971, number of examples in current step: 5, step 3400 out of total 10000\n",
      "loss: 28.125119, time: 20.701797, number of examples in current step: 5, step 3500 out of total 10000\n",
      "loss: 27.724689, time: 21.208107, number of examples in current step: 5, step 3600 out of total 10000\n",
      "loss: 28.469454, time: 20.735428, number of examples in current step: 5, step 3700 out of total 10000\n",
      "loss: 27.441285, time: 21.201085, number of examples in current step: 5, step 3800 out of total 10000\n",
      "loss: 27.446780, time: 20.751544, number of examples in current step: 5, step 3900 out of total 10000\n",
      "loss: 26.043867, time: 21.156237, number of examples in current step: 5, step 4000 out of total 10000\n",
      "loss: 26.181683, time: 21.134482, number of examples in current step: 5, step 4100 out of total 10000\n",
      "loss: 24.185787, time: 20.864966, number of examples in current step: 5, step 4200 out of total 10000\n",
      "loss: 24.647515, time: 21.104284, number of examples in current step: 5, step 4300 out of total 10000\n",
      "loss: 26.308780, time: 20.772454, number of examples in current step: 5, step 4400 out of total 10000\n",
      "loss: 25.744383, time: 21.172621, number of examples in current step: 5, step 4500 out of total 10000\n",
      "loss: 24.773671, time: 20.700181, number of examples in current step: 5, step 4600 out of total 10000\n",
      "loss: 24.270896, time: 21.268451, number of examples in current step: 5, step 4700 out of total 10000\n",
      "loss: 25.846365, time: 20.598596, number of examples in current step: 5, step 4800 out of total 10000\n",
      "loss: 23.428492, time: 20.967340, number of examples in current step: 5, step 4900 out of total 10000\n",
      "loss: 19.957516, time: 20.714996, number of examples in current step: 5, step 5000 out of total 10000\n",
      "loss: 20.340182, time: 21.082933, number of examples in current step: 5, step 5100 out of total 10000\n",
      "loss: 23.037734, time: 20.697294, number of examples in current step: 5, step 5200 out of total 10000\n",
      "loss: 22.533047, time: 20.984664, number of examples in current step: 5, step 5300 out of total 10000\n",
      "loss: 21.818605, time: 20.536927, number of examples in current step: 5, step 5400 out of total 10000\n",
      "loss: 21.626095, time: 21.029142, number of examples in current step: 5, step 5500 out of total 10000\n",
      "loss: 19.186640, time: 20.506389, number of examples in current step: 5, step 5600 out of total 10000\n",
      "loss: 18.841879, time: 21.052580, number of examples in current step: 5, step 5700 out of total 10000\n",
      "loss: 19.867750, time: 20.716353, number of examples in current step: 5, step 5800 out of total 10000\n",
      "loss: 16.718751, time: 20.919875, number of examples in current step: 5, step 5900 out of total 10000\n",
      "loss: 13.844668, time: 20.654640, number of examples in current step: 5, step 6000 out of total 10000\n",
      "loss: 13.259359, time: 21.294722, number of examples in current step: 5, step 6100 out of total 10000\n",
      "loss: 12.555993, time: 20.735506, number of examples in current step: 5, step 6200 out of total 10000\n",
      "loss: 15.363859, time: 21.011957, number of examples in current step: 5, step 6300 out of total 10000\n",
      "loss: 16.355932, time: 20.613020, number of examples in current step: 5, step 6400 out of total 10000\n",
      "loss: 14.205648, time: 21.048965, number of examples in current step: 5, step 6500 out of total 10000\n",
      "loss: 13.313909, time: 20.750437, number of examples in current step: 5, step 6600 out of total 10000\n",
      "loss: 16.069617, time: 21.005120, number of examples in current step: 5, step 6700 out of total 10000\n",
      "loss: 16.353159, time: 20.613764, number of examples in current step: 5, step 6800 out of total 10000\n",
      "loss: 10.449840, time: 21.011440, number of examples in current step: 5, step 6900 out of total 10000\n",
      "loss: 7.821031, time: 20.688589, number of examples in current step: 5, step 7000 out of total 10000\n",
      "loss: 9.534725, time: 20.963867, number of examples in current step: 5, step 7100 out of total 10000\n",
      "loss: 9.384873, time: 20.649505, number of examples in current step: 9, step 7200 out of total 10000\n",
      "loss: 9.650093, time: 21.183623, number of examples in current step: 5, step 7300 out of total 10000\n",
      "loss: 8.970471, time: 20.680761, number of examples in current step: 5, step 7400 out of total 10000\n",
      "loss: 11.752754, time: 21.021969, number of examples in current step: 6, step 7500 out of total 10000\n",
      "loss: 11.919778, time: 20.702512, number of examples in current step: 5, step 7600 out of total 10000\n",
      "loss: 11.981617, time: 21.046392, number of examples in current step: 5, step 7700 out of total 10000\n",
      "loss: 11.779458, time: 20.753459, number of examples in current step: 5, step 7800 out of total 10000\n",
      "loss: 6.661400, time: 21.105260, number of examples in current step: 5, step 7900 out of total 10000\n",
      "loss: 5.817208, time: 20.653457, number of examples in current step: 5, step 8000 out of total 10000\n",
      "loss: 6.695193, time: 20.963968, number of examples in current step: 5, step 8100 out of total 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.945398, time: 20.959122, number of examples in current step: 5, step 8200 out of total 10000\n",
      "loss: 7.403578, time: 20.623628, number of examples in current step: 5, step 8300 out of total 10000\n",
      "loss: 7.579400, time: 21.010104, number of examples in current step: 5, step 8400 out of total 10000\n",
      "loss: 6.733897, time: 20.956976, number of examples in current step: 5, step 8500 out of total 10000\n",
      "loss: 7.400434, time: 21.315107, number of examples in current step: 5, step 8600 out of total 10000\n",
      "loss: 8.942719, time: 20.842602, number of examples in current step: 5, step 8700 out of total 10000\n",
      "loss: 8.192907, time: 21.137500, number of examples in current step: 5, step 8800 out of total 10000\n",
      "loss: 5.031124, time: 20.709420, number of examples in current step: 5, step 8900 out of total 10000\n",
      "loss: 4.819118, time: 21.070154, number of examples in current step: 6, step 9000 out of total 10000\n",
      "loss: 4.357930, time: 20.748780, number of examples in current step: 5, step 9100 out of total 10000\n",
      "loss: 4.545584, time: 21.223144, number of examples in current step: 5, step 9200 out of total 10000\n",
      "loss: 4.658168, time: 20.557300, number of examples in current step: 5, step 9300 out of total 10000\n",
      "loss: 5.264066, time: 21.249058, number of examples in current step: 5, step 9400 out of total 10000\n",
      "loss: 5.969067, time: 20.712935, number of examples in current step: 5, step 9500 out of total 10000\n",
      "loss: 5.285898, time: 21.363654, number of examples in current step: 5, step 9600 out of total 10000\n",
      "loss: 4.935408, time: 20.708985, number of examples in current step: 5, step 9700 out of total 10000\n",
      "loss: 5.457768, time: 21.089815, number of examples in current step: 5, step 9800 out of total 10000\n",
      "loss: 4.436776, time: 20.591032, number of examples in current step: 5, step 9900 out of total 10000\n",
      "loss: 4.003601, time: 21.361167, number of examples in current step: 5, step 10000 out of total 10000\n"
     ]
    }
   ],
   "source": [
    "summarizer.fit(\n",
    "            train_dataloader,\n",
    "            num_gpus=1,\n",
    "            gradient_accumulation_steps=2,\n",
    "            max_steps=MAX_STEPS,\n",
    "            lr=LEARNING_RATE,\n",
    "            warmup_steps=WARMUP_STEPS,\n",
    "            verbose=True,\n",
    "            report_every=REPORT_EVERY,\n",
    "            clip_grad_norm=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1217 19:20:14.048710 139802557667136 extractive_summarization.py:432] Saving model checkpoint to /tmp/tmpdym52i5i/fine_tuned/extsum_modelname_distilbert-base-uncased_quickrun_True.pt\n"
     ]
    }
   ],
   "source": [
    "summarizer.save_model(\"extsum_modelname_{0}_quickrun_{1}.pt\".format(MODEL_NAME, QUICK_RUN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dadendev/anaconda3/envs/cm3/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'transformers.modeling_distilbert.DistilBertModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# for loading a previously saved model\n",
    "import torch\n",
    "summarizer.model = torch.load(\"cnndm_transformersum_distilbert-base-uncased_bertsum_processed_data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "[ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)), or Recall-Oriented Understudy for Gisting Evaluation has been commonly used for evaluation text summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset=[]\n",
    "for i in test_dataset_generator():\n",
    "    eval_dataset.extend(i)\n",
    "target = [eval_dataset[i]['tgt_txt'] for i in range(len(eval_dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_eval_batch = [] \n",
    "for batch in get_sequential_dataloader(eval_dataset, is_labeled=True):\n",
    "    new_eval_batch.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_eval_batch = [] \n",
    "new_eval_dataset = [] \n",
    "j = 0\n",
    "for batch in get_sequential_dataloader(eval_dataset, is_labeled=True):\n",
    "    new_eval_dataset.append(ExtSumProcessor.get_inputs(batch, MODEL_NAME))\n",
    "    new_eval_batch.append(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['turkey has blocked access to twitter and youtube after they refused a request to remove pictures of a prosecutor held during an armed siege last week .',\n",
       "  \"a turkish court imposed the blocks because images of the deadly siege were being shared on social media and ` deeply upset ' the wife and children of mehmet selim kiraz , the hostage who was killed .\",\n",
       "  \"the 46-year-old turkish prosecutor died in hospital when members of the revolutionary people 's liberation party-front ( dhkp-c ) stormed a courthouse and took him hostage .\",\n",
       "  'the dhkp-c is considered a terrorist group by turkey , the european union and us .',\n",
       "  'a turkish court has blocked access to twitter and youtube after they refused a request to remove pictures of prosecutor mehmet selim kiraz held during an armed siege last week',\n",
       "  'grief : the family of mehmet selim kiraz grieve over his coffin during his funeral at eyup sultan mosque in istanbul , turkey .',\n",
       "  'he died in hospital after he was taken hostage by the far-left organisation',\n",
       "  'two of his captors were killed when security forces took back the building where the far-left group was holding him .',\n",
       "  'gunshots were heard and smoke could be seen rising from the scene at the end of the six-hour stand-off .',\n",
       "  'mr kiraz , a father-of-two married to a judge who also worked at the courthouse , was targeted for his part in an investigation into the death of berkin elvan .',\n",
       "  'the 15-year-old was severely wounded after being hit on the head by a tear-gas canister fired by a police officer during anti-government protests in istanbul in june 2013 .',\n",
       "  'after spending 269 days in a coma , elvan eventually died on march 11 last year .',\n",
       "  \"his death , and the subsequent investigation , have since become a rallying point for the country 's far-left .\",\n",
       "  'gathering : prosecutors , lawyers and judges stand near a statue of lady justice during the funeral ceremony',\n",
       "  \"a british national , of polish origin but who has not been named , was arrested on saturday as part of an operation against the revolutionary people 's liberation party-front , according to reports .\",\n",
       "  \"a foreign office spokeswoman said this morning : ' i can confirm that a british national has been arrested in turkey and that we are offering consular assistance . '\",\n",
       "  'before imposing the blocks on the websites , turkish authorities had tried to prevent newspapers printing images taken during the siege last week .',\n",
       "  \"the newspapers were accused by the government of ` spreading terrorist propaganda ' in sharing the images of the hostage-taking .\",\n",
       "  \"presidential spokesman ibrahim kalin said : ` this has to do with the publishing of the prosecutor 's\",\n",
       "  \"what happened in the aftermath ( of the prosecutor 's\",\n",
       "  'killing ) is as grim as the incident itself .',\n",
       "  \"` the demand from the prosecutor 's office is that this image\",\n",
       "  'not be used anywhere in electronic platforms .',\n",
       "  '` the wife and children of prosecutor kiraz have been deeply',\n",
       "  \"the images are everywhere . '\",\n",
       "  \"he added : ' a request has been made to both twitter and youtube for the\",\n",
       "  'removal of the images and posts but they have not accepted it',\n",
       "  'and no response has been given .',\n",
       "  \"this decision has been taken through a court in istanbul . '\",\n",
       "  'critical : prosecutor mehmet selim kiraz was taken to hospital with gunshot wounds but died of his injuries',\n",
       "  'strength of feeling : elvan has since become an icon for the turkish far-left and his supporters accuse the authorities of covering up the circumstances and perpetrators of his death',\n",
       "  'google said it was working to restore service to the youtube',\n",
       "  'video-sharing site , which it owns .',\n",
       "  'working to restore access for its users .',\n",
       "  'facebook said it had complied with a turkish court order requiring it to restrict access to some content or face a block on its service .',\n",
       "  'a company spokesman said it would appeal the order .',\n",
       "  \"turkey 's telecoms regulator could not immediately be reached\",\n",
       "  'and there was no statement on its website .',\n",
       "  'this is not the first time that turkish authorities have imposed blocks on social media sites and networks .',\n",
       "  'in the run-up to local elections in march 2014 blocks were imposed after recordings circulated allegedly revealing corruption among senior officials .',\n",
       "  'figures provided by twitter revealed that turkey filed more requests to remove content from the social network than any other nation between july and december 2014 .'],\n",
       " ['deborah fuller has been banned from keeping animals after she dragged her dog behind her car , causing wounds as she drove at 30mph',\n",
       "  'a dog breeder and exhibitor who dragged her pet behind her car at a speed of 30mph and failed to get painful wounds to its paws and chest treated , has been banned from keeping animals and had her dogs confiscated .',\n",
       "  'deborah fuller , 56 , dragged her dog tango for 400 metres behind her car as she drove along the b1066 near long melford , essex .',\n",
       "  'the rhodesian ridgeback was left with injuries to all four paws as well as grazing to his chest and a deep wound on his elbow .',\n",
       "  \"he is believed to have somehow escaped from the boot of her car and was dragged along the single carriageway because his lead was attached to the vehicle 's tailgate .\",\n",
       "  \"fuller , of lawford , essex , denied causing unnecessary suffering to an animal by not taking it to the vets and failing to take steps to safely secure a dog within a vehicle , but was convicted following a hearing at chelmsford magistrates ' court .\",\n",
       "  'fuller has also been banned from keeping animals for five years and had her 27 other dogs confiscated .',\n",
       "  \"chairman of the bench anthony ealden said if tango had been taken to the vet earlier ` unnecessary suffering ' could have been avoided .\",\n",
       "  'he said : ` we believe for whatever reason , known only to yourself , you had no intention of getting veterinary treatment as a matter of urgency .',\n",
       "  \"` we do not accept your reason for delaying treatment as reasonable . '\",\n",
       "  'the incident took place on june 11 , 2014 , when the dog was seen being dragged along the b1006 behind the car .',\n",
       "  'tree surgeons working nearby spotted what had happened and tried to get fuller , who is a rhodesian ridgeback breeder and exhibitor , to stop her car .',\n",
       "  \"she did n't stop until she reached the end of the carriageway and they took her registration number and reported her to police who called the rspca , the court heard .\",\n",
       "  \"tango was later found by inspectors in an outbuilding at fuller 's home with bandages on his paws .\",\n",
       "  'he was taken to a vet and given treatment for his injuries , which took eight weeks .',\n",
       "  'tango was left with considerable injuries to his paws and stomach , as well as a deep elbow wound',\n",
       "  'tango , a rhodesian ridgeback , pictured before being injured by being dragged along the road',\n",
       "  'fuller claimed she had not been aware the rear hatch of her car had opened and claimed she had given the one-year-old dog first aid , and had already arranged for him to go to the vet when police turned up .',\n",
       "  \"mike fullerton , defending fuller , said : ` when deborah fuller was being restrained she asked why she was not allowed to take the dog to the vet . '\",\n",
       "  'rspca inspector sam garvey said after the sentencing : ` eyewitnesses report they saw the dog being dragged about 400 metres at a speed of 30mph .',\n",
       "  '` this must have been horrific for poor tango .',\n",
       "  'so painful , and so distressing .',\n",
       "  '` it is hard to say what caused tango to be dragged behind a moving car in this way , but by the time we found him , seven hours later , he was urgently in need of vet treatment .',\n",
       "  'the animal was taken to the vets and treated for the burns , suffered when he was dragged along the road',\n",
       "  \"judges ruled that the dog 's suffering could have been avoided if fuller had taken him to the vets earlier\",\n",
       "  '` he had injuries to the pads of all four feet , causing the black layer of skin to be removed .',\n",
       "  'he also had grazing to his chest area and a nasty deep wound to his elbow and leg area .',\n",
       "  \"` it took a period of eight weeks to heal the wounds and for his skin to grow back over his pads so he could walk without discomfort . '\",\n",
       "  'fuller was also ordered to pay # 3,000 costs , given a 12 month community order and a two month curfew from 7pm to 7am .',\n",
       "  'tango was taken to a vet for treatment after being found and has made a full recovery in foster care .',\n",
       "  'the court also allowed confiscation of all the animals owned by fuller , which are currently in rspca care .',\n",
       "  'tango was removed from fuller , along with more than 40 other dogs that were at her essex home',\n",
       "  \"fuller and her partner phil sheldrake , 59 , previously pleaded guilty to 16 charges of causing unnecessary suffering and failing to meet the dogs ' needs at colchester magistrates court in june .\",\n",
       "  'earlier this month the case was thrown out after the high court ruled that inspectors did have the correct warrant to seize 44 dogs from their essex home .',\n",
       "  \"tendring district council had been granted a warrant to investigate ` nuisance ' at the house , following complaints about noise and dog faeces .\",\n",
       "  'the council joined forces with the rspca and seized 44 dogs from the house , with the animal welfare charity claiming several of the animals were emaciated .',\n",
       "  'however the trial was halted when district judge kenneth sheraton said evidence gathered by inspectors was inadmissible because they did not have the correct warrant .'],\n",
       " [\"media personality miranda devine has apologised after calling a rugby player a ` tosser ' for celebrating a try using sign language .\",\n",
       "  'flanker david pocock scored a hat-trick of tries for australian super rugby team , the brumbies , who were on their way to a win against the highlanders at canberra stadium on friday night .',\n",
       "  'devine tweeted : ` did pocock actually do jazz hands when he celebrated a try ?!!!',\n",
       "  \"but unfortunately for devine , it was n't actually the hand shaking gesture that 's become popular recently - the flanker and former australian captain was actually doing sign language for a friend , which pocock pointed out in reply .\",\n",
       "  \"miranda devine has apologised after calling david pocock a ` tosser ' for celebrating a try using sign language\",\n",
       "  \"devine had assumed a gesture pocock had made after scoring a try on friday night was ` jazz hands '\",\n",
       "  'devine tweeted : ` did pocock actually do jazz hands when he celebrated a try ?!!!',\n",
       "  \"after the match , pocock responded to devine that she 'd misinterpreted his hand movements .\",\n",
       "  '` it was actually auslan/sign language for clapping .',\n",
       "  \"i have a friend who 's first language is auslan so it was for her ... ' he tweeted .\",\n",
       "  'ms devine then quickly changed her tune and apologised for being so harsh with her initial judgement .',\n",
       "  \"` that 's really nice .\",\n",
       "  \"glad it was n't jazz hands !\",\n",
       "  \"and congrats on your hat trick , ' she replied , alongside an emoji of two open hands .\",\n",
       "  'this emoji can be interpreted as showing praise for someone or -- fittingly -- jazz hands .',\n",
       "  '` it was actually auslan/sign language for clapping .',\n",
       "  \"i have a friend who 's first language is auslan so it was for her ... ' pocock tweeted in return\",\n",
       "  'ms devine then quickly changed her tune and apologised for being so harsh with her initial judgement',\n",
       "  'pocock was gracious in his reply , tweeting ` thanks , miranda .',\n",
       "  'also glad it was n\\'t \" jazz hands \" , \\' accompanied by a smiley face',\n",
       "  'pocock was gracious in his reply , tweeting ` thanks , miranda .',\n",
       "  'also glad it was n\\'t \" jazz hands \" , \\' accompanied by a smiley face .',\n",
       "  \"however , other social media users were n't as quick to forgive .\",\n",
       "  '` in fairness , devine apologised to pocock .',\n",
       "  \"but really : ( 1 ) what kind of adult writes a tweet like that ; and ( 2 ) what 's wrong with jazz hands , ' columnist benjamin law tweeted .\",\n",
       "  \"` egg , meet face , ' criag wilson wrote .\",\n",
       "  \"other social media users were n't as quick to forgive devine , despite her quick apology\",\n",
       "  \"but others were perfectly fine with jazz hands : ` am i the only one that thinks jazz hands would have been totally acceptable also ? '\",\n",
       "  \"others on social media were more understanding , taking the view that ` accidents happen ' .\",\n",
       "  \"` and you 've * never * made a dumb *** assumption/judgement ? '\",\n",
       "  \"the woman wrote to someone who had condemned ms devine 's comment .\",\n",
       "  \"` we 're all capable of foot-in-mouth . '\"],\n",
       " ['saracens director of rugby mark mccall lauded his young guns after their latest european heartache before declaring he has no intention of overspending in a competitive post-world cup transfer market .',\n",
       "  'mccall watched his side , which contained five english-qualified forwards in the starting pack , battle in vain before losing 13-9 to the clermont on saturday .',\n",
       "  \"saracens ' millionaire chairman nigel wray spent much of last week repeating his belief the cap should be scrapped in order for saracens to compete at europe 's top table , raising expectations they could be set to land a ` marquee ' player from outside the league whose wages would sit outside next season 's # 5.5 m cap .\",\n",
       "  'maro itoje ( second left ) was one of five england-qualified forwards in the saracens pack that faced clermont',\n",
       "  'mako vunipola tries to fend off clermont lock jamie cudmore during a ferocious contest',\n",
       "  'saracens director of rugby mark mccall saw his side come agonisingly close to reaching the final',\n",
       "  \"but mccall said : ` we know where we 'd like to improve our side and we 're prepared to wait for the right person .\",\n",
       "  'we do n\\'t want to jump in and get \" a name \" just because he \\'s available post-world cup .',\n",
       "  '` the fact our pack is as young as it is is incredibly exciting for us .',\n",
       "  \"they could be the mainstay of the club for the next four to five seasons . '\",\n",
       "  'billy vunipola ( left ) , jim hamilton and itoje leave the field following their 13-9 loss against clermont'],\n",
       " [\"it 's t20 season on the sub-continent and the world 's best players are about the pad up for the latest edition of the indian premier league , cricket 's most exciting and richest domestic tournament .\",\n",
       "  \"eight teams will play a total of 60 games over almost seven weeks across 12 venues all round india in a battle to be crowned champions of the tournament 's eighth edition , with the final taking place at eden gardens in kolkata on may 24 .\",\n",
       "  'can kolkata knight riders retain their title ?',\n",
       "  'will virat kohli lead the royal challengers bangalore to their first title ?',\n",
       "  \"can ms dhoni 's chennai super kings win their third crown ?\",\n",
       "  'and who are the players to watch out for ?',\n",
       "  'sportsmail tells you all you need to know in our guide to the 2015 indian premier league as india prepares for the spectacular cricket roadshow .',\n",
       "  'ms dhoni , pictured in the 2011 champions league , is looking to guide chennai super kings to a third title',\n",
       "  'the bright yellow jerseys of the super kings are one of the iconic sights of the indian premier league .',\n",
       "  'led by the superstar indian duo of ms dhoni and suresh raina , chennai are the most successful team in ipl history .',\n",
       "  'as well as their back-to-back victories in 2010 and 2011 , csk have been losing finalists three times and never failed to reach the last four .',\n",
       "  'in international players dhoni , raina , ravi ashwin , ravi jadeja and mohit sharma , the super kings have probably the best pool of indian talent in the tournament , which is key given that seven of the starting xi have to be domestic players .',\n",
       "  'the foreign talent is also strong , though , and includes new zealand captain brendon mccullum , south african faf du plessis and west indian all-rounder dwyane bravo .',\n",
       "  'one to watch : there are so many .',\n",
       "  'dhoni needs no introduction , raina is the top scorer in ipl history , but mccullum is one of the most exciting players in world cricket at the moment .',\n",
       "  'he hit the first ever ipl century in 2008 and will be looking to build on a brilliant world cup campaign .',\n",
       "  \"brendon mccullum 's aggressive brand of cricket led new zealand to the world cup final\",\n",
       "  \"# 1,740,000 - yuvraj singh 's salary , the highest in the 2015 tournament after he was picked up by delhi daredevils in the auction .\",\n",
       "  '3325 - runs suresh raina has scored , the most in tournament history .',\n",
       "  '2008 - year the ipl was first played .',\n",
       "  '119 - wickets taken by lasith malinga , the most in the history of the tournament .',\n",
       "  '60 - matches in the 2015 tournament .',\n",
       "  '46 - days the tournament lasts , beginning on april 8 and ending on may 24 .',\n",
       "  '12 - venues to be used in 2015 .',\n",
       "  '8 - teams in 2015 edition of the ipl .',\n",
       "  '3 - english players in the tournament - eoin morgan , ravi bopara and kevin pietersen .',\n",
       "  'the side from the capital are out to prove a point having never won the tournament and never even reached the final .',\n",
       "  'the daredevils have missed out on the semi-finals the last two seasons and will be looking to get back on track this year .',\n",
       "  'they are led by south african jp duminy and a lot of their overseas talent also comes from the same country in the form of quinton de kock , imran tahir and albie morkel , although sri lankan all-rounder angelo mathews is a handy player as well .',\n",
       "  \"world cup outcasts yuvraj singh , zaheer khan and amit mishra , all of whom featured in india 's successful 2011 team , will relish a return to the big stage and try and force themselves back into international reckoning .\",\n",
       "  'one to watch : in 22-year-old de kock , delhi have the most exciting young wicketkeeper batsman in the world .',\n",
       "  'de kock has already scored six one-day international tons but his highest score in the world cup was an unbeaten 78 .',\n",
       "  \"2011 world cup winner yuvraj singh will be out to prove a point after being left out of this year 's india team\",\n",
       "  'after years of just making up the numbers , the kings xi punjab lit up the 2014 tournament on their way to topping the table in the round-robin stage before losing in the final .',\n",
       "  \"punjab 's success in 2014 came largely thanks to their strong australian contingent , and this year they will be just as reliant on the likes of glenn maxwell , mitchell johnson , george bailey and shaun marsh .\",\n",
       "  'but the kings xi also have south african powerhouse david miller in their ranks along with sri lankan thisara perera .',\n",
       "  \"their indian talent is n't the strongest in the tournament but virender sehwag and murali vijay have both performed on the big stage for their country , and 21-year-old axar patel is one of the best young talents in india .\",\n",
       "  'one to watch : the destructive maxwell .',\n",
       "  \"one banner in the stands in chandigarh last year read ` glenndeep singh maxwell - the king of punjab ' .\",\n",
       "  \"it was maxwell 's power-hitting that almost led his team to the 2014 title and he showed again at the world cup just how dangerous he can be .\",\n",
       "  'glenn maxwell was one of the top run-scorers in the ipl last year and almost guided the kings xi to the title',\n",
       "  'the reigning champions knight riders have one of the most balanced teams in the tournament and will be looking to win their third ipl title in four years .',\n",
       "  \"gautam gambhir 's international career may have stalled , but he is still one of the most talented indian batsmen out there .\",\n",
       "  \"along with gambhir , yusuf pathan was also part of india 's 2011 world cup winning team while robin uthappa was the leading run-scorer last year with 660 .\",\n",
       "  'in terms of overseas talent , kolkata boast sunil narine , morne morkel , johan botha , andre russell , pat cummins , bangladeshi all-rounder shakib-al-hasan and dutchman ryan ten doeschate .',\n",
       "  \"one to watch : it 's rare for india to produce fast bowlers with genuine pace , but they have one in umesh yadav .\",\n",
       "  'kolkata will be looking for yadav to combine with morkel and narine as part of a fearsome bowling attack .',\n",
       "  'sunil narine , pictured in action for the kolkata knight riders in the 2012 indian premier league',\n",
       "  'the team that once featured the great sachin tendulkar finally won the ipl in 2013 , and they have an excellent chance to lift their second title this year .',\n",
       "  'in rohit sharma , harbhajan singh , pragyan ojha and parthiv patel , mumbai have a strong core of indian talent , but it is their overseas game-winners that makes them dangerous .',\n",
       "  'sri lankan fast bowler lasith malinga is the highest wicket-taker in tournament history with 119 , and he is joined by kieron pollard , aaron finch , corey anderson and josh hazlewood .',\n",
       "  'after losing in the eliminator against chennai last year , the mumbai indians will once again expect to reach the play-offs and mount a serious challenge for the title .',\n",
       "  'one to watch : the demon bowler that is malinga has made a habit of cleaning up batsmen in the ipl and was key in their success in 2013 .',\n",
       "  'he will once again lead this bowling attack .',\n",
       "  'mumbai indians batsman rohit sharma pictured in action for india against bangladesh at the world cup',\n",
       "  '2009 : deccan chargers ( defunct )',\n",
       "  \"since shane warne 's side won the inaugural ipl in 2008 , the rajasthan royals have only made the play-offs on one occasion since .\",\n",
       "  \"rajasthan 's short history has been eventful to say the lease .\",\n",
       "  'they were expelled by the bcci and then reinstated in 2010 and were also rocked by the spot-fixing scandal that saw former test match bowler shanthakumaran sreesanth banned for life .',\n",
       "  \"this year 's royals team features a strong australian presence in captain shane watson , steve smith and james faulkner as well as new zealand seamer tim southee .\",\n",
       "  'their indian talent lacks star quality , though , with ajinkya rahane , stuart binny and dhawal kulkarni the only men who have forced their way into the national side .',\n",
       "  'one to watch : australian smith has enjoyed a summer of dominating india and was instrumental in his country winning the world cup .',\n",
       "  'smith is a dangerous player with the bat , can hold up his end with the ball and is also one of the best fielders in the tournament .',\n",
       "  'steve smith will look to continue his excellent form into the indian premier league with rajasthan',\n",
       "  'bollywood actress shilpa shetty , pictured in 2009 , is a part owner of the rajasthan royals',\n",
       "  \"any batting order that contains chris gayle , ab de villers and kohli has half a chance , but it has been bangalore 's bowling that has held them back in recent years .\",\n",
       "  'bangalore have never won the ipl and have missed out on the play-offs altogether in the last three years .',\n",
       "  'the royal challengers paid big money in the auction to pick up dinesh karthik ( # 1.17 million ) in an attempt to shake off their underachievers tag .',\n",
       "  'but news that world cup player of the tournament mitchell starc will miss the start of the ipl will hurt their bowling attack .',\n",
       "  'one to watch : any of their big three batsmen really , but de villiers is often hailed as the most innovative batsman in world cricket for his stunning range of shots .',\n",
       "  'virat kohli and chris gayle pictured playing for royal challengers bangalore in the 2012 tournament',\n",
       "  'south african ab de villiers is often hailed as the most innovative batsman in world cricket',\n",
       "  'the newest team in the indian premier league , the sunrisers hyderabad are set to embark on their third campaign having been founded in 2013 and replaced the deccan chargers .',\n",
       "  'the sunrisers will be led up front by the explosive opening duo of david warner and shikhar dhawan and their middle order will feature new zealander kane williamson and english duo ravi bopara and eoin morgan .',\n",
       "  'hyderabad also landed kevin pietersen in the auction for what looked like a bargain of # 205,000 after he was released by the delhi daredevils , but the 34-year-old will not feature in the orange shirt unless they make the play-offs .',\n",
       "  \"pietersen reached the agreement with the sunrisers in order to return to surrey in an attempt to resurrect his england career , but the play-offs take place during the same week as england 's first test against new zealand at lord 's .\",\n",
       "  'the sunrisers also boast a a strong bowling line-up with foreign stars dale steyn and trent boult supported by indian internationals ishant sharma and bhuvneshwar kumar .',\n",
       "  \"one to watch : hyderabad 's strength is up top with captain warner and dhawan .\",\n",
       "  \"the indian batsman scored two centuries at the recent world cup and , like warner , has the power to take the game away from the opposition if he 's there for a while .\",\n",
       "  \"eoin morgan will look to move on quickly from england 's miserable world cup when he plays in the ipl\",\n",
       "  'kevin pietersen , here playing for delhi in 2012 , will join hyderabad if they make the play-offs']]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_eval_batch[0].src_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = new_eval_dataset[0]\n",
    "temp = (batch['x'], batch['segs'], batch['clss'], batch['mask'], batch['mask_cls'], batch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[  101,  4977,  2038,  ...,  4652,  6399,   102],\n",
       "         [  101, 15555, 12548,  ..., 12548,  3555,   102],\n",
       "         [  101,  2865,  6180,  ...,  2036,  5580,   102],\n",
       "         [  101,  7354, 19023,  ...,     0,     0,     0],\n",
       "         [  101,  2009,  1005,  ...,  2011,  6768,   102]]),\n",
       " 'segs': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
       " 'clss': tensor([[  0,  29,  73, 113, 135, 171, 205, 222, 248, 275, 315, 355, 375, 401,\n",
       "          421, 461, 495,   0,   0,   0,   0,   0],\n",
       "         [  0,  28,  76, 108, 138, 174, 227, 248, 276, 307, 323, 351, 385, 424,\n",
       "          447, 467, 488, 508,   0,   0,   0,   0],\n",
       "         [  0,  30,  73,  98, 147, 174, 198, 223, 248, 262, 290, 314, 323, 334,\n",
       "          359, 383, 397, 427, 450, 469, 489, 508],\n",
       "         [  0,  39,  72, 144, 170, 193, 214, 244, 272, 291, 312,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,  45,  95, 105, 123, 139, 151, 181, 205, 227, 256, 290, 344, 387,\n",
       "          398, 435, 460, 482,   0,   0,   0,   0]]),\n",
       " 'mask': tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True]]),\n",
       " 'mask_cls': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "          False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "          False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False, False, False, False, False, False, False, False,\n",
       "          False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "          False, False]]),\n",
       " 'labels': tensor([[0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\"\n",
    "new_batch = tuple(t.to(device) for t in temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ExtSumProcessor.get_inputs2(new_batch, summarizer.model_name, train_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[  101,  4977,  2038,  ...,  4652,  6399,   102],\n",
       "         [  101, 15555, 12548,  ..., 12548,  3555,   102],\n",
       "         [  101,  2865,  6180,  ...,  2036,  5580,   102],\n",
       "         [  101,  7354, 19023,  ...,     0,     0,     0],\n",
       "         [  101,  2009,  1005,  ...,  2011,  6768,   102]], device='cuda:0'),\n",
       " 'segs': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0'),\n",
       " 'clss': tensor([[  0,  29,  73, 113, 135, 171, 205, 222, 248, 275, 315, 355, 375, 401,\n",
       "          421, 461, 495,   0,   0,   0,   0,   0],\n",
       "         [  0,  28,  76, 108, 138, 174, 227, 248, 276, 307, 323, 351, 385, 424,\n",
       "          447, 467, 488, 508,   0,   0,   0,   0],\n",
       "         [  0,  30,  73,  98, 147, 174, 198, 223, 248, 262, 290, 314, 323, 334,\n",
       "          359, 383, 397, 427, 450, 469, 489, 508],\n",
       "         [  0,  39,  72, 144, 170, 193, 214, 244, 272, 291, 312,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,  45,  95, 105, 123, 139, 151, 181, 205, 227, 256, 290, 344, 387,\n",
       "          398, 435, 460, 482,   0,   0,   0,   0]], device='cuda:0'),\n",
       " 'mask': tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True]], device='cuda:0'),\n",
       " 'mask_cls': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "          False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "          False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True, False, False, False, False, False, False, False, False, False,\n",
       "          False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "          False, False]], device='cuda:0')}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = summarizer.model(**a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_scores = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2797, 1.4138, 1.3300, 1.2633, 1.2465, 1.0688, 1.1607, 1.0789, 1.0379,\n",
       "         1.0831, 1.1103, 1.0584, 1.0471, 1.0388, 1.0484, 1.0268, 1.0320, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [1.4332, 1.2015, 1.4598, 1.3369, 1.2130, 1.1952, 1.1715, 1.0674, 1.0351,\n",
       "         1.0249, 1.0774, 1.0215, 1.0350, 1.0662, 1.0975, 1.0838, 1.0363, 1.0532,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [1.3368, 1.5235, 1.1833, 1.1581, 1.3971, 1.1417, 1.1155, 1.0668, 1.0552,\n",
       "         1.0474, 1.0775, 1.0161, 1.0235, 1.0214, 1.0414, 1.0415, 1.0308, 1.0466,\n",
       "         1.0516, 1.0198, 1.0394, 1.0168],\n",
       "        [1.3996, 1.2992, 1.2811, 1.3704, 1.1763, 1.1740, 1.0317, 1.0152, 1.0304,\n",
       "         1.1223, 1.1197, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [1.2746, 1.4863, 1.1093, 1.2819, 1.1078, 1.0225, 1.0339, 1.2592, 1.0943,\n",
       "         1.1625, 1.0523, 1.0986, 1.0223, 1.0163, 1.0467, 1.0518, 1.1166, 1.0232,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sampler = SequentialSampler(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 1 µs, total: 10 µs\n",
      "Wall time: 17.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "prediction = summarizer.predict(new_eval_dataset, num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prediction_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[[  101,  4977,  2038,  ...,  4652,  6399,   102],\n",
      "         [  101, 15555, 12548,  ..., 12548,  3555,   102],\n",
      "         [  101,  2865,  6180,  ...,  2036,  5580,   102],\n",
      "         [  101,  7354, 19023,  ...,     0,     0,     0],\n",
      "         [  101,  2009,  1005,  ...,  2011,  6768,   102]]]), 'segs': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 1, 1, 1],\n",
      "         [0, 0, 0,  ..., 1, 1, 1],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 1, 1, 1]]]), 'clss': tensor([[[  0,  29,  73, 113, 135, 171, 205, 222, 248, 275, 315, 355, 375, 401,\n",
      "          421, 461, 495,   0,   0,   0,   0,   0],\n",
      "         [  0,  28,  76, 108, 138, 174, 227, 248, 276, 307, 323, 351, 385, 424,\n",
      "          447, 467, 488, 508,   0,   0,   0,   0],\n",
      "         [  0,  30,  73,  98, 147, 174, 198, 223, 248, 262, 290, 314, 323, 334,\n",
      "          359, 383, 397, 427, 450, 469, 489, 508],\n",
      "         [  0,  39,  72, 144, 170, 193, 214, 244, 272, 291, 312,   0,   0,   0,\n",
      "            0,   0,   0,   0,   0,   0,   0,   0],\n",
      "         [  0,  45,  95, 105, 123, 139, 151, 181, 205, 227, 256, 290, 344, 387,\n",
      "          398, 435, 460, 482,   0,   0,   0,   0]]]), 'mask': tensor([[[ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]]), 'mask_cls': tensor([[[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "          False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "          False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True, False, False, False, False, False, False, False, False, False,\n",
      "          False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "          False, False]]]), 'labels': tensor([[[0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])}\n",
      "{'x': tensor([[  101,  4977,  2038,  ...,  4652,  6399,   102],\n",
      "        [  101, 15555, 12548,  ..., 12548,  3555,   102],\n",
      "        [  101,  2865,  6180,  ...,  2036,  5580,   102],\n",
      "        [  101,  7354, 19023,  ...,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  ...,  2011,  6768,   102]], device='cuda:0'), 'segs': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0'), 'clss': tensor([[  0,  29,  73, 113, 135, 171, 205, 222, 248, 275, 315, 355, 375, 401,\n",
      "         421, 461, 495,   0,   0,   0,   0,   0],\n",
      "        [  0,  28,  76, 108, 138, 174, 227, 248, 276, 307, 323, 351, 385, 424,\n",
      "         447, 467, 488, 508,   0,   0,   0,   0],\n",
      "        [  0,  30,  73,  98, 147, 174, 198, 223, 248, 262, 290, 314, 323, 334,\n",
      "         359, 383, 397, 427, 450, 469, 489, 508],\n",
      "        [  0,  39,  72, 144, 170, 193, 214, 244, 272, 291, 312,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,  45,  95, 105, 123, 139, 151, 181, 205, 227, 256, 290, 344, 387,\n",
      "         398, 435, 460, 482,   0,   0,   0,   0]], device='cuda:0'), 'mask': tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True]], device='cuda:0'), 'mask_cls': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "prediction_list = list(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-d2f2d3501021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_batch' is not defined"
     ]
    }
   ],
   "source": [
    "len(eval_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sentence_score=prediction_list[0]\n",
    "selected_ids = np.argsort(-sentence_score, 1)\n",
    "#prediction_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  0,  3,  4,  6, 10,  9,  7,  5, 11, 14, 12, 13,  8, 16,\n",
       "        15, 20, 17, 18, 19, 21],\n",
       "       [ 2,  0,  3,  4,  1,  5,  6, 14, 15, 10,  7, 13, 17, 16,  8, 12,\n",
       "         9, 11, 20, 18, 19, 21],\n",
       "       [ 1,  4,  0,  2,  3,  5,  6, 10,  7,  8, 18,  9, 17, 15, 14, 20,\n",
       "        16, 12, 13, 19, 21, 11],\n",
       "       [ 0,  3,  1,  2,  4,  5,  9, 10,  6,  8,  7, 20, 11, 12, 13, 14,\n",
       "        15, 16, 17, 18, 19, 21],\n",
       "       [ 1,  3,  0,  7,  9, 16,  2,  4, 11,  8, 10, 15, 14,  6, 17,  5,\n",
       "        12, 13, 18, 19, 20, 21]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_seperator=\"<q>\",\n",
    "top_n=3,\n",
    "block_trigram=True,\n",
    "verbose=True,\n",
    "cal_lead=False,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 1  2  0  3  4  6 10  9  7  5 11 14 12 13  8 16 15 20 17 18 19 21]\n",
      " [ 2  0  3  4  1  5  6 14 15 10  7 13 17 16  8 12  9 11 20 18 19 21]\n",
      " [ 1  4  0  2  3  5  6 10  7  8 18  9 17 15 14 20 16 12 13 19 21 11]\n",
      " [ 0  3  1  2  4  5  9 10  6  8  7 20 11 12 13 14 15 16 17 18 19 21]\n",
      " [ 1  3  0  7  9 16  2  4 11  8 10 15 14  6 17  5 12 13 18 19 20 21]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'join'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-57d8f1d4ff66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#selected_ids = np.argsort(-sent_scores, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print(selected_ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtemp_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_eval_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_targe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-4ed457173a14>\u001b[0m in \u001b[0;36mget_pred\u001b[0;34m(batch, sent_scores, cal_lead)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# _pred = '<q>'.join(_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0m_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_seperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_str\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'join'"
     ]
    }
   ],
   "source": [
    "for i in range(len(new_eval_batch)):\n",
    "#for (batch, sent_scores) in zip(new_eval_batch, prediction_list):\n",
    "    sent_scores = prediction_list[i]\n",
    "    print(type(prediction_list[0]))\n",
    "    #selected_ids = np.argsort(-sent_scores, 1)\n",
    "    #print(selected_ids)\n",
    "    temp_pred, temp_target = get_pred(new_eval_batch[i], sent_scores)\n",
    "    print(temp_pred[0])\n",
    "    print(temp_targe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ngrams(n, text):\n",
    "    ngram_set = set()\n",
    "    text_length = len(text)\n",
    "    max_index_ngram_start = text_length - n\n",
    "    for i in range(max_index_ngram_start + 1):\n",
    "        ngram_set.add(tuple(text[i : i + n]))\n",
    "    return ngram_set\n",
    "\n",
    "def _block_tri(c, p):\n",
    "    tri_c = _get_ngrams(3, c.split())\n",
    "    for s in p:\n",
    "        tri_s = _get_ngrams(3, s.split())\n",
    "        if len(tri_c.intersection(tri_s)) > 0:\n",
    "            return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(batch, sent_scores, cal_lead=False, sentence_seperator='<q>'):\n",
    "    print(type(sent_scores))\n",
    "    selected_ids = np.argsort(-sent_scores, 1)\n",
    "    #print(selected_ids)\n",
    "    if cal_lead:\n",
    "        selected_ids = list(range(batch.clss.size(1))) * len(batch.clss)\n",
    "    print(selected_ids)\n",
    "    pred = []\n",
    "    target = []\n",
    "    for i, idx in enumerate(selected_ids):\n",
    "        _pred = []\n",
    "        if len(batch.src_str[i]) == 0:\n",
    "            pred.append(\"\")\n",
    "            continue\n",
    "        for j in selected_ids[i][: len(batch.src_str[i])]:\n",
    "            if j >= len(batch.src_str[i]):\n",
    "                continue\n",
    "            candidate = batch.src_str[i][j].strip()\n",
    "            if block_trigram:\n",
    "                if not _block_tri(candidate, _pred):\n",
    "                    _pred.append(candidate)\n",
    "            else:\n",
    "                _pred.append(candidate)\n",
    "\n",
    "            # only select the top 3\n",
    "            if len(_pred) == top_n:\n",
    "                break\n",
    "\n",
    "        # _pred = '<q>'.join(_pred)\n",
    "        _pred = sentence_seperator.join(_pred)\n",
    "        pred.append(_pred.strip())\n",
    "        target.append(batch.tgt_str[i])\n",
    "    print(\"=======================\")\n",
    "    print(pred)\n",
    "    print(\"=======================\")\n",
    "    print(target)\n",
    "    return pred, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 2)\n",
      "cuda\n",
      "CPU times: user 2min 47s, sys: 55.2 s, total: 3min 42s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "prediction = summarizer.predict(get_sequential_dataloader(test_dataset), num_gpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 4)\n",
      "cuda\n",
      "CPU times: user 5min 14s, sys: 1min 56s, total: 7min 10s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "prediction = summarizer.predict(get_sequential_dataloader(test_dataset), num_gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 4)\n",
      "cuda\n",
      "CPU times: user 5min 15s, sys: 1min 57s, total: 7min 13s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "prediction = summarizer.predict(get_sequential_dataloader(test_dataset), num_gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.8 s, sys: 18 s, total: 1min 14s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "prediction = summarizer.predict(get_sequential_dataloader(test_dataset), num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 13s, sys: 1min 55s, total: 7min 9s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "prediction = summarizer.predict(get_sequential_dataloader(test_dataset), num_gpus=4,)\n",
    "#prediction = summarizer.predict(get_dataloader(test_dataset_generator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 13s, sys: 1min 57s, total: 7min 11s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction = summarizer.predict(get_sequential_dataloader(test_dataset), num_gpus=4,)\n",
    "#prediction = summarizer.predict(get_dataloader(test_dataset_generator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11489"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.predict_target', '1.predict_target', '2.predict_target', '3.predict_target']\n"
     ]
    }
   ],
   "source": [
    "file_numbers = range(0,4)\n",
    "filenames = [\"{}.predict\".format(i) for i in file_numbers]\n",
    "print(filenames)\n",
    "prediction = []\n",
    "for i in filenames:\n",
    "    prediction.extend(torch.load(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.load(\"0.predict\")\n",
    "target = torch.load(\"0.target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11489"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11489"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"deborah fuller has been banned from keeping animals after she dragged her dog behind her car , causing wounds as she drove at 30mph<q>the rhodesian ridgeback was left with injuries to all four paws as well as grazing to his chest and a deep wound on his elbow .<q>he is believed to have somehow escaped from the boot of her car and was dragged along the single carriageway because his lead was attached to the vehicle 's tailgate .\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"warning : graphic content - deborah fuller dragged her one-year-old dog behind her car for 400 metres at a speed of around 30mph<q>animal was left with wounds to paws and elbow and grazes on his stomach<q>fuller , a breeder , failed to quickly take the animal to vet which could have reduced the ` unnecessary suffering ' of the rhodesian ridgeback<q>she was banned from keeping animals for five years and given a curfew\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11489\n",
      "11489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 21:58:09,503 [MainThread  ] [INFO ]  Writing summaries.\n",
      "I1218 21:58:09.503323 140578347489088 pyrouge.py:525] Writing summaries.\n",
      "2019-12-18 21:58:09,505 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./results/tmp71b7igdt/system and model files to ./results/tmp71b7igdt/model.\n",
      "I1218 21:58:09.505720 140578347489088 pyrouge.py:518] Processing summaries. Saving system files to ./results/tmp71b7igdt/system and model files to ./results/tmp71b7igdt/model.\n",
      "2019-12-18 21:58:09,506 [MainThread  ] [INFO ]  Processing files in ./results/rouge-tmp-2019-12-18-21-58-08/candidate/.\n",
      "I1218 21:58:09.506670 140578347489088 pyrouge.py:43] Processing files in ./results/rouge-tmp-2019-12-18-21-58-08/candidate/.\n",
      "2019-12-18 21:58:10,667 [MainThread  ] [INFO ]  Saved processed files to ./results/tmp71b7igdt/system.\n",
      "I1218 21:58:10.667188 140578347489088 pyrouge.py:53] Saved processed files to ./results/tmp71b7igdt/system.\n",
      "2019-12-18 21:58:10,668 [MainThread  ] [INFO ]  Processing files in ./results/rouge-tmp-2019-12-18-21-58-08/reference/.\n",
      "I1218 21:58:10.668822 140578347489088 pyrouge.py:43] Processing files in ./results/rouge-tmp-2019-12-18-21-58-08/reference/.\n",
      "2019-12-18 21:58:11,807 [MainThread  ] [INFO ]  Saved processed files to ./results/tmp71b7igdt/model.\n",
      "I1218 21:58:11.807205 140578347489088 pyrouge.py:53] Saved processed files to ./results/tmp71b7igdt/model.\n",
      "2019-12-18 21:58:11,888 [MainThread  ] [INFO ]  Written ROUGE configuration to ./results/tmp7fy_q2kz/rouge_conf.xml\n",
      "I1218 21:58:11.888963 140578347489088 pyrouge.py:354] Written ROUGE configuration to ./results/tmp7fy_q2kz/rouge_conf.xml\n",
      "2019-12-18 21:58:11,890 [MainThread  ] [INFO ]  Running ROUGE with command /dadendev/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /dadendev/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./results/tmp7fy_q2kz/rouge_conf.xml\n",
      "I1218 21:58:11.890037 140578347489088 pyrouge.py:372] Running ROUGE with command /dadendev/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /dadendev/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./results/tmp7fy_q2kz/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.52266 (95%-conf.int. 0.51986 - 0.52568)\n",
      "1 ROUGE-1 Average_P: 0.34674 (95%-conf.int. 0.34446 - 0.34907)\n",
      "1 ROUGE-1 Average_F: 0.40313 (95%-conf.int. 0.40106 - 0.40530)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.22634 (95%-conf.int. 0.22379 - 0.22906)\n",
      "1 ROUGE-2 Average_P: 0.14922 (95%-conf.int. 0.14747 - 0.15107)\n",
      "1 ROUGE-2 Average_F: 0.17380 (95%-conf.int. 0.17189 - 0.17581)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.47360 (95%-conf.int. 0.47089 - 0.47638)\n",
      "1 ROUGE-L Average_P: 0.31457 (95%-conf.int. 0.31237 - 0.31671)\n",
      "1 ROUGE-L Average_F: 0.36555 (95%-conf.int. 0.36355 - 0.36758)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rouge_transformer = get_rouge(prediction, target, \"./results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11489\n",
      "11489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-18 03:30:54,263 [MainThread  ] [INFO ]  Writing summaries.\n",
      "I1218 03:30:54.263799 140518432167744 pyrouge.py:525] Writing summaries.\n",
      "2019-12-18 03:30:54,265 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./results/tmpctvsqcxg/system and model files to ./results/tmpctvsqcxg/model.\n",
      "I1218 03:30:54.265614 140518432167744 pyrouge.py:518] Processing summaries. Saving system files to ./results/tmpctvsqcxg/system and model files to ./results/tmpctvsqcxg/model.\n",
      "2019-12-18 03:30:54,266 [MainThread  ] [INFO ]  Processing files in ./results/rouge-tmp-2019-12-18-03-30-53/candidate/.\n",
      "I1218 03:30:54.266546 140518432167744 pyrouge.py:43] Processing files in ./results/rouge-tmp-2019-12-18-03-30-53/candidate/.\n",
      "2019-12-18 03:30:55,387 [MainThread  ] [INFO ]  Saved processed files to ./results/tmpctvsqcxg/system.\n",
      "I1218 03:30:55.387292 140518432167744 pyrouge.py:53] Saved processed files to ./results/tmpctvsqcxg/system.\n",
      "2019-12-18 03:30:55,389 [MainThread  ] [INFO ]  Processing files in ./results/rouge-tmp-2019-12-18-03-30-53/reference/.\n",
      "I1218 03:30:55.389828 140518432167744 pyrouge.py:43] Processing files in ./results/rouge-tmp-2019-12-18-03-30-53/reference/.\n",
      "2019-12-18 03:30:56,517 [MainThread  ] [INFO ]  Saved processed files to ./results/tmpctvsqcxg/model.\n",
      "I1218 03:30:56.517802 140518432167744 pyrouge.py:53] Saved processed files to ./results/tmpctvsqcxg/model.\n",
      "2019-12-18 03:30:56,600 [MainThread  ] [INFO ]  Written ROUGE configuration to ./results/tmpmzktjbfq/rouge_conf.xml\n",
      "I1218 03:30:56.600011 140518432167744 pyrouge.py:354] Written ROUGE configuration to ./results/tmpmzktjbfq/rouge_conf.xml\n",
      "2019-12-18 03:30:56,601 [MainThread  ] [INFO ]  Running ROUGE with command /dadendev/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /dadendev/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./results/tmpmzktjbfq/rouge_conf.xml\n",
      "I1218 03:30:56.601049 140518432167744 pyrouge.py:372] Running ROUGE with command /dadendev/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /dadendev/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./results/tmpmzktjbfq/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.54208 (95%-conf.int. 0.53930 - 0.54484)\n",
      "1 ROUGE-1 Average_P: 0.36866 (95%-conf.int. 0.36651 - 0.37103)\n",
      "1 ROUGE-1 Average_F: 0.42466 (95%-conf.int. 0.42276 - 0.42672)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.24754 (95%-conf.int. 0.24499 - 0.25011)\n",
      "1 ROUGE-2 Average_P: 0.16856 (95%-conf.int. 0.16669 - 0.17049)\n",
      "1 ROUGE-2 Average_F: 0.19382 (95%-conf.int. 0.19190 - 0.19576)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.49419 (95%-conf.int. 0.49159 - 0.49685)\n",
      "1 ROUGE-L Average_P: 0.33667 (95%-conf.int. 0.33456 - 0.33889)\n",
      "1 ROUGE-L Average_F: 0.38754 (95%-conf.int. 0.38561 - 0.38960)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rouge_transformer = get_rouge(prediction, target, \"./results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marseille prosecutor says `` so far no videos were used in the crash investigation `` despite media reports .<q>journalists at bild and paris match are `` very confident `` the video clip is real , an editor says .<q>andreas lubitz had informed his lufthansa training school of an episode of severe depression , airline says .<q>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]['tgt_txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"marseille , france ( cnn ) the french prosecutor leading an investigation into the crash of germanwings flight 9525 insisted wednesday that he was not aware of any video footage from on board the plane .<q>all 150 on board were killed .<q>cell phones have been collected at the site , he said , but that they `` had n't been exploited yet . ``\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marseille , france ( cnn ) the french prosecutor leading an investigation into the crash of germanwings flight 9525 insisted wednesday that he was not aware of any video footage from on board the plane .',\n",
       " 'marseille prosecutor brice robin told cnn that `` so far no videos were used in the crash investigation . ``',\n",
       " 'he added , `` a person who has such a video needs to immediately give it to the investigators . ``',\n",
       " \"robin 's comments follow claims by two magazines , german daily bild and french paris match , of a cell phone video showing the harrowing final seconds from on board germanwings flight 9525 as it crashed into the french alps .\",\n",
       " 'all 150 on board were killed .',\n",
       " 'paris match and bild reported that the video was recovered from a phone at the wreckage site .',\n",
       " 'the two publications described the supposed video , but did not post it on their websites .',\n",
       " 'the publications said that they watched the video , which was found by a source close to the investigation . ``',\n",
       " \"one can hear cries of ` my god ' in several languages , `` paris match reported . ``\",\n",
       " 'metallic banging can also be heard more than three times , perhaps of the pilot trying to open the cockpit door with a heavy object .',\n",
       " 'towards the end , after a heavy shake , stronger than the others , the screaming intensifies .',\n",
       " '`` it is a very disturbing scene , `` said julian reichelt , editor-in-chief of bild online .',\n",
       " \"an official with france 's accident investigation agency , the bea , said the agency is not aware of any such video .\",\n",
       " 'lt. col. jean-marc menichini , a french gendarmerie spokesman in charge of communications on rescue efforts around the germanwings crash site , told cnn that the reports were `` completely wrong `` and `` unwarranted . ``',\n",
       " \"cell phones have been collected at the site , he said , but that they `` had n't been exploited yet . ``\",\n",
       " 'menichini said he believed the cell phones would need to be sent to the criminal research institute in rosny sous-bois , near paris , in order to be analyzed by specialized technicians working hand-in-hand with investigators .',\n",
       " 'but none of the cell phones found so far have been sent to the institute , menichini said .',\n",
       " 'asked whether staff involved in the search could have leaked a memory card to the media , menichini answered with a categorical `` no . ``',\n",
       " 'reichelt told `` erin burnett : outfront `` that he had watched the video and stood by the report , saying bild and paris match are `` very confident `` that the clip is real .',\n",
       " \"he noted that investigators only revealed they 'd recovered cell phones from the crash site after bild and paris match published their reports . ``\",\n",
       " 'that is something we did not know before .',\n",
       " \"... overall we can say many things of the investigation were n't revealed by the investigation at the beginning , `` he said .\",\n",
       " 'what was mental state of germanwings co-pilot ?',\n",
       " \"german airline lufthansa confirmed tuesday that co-pilot andreas lubitz had battled depression years before he took the controls of germanwings flight 9525 , which he 's accused of deliberately crashing last week in the french alps .\",\n",
       " 'lubitz told his lufthansa flight training school in 2009 that he had a `` previous episode of severe depression , `` the airline said tuesday .',\n",
       " 'email correspondence between lubitz and the school discovered in an internal investigation , lufthansa said , included medical documents he submitted in connection with resuming his flight training .',\n",
       " \"the announcement indicates that lufthansa , the parent company of germanwings , knew of lubitz 's battle with depression , allowed him to continue training and ultimately put him in the cockpit .\",\n",
       " 'lufthansa , whose ceo carsten spohr previously said lubitz was 100 % fit to fly , described its statement tuesday as a `` swift and seamless clarification `` and said it was sharing the information and documents -- including training and medical records -- with public prosecutors .',\n",
       " 'spohr traveled to the crash site wednesday , where recovery teams have been working for the past week to recover human remains and plane debris scattered across a steep mountainside .',\n",
       " 'he saw the crisis center set up in seyne-les-alpes , laid a wreath in the village of le vernet , closer to the crash site , where grieving families have left flowers at a simple stone memorial .',\n",
       " 'menichini told cnn late tuesday that no visible human remains were left at the site but recovery teams would keep searching .',\n",
       " 'french president francois hollande , speaking tuesday , said that it should be possible to identify all the victims using dna analysis by the end of the week , sooner than authorities had previously suggested .',\n",
       " \"in the meantime , the recovery of the victims ' personal belongings will start wednesday , menichini said .\",\n",
       " 'among those personal belongings could be more cell phones belonging to the 144 passengers and six crew on board .',\n",
       " 'check out the latest from our correspondents .',\n",
       " \"the details about lubitz 's correspondence with the flight school during his training were among several developments as investigators continued to delve into what caused the crash and lubitz 's possible motive for downing the jet .\",\n",
       " 'a lufthansa spokesperson told cnn on tuesday that lubitz had a valid medical certificate , had passed all his examinations and `` held all the licenses required . ``',\n",
       " \"earlier , a spokesman for the prosecutor 's office in dusseldorf , christoph kumpa , said medical records reveal lubitz suffered from suicidal tendencies at some point before his aviation career and underwent psychotherapy before he got his pilot 's license .\",\n",
       " \"kumpa emphasized there 's no evidence suggesting lubitz was suicidal or acting aggressively before the crash .\",\n",
       " \"investigators are looking into whether lubitz feared his medical condition would cause him to lose his pilot 's license , a european government official briefed on the investigation told cnn on tuesday .\",\n",
       " \"while flying was `` a big part of his life , `` the source said , it 's only one theory being considered .\",\n",
       " 'another source , a law enforcement official briefed on the investigation , also told cnn that authorities believe the primary motive for lubitz to bring down the plane was that he feared he would not be allowed to fly because of his medical problems .',\n",
       " \"lubitz 's girlfriend told investigators he had seen an eye doctor and a neuropsychologist , both of whom deemed him unfit to work recently and concluded he had psychological issues , the european government official said .\",\n",
       " \"but no matter what details emerge about his previous mental health struggles , there 's more to the story , said brian russell , a forensic psychologist . ``\",\n",
       " \"psychology can explain why somebody would turn rage inward on themselves about the fact that maybe they were n't going to keep doing their job and they 're upset about that and so they 're suicidal , `` he said . ``\",\n",
       " \"but there is no mental illness that explains why somebody then feels entitled to also take that rage and turn it outward on 149 other people who had nothing to do with the person 's problems . ``\",\n",
       " 'germanwings crash compensation : what we know .',\n",
       " 'who was the captain of germanwings flight 9525 ?',\n",
       " \"cnn 's margot haddad reported from marseille and pamela brown from dusseldorf , while laura smith-spark wrote from london .\",\n",
       " \"cnn 's frederik pleitgen , pamela boykoff , antonia mortensen , sandrine amiel and anna-maja rappard contributed to this report .\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]['src_txt']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6 cm3",
   "language": "python",
   "name": "cm3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
