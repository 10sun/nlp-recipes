{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "nlp_path = os.path.abspath(\"../../\")\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "sys.path.insert(0, \"./\")\n",
    "sys.path.insert(0, \"./BertSum\")\n",
    "sys.path.insert(0, \"/dadendev/PreSumm2/PreSumm/\")\n",
    "sys.path.insert(0, \"/dadendev/PreSumm2/PreSumm/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_nlp.dataset.chinese_cnndm_style import ChineseCNNDMSummarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0lines [00:00, ?lines/s]Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.793 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "\n",
      "0lines [00:00, ?lines/s]\n",
      "0lines [00:00, ?lines/s]\n",
      "0lines [00:00, ?lines/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = ChineseCNNDMSummarization(top_n=-1, local_cache_path='/dadendev/PreSumm/raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['中新',\n",
       "  '中新社',\n",
       "  '休斯',\n",
       "  '休斯敦',\n",
       "  '斯敦',\n",
       "  '10',\n",
       "  '月',\n",
       "  '24',\n",
       "  '日电',\n",
       "  '',\n",
       "  '',\n",
       "  '美国',\n",
       "  '国人',\n",
       "  '人口',\n",
       "  '人口普查',\n",
       "  '普查',\n",
       "  '普查局',\n",
       "  '24',\n",
       "  '日',\n",
       "  '发布',\n",
       "  '的',\n",
       "  '一份',\n",
       "  '报告',\n",
       "  '显示',\n",
       "  '',\n",
       "  '',\n",
       "  '随着',\n",
       "  '美国',\n",
       "  '国人',\n",
       "  '人口',\n",
       "  '人口老龄化',\n",
       "  '老龄',\n",
       "  '老龄化',\n",
       "  '',\n",
       "  '',\n",
       "  '美国',\n",
       "  '的',\n",
       "  '人口',\n",
       "  '增长',\n",
       "  '将',\n",
       "  '放缓',\n",
       "  '',\n",
       "  ''],\n",
       " ['预计', '到', '2058', '年', '美国', '国人', '人口', '将', '突破', '4', '亿', '', ''],\n",
       " ['美联社',\n",
       "  '联社',\n",
       "  '消息',\n",
       "  '',\n",
       "  '',\n",
       "  '当日',\n",
       "  '',\n",
       "  '',\n",
       "  '在',\n",
       "  '由',\n",
       "  '美国',\n",
       "  '南方',\n",
       "  '南方人',\n",
       "  '方人',\n",
       "  '人口',\n",
       "  '协会',\n",
       "  '举办',\n",
       "  '的',\n",
       "  '会议',\n",
       "  '上',\n",
       "  '',\n",
       "  '',\n",
       "  '美国',\n",
       "  '国人',\n",
       "  '人口',\n",
       "  '人口普查',\n",
       "  '普查',\n",
       "  '普查局',\n",
       "  '发布',\n",
       "  '了',\n",
       "  '一份',\n",
       "  '题为',\n",
       "  '',\n",
       "  '',\n",
       "  '美国',\n",
       "  '国人',\n",
       "  '人口',\n",
       "  '的',\n",
       "  '拐点',\n",
       "  '',\n",
       "  '2020',\n",
       "  '年',\n",
       "  '至',\n",
       "  '2060',\n",
       "  '年',\n",
       "  '人口',\n",
       "  '人口预测',\n",
       "  '预测',\n",
       "  '',\n",
       "  '',\n",
       "  '的',\n",
       "  '报告',\n",
       "  '',\n",
       "  ''],\n",
       " ['报告',\n",
       "  '显示',\n",
       "  '',\n",
       "  '',\n",
       "  '预计',\n",
       "  '美国',\n",
       "  '到',\n",
       "  '2058',\n",
       "  '年',\n",
       "  '将',\n",
       "  '突破',\n",
       "  '4',\n",
       "  '亿',\n",
       "  '人口',\n",
       "  '',\n",
       "  ''],\n",
       " ['如今', '', '', '美国', '约', '有', '3', ''],\n",
       " ['26', '亿', '人', '', ''],\n",
       " ['这',\n",
       "  '意味',\n",
       "  '意味着',\n",
       "  '在',\n",
       "  '未来',\n",
       "  '40',\n",
       "  '年内',\n",
       "  '',\n",
       "  '',\n",
       "  '美国',\n",
       "  '将',\n",
       "  '增加',\n",
       "  '7900',\n",
       "  '万',\n",
       "  '人',\n",
       "  '',\n",
       "  ''],\n",
       " ['报告',\n",
       "  '称',\n",
       "  '',\n",
       "  '',\n",
       "  '近年',\n",
       "  '近年来',\n",
       "  '年来',\n",
       "  '',\n",
       "  '',\n",
       "  '美国',\n",
       "  '国人',\n",
       "  '人口',\n",
       "  '人口老龄化',\n",
       "  '老龄',\n",
       "  '老龄化',\n",
       "  '日趋',\n",
       "  '日趋严重',\n",
       "  '严重',\n",
       "  '',\n",
       "  ''],\n",
       " ['预计',\n",
       "  '到',\n",
       "  '2060',\n",
       "  '年',\n",
       "  '',\n",
       "  '',\n",
       "  '美国',\n",
       "  '国人',\n",
       "  '人口',\n",
       "  '年龄',\n",
       "  '中位数',\n",
       "  '位数',\n",
       "  '将',\n",
       "  '从',\n",
       "  '现在',\n",
       "  '的',\n",
       "  '38',\n",
       "  '岁',\n",
       "  '提高',\n",
       "  '到',\n",
       "  '43',\n",
       "  '岁',\n",
       "  '',\n",
       "  ''],\n",
       " ['另',\n",
       "  '据',\n",
       "  '联合',\n",
       "  '联合国',\n",
       "  '预测',\n",
       "  '',\n",
       "  '',\n",
       "  '到',\n",
       "  '2050',\n",
       "  '年',\n",
       "  '',\n",
       "  '',\n",
       "  '全球',\n",
       "  '每',\n",
       "  '6',\n",
       "  '个人',\n",
       "  '中',\n",
       "  '就',\n",
       "  '有',\n",
       "  '1',\n",
       "  '个人',\n",
       "  '的',\n",
       "  '年龄',\n",
       "  '在',\n",
       "  '65',\n",
       "  '岁',\n",
       "  '以上',\n",
       "  '',\n",
       "  ''],\n",
       " ['在',\n",
       "  '美国',\n",
       "  '',\n",
       "  '',\n",
       "  '届时',\n",
       "  '每',\n",
       "  '4',\n",
       "  '个人',\n",
       "  '中',\n",
       "  '就',\n",
       "  '有',\n",
       "  '1',\n",
       "  '个',\n",
       "  '65',\n",
       "  '岁',\n",
       "  '以上',\n",
       "  '的',\n",
       "  '老年',\n",
       "  '老年人',\n",
       "  '',\n",
       "  ''],\n",
       " ['报告',\n",
       "  '还',\n",
       "  '称',\n",
       "  '',\n",
       "  '',\n",
       "  '由于',\n",
       "  '移民',\n",
       "  '不断',\n",
       "  '增加',\n",
       "  '',\n",
       "  '',\n",
       "  '出生',\n",
       "  '出生人数',\n",
       "  '生人',\n",
       "  '人数',\n",
       "  '数下',\n",
       "  '下降',\n",
       "  '',\n",
       "  '',\n",
       "  '死亡',\n",
       "  '人数',\n",
       "  '增长',\n",
       "  '',\n",
       "  '',\n",
       "  '预计',\n",
       "  '到',\n",
       "  '2034',\n",
       "  '年',\n",
       "  '',\n",
       "  '',\n",
       "  '美国',\n",
       "  '年龄',\n",
       "  '65',\n",
       "  '岁',\n",
       "  '以上',\n",
       "  '人口',\n",
       "  '将',\n",
       "  '增加',\n",
       "  '至',\n",
       "  '7695',\n",
       "  '万',\n",
       "  '人',\n",
       "  '',\n",
       "  '',\n",
       "  '历史',\n",
       "  '上首',\n",
       "  '首次',\n",
       "  '超过',\n",
       "  '18',\n",
       "  '岁',\n",
       "  '以下',\n",
       "  '下人',\n",
       "  '人口',\n",
       "  '人口数',\n",
       "  '人口数量',\n",
       "  '数量',\n",
       "  '',\n",
       "  ''],\n",
       " ['按照',\n",
       "  '美国',\n",
       "  '的',\n",
       "  '定义',\n",
       "  '',\n",
       "  '',\n",
       "  '届时',\n",
       "  '美国',\n",
       "  '老年',\n",
       "  '老年人',\n",
       "  '人口',\n",
       "  '人口数',\n",
       "  '人口数量',\n",
       "  '数量',\n",
       "  '将',\n",
       "  '在历史上',\n",
       "  '历史',\n",
       "  '上首',\n",
       "  '首次',\n",
       "  '超过',\n",
       "  '过儿',\n",
       "  '儿童',\n",
       "  '',\n",
       "  ''],\n",
       " ['报告',\n",
       "  '预测',\n",
       "  '',\n",
       "  '',\n",
       "  '美国',\n",
       "  '国人',\n",
       "  '人口',\n",
       "  '的',\n",
       "  '种族',\n",
       "  '构成',\n",
       "  '将',\n",
       "  '进一步',\n",
       "  '一步',\n",
       "  '多样',\n",
       "  '多样化',\n",
       "  '',\n",
       "  '',\n",
       "  '并',\n",
       "  '将',\n",
       "  '呈现',\n",
       "  '三',\n",
       "  '大',\n",
       "  '特征',\n",
       "  '',\n",
       "  '',\n",
       "  '一',\n",
       "  '是',\n",
       "  '全美',\n",
       "  '白人',\n",
       "  '人人',\n",
       "  '人口',\n",
       "  '逐渐',\n",
       "  '老龄',\n",
       "  '老龄化',\n",
       "  '',\n",
       "  '',\n",
       "  '二',\n",
       "  '是',\n",
       "  '年轻',\n",
       "  '年轻一代',\n",
       "  '一代',\n",
       "  '一代人',\n",
       "  '代人',\n",
       "  '人口',\n",
       "  '在',\n",
       "  '种族',\n",
       "  '构成',\n",
       "  '成方',\n",
       "  '方面',\n",
       "  '更加',\n",
       "  '加多',\n",
       "  '多元',\n",
       "  '多元化',\n",
       "  '',\n",
       "  '',\n",
       "  '预计',\n",
       "  '到',\n",
       "  '2020',\n",
       "  '年',\n",
       "  '',\n",
       "  '',\n",
       "  '美国',\n",
       "  '18',\n",
       "  '岁',\n",
       "  '以下',\n",
       "  '下人',\n",
       "  '人口',\n",
       "  '口中',\n",
       "  '',\n",
       "  '',\n",
       "  '任何',\n",
       "  '一个',\n",
       "  '种族',\n",
       "  '居民',\n",
       "  '占',\n",
       "  '总人口',\n",
       "  '人口',\n",
       "  '比重',\n",
       "  '均',\n",
       "  '不足',\n",
       "  '一半',\n",
       "  '',\n",
       "  '',\n",
       "  '三',\n",
       "  '是',\n",
       "  '种族',\n",
       "  '融合',\n",
       "  '的',\n",
       "  '群体',\n",
       "  '人口',\n",
       "  '继续',\n",
       "  '增长',\n",
       "  '',\n",
       "  ''],\n",
       " ['\\n']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 04:01:00.021880 140548415072064 utils.py:173] Opening tar file .data/cnndm.tar.gz.\n",
      "I1029 04:01:00.023381 140548415072064 utils.py:181] .data/test.txt.src already extracted.\n",
      "I1029 04:01:00.312693 140548415072064 utils.py:181] .data/test.txt.tgt.tagged already extracted.\n",
      "I1029 04:01:00.339518 140548415072064 utils.py:181] .data/train.txt.src already extracted.\n",
      "I1029 04:01:07.846778 140548415072064 utils.py:181] .data/train.txt.tgt.tagged already extracted.\n",
      "I1029 04:01:08.479731 140548415072064 utils.py:181] .data/val.txt.src already extracted.\n",
      "I1029 04:01:08.812915 140548415072064 utils.py:181] .data/val.txt.tgt.tagged already extracted.\n",
      "0lines [00:00, ?lines/s]\n",
      "0lines [00:00, ?lines/s]\n",
      "0lines [00:00, ?lines/s]\n",
      "0lines [00:00, ?lines/s]\n"
     ]
    }
   ],
   "source": [
    "#from utils_nlp.dataset.cnndm import CNNDMSummarization\n",
    "#train_dataset, test_dataset = CNNDMSummarization(top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 16:34:04.529138 140402226906944 modeling_bert.py:226] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I1029 16:34:04.533537 140402226906944 modeling_xlnet.py:339] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I1029 16:34:04.582806 140402226906944 modeling.py:230] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "from utils_nlp.models.transformers.abstractive_summarization import AbsSumProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1029 16:34:07.582202 140402226906944 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at ./5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "I1029 16:34:07.754444 140402226906944 tokenization.py:156] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /home/daden/.cache/torch/pytorch_transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n"
     ]
    }
   ],
   "source": [
    "processor = AbsSumProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_sum_train = processor.preprocess(train_dataset, train_dataset.get_target())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(list(abs_sum_train), \"/dadendev/PreSumm2/PreSumm/bert_data/chinese.train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(abs_sum_train)[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_sum_test = processor.preprocess(list(test_dataset), list(test_dataset.get_target()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utils_nlp.models.transformers.extractive_summarization.ExtSumIterableDataset"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ext_sum_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utils_nlp.models.transformers.extractive_summarization.ExtSumData"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ext_sum_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_sum_train[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "BERT_DATA_PATH = BERT_DATA_PATH=\"./bert_data/\"\n",
    "pts = sorted(glob.glob(BERT_DATA_PATH + 'cnndm.train' + '.[0-9]*.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def get_dataset(file_list):\n",
    "    #random.shuffle(file_list)\n",
    "    for file in file_list:\n",
    "        yield torch.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(pts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1024 20:41:45.197966 140449625069376 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at ./b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I1024 20:41:45.200124 140449625069376 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I1024 20:41:45.342200 140449625069376 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at ./35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "I1024 20:41:48.732301 140449625069376 modeling_utils.py:405] Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1024 20:41:48.733542 140449625069376 modeling_utils.py:408] Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "I1024 20:41:48.868890 140449625069376 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at ./b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I1024 20:41:48.870221 140449625069376 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I1024 20:41:48.990102 140449625069376 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at ./35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "I1024 20:41:52.468241 140449625069376 modeling_utils.py:405] Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1024 20:41:52.471548 140449625069376 modeling_utils.py:408] Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "summarizer = ExtractiveSummarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook parameters\n",
    "DATA_FOLDER = \"./temp\"\n",
    "CACHE_DIR = \"./temp\"\n",
    "DEVICE = \"cuda\"\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "NUM_GPUS = 2\n",
    "MAX_LEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A/dadendev/anaconda3/envs/cm3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:12<?, ?it/s]\n",
      "Iteration: 0it [00:12, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.098849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:12, 12.42s/it]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:12<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.104650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.46it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:12<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.098288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.46it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:13<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.092516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.40it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:13<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.094773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.39it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:14<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.098362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.47it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:14<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.095246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.48it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:15<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.097674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.49it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:15<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.102338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.45it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:16<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.101050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1it [00:00,  2.47it/s]\u001b[A\n",
      "                                            \n",
      "Epoch:   0%|          | 0/1 [00:16<?, ?it/s]\n",
      "Iteration: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.098637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils_nlp.common.timer import Timer\n",
    "with Timer() as t:\n",
    "    summarizer.fit(\n",
    "            ext_sum_train,\n",
    "            device=DEVICE,\n",
    "            num_epochs=NUM_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_gpus=NUM_GPUS,\n",
    "            max_steps=1e1,\n",
    "            verbose=True,\n",
    "        )\n",
    "train_time = t.interval / 3600    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 1it [00:00, 20.03it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = summarizer.predict(ext_sum_test,\n",
    "                               device=DEVICE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metallic banging can also be heard more than three times , perhaps of the pilot trying to open the cockpit door with a heavy object .<q>but none of the cell phones found so far have been sent to the institute , menichini said .<q>`` it is a very disturbing scene , `` said julian reichelt , editor-in-chief of bild online .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.argsort(negative, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort([0,1,2,0.3,0.2], 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ext_sum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6 cm3",
   "language": "python",
   "name": "cm3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
