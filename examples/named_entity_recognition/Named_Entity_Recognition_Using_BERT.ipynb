{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition Using BERT\n",
    "## Summary\n",
    "This notebook demonstrates how to fine tune [pretrained BERT model](https://github.com/huggingface/pytorch-pretrained-BERT) for token level named entity recognition (NER) task. A few utility functions and classes in the NLP Best Practices repo are used to facilitate data preprocessing, model training, and model evaluation. \n",
    "\n",
    "[BERT (Bidirectional Transformers forLanguage Understanding)](https://arxiv.org/pdf/1810.04805.pdf) is a powerful pre-trained lanaguage model that can be used for multiple NLP tasks, including text classification, question answering, named entity recognition. It's able to achieve state of the art performance with only a few epochs of fine tuning.  \n",
    "The figure below illustrates how BERT can be fine tuned for NER tasks. The input data is a list of tokens representing a sentence. In the training data, each token has an entity label. After fine tuning, the model predicts an entity label for each token of a given sentence in the testing data. \n",
    "\n",
    "<img src=\"https://nlpbp.blob.core.windows.net/images/bert_architecture.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required packages\n",
    "* pytorch\n",
    "* pytorch-pretrained-bert\n",
    "* pandas\n",
    "* seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import pprint\n",
    "import random\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "\n",
    "nlp_path = os.path.abspath('../../')\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "\n",
    "from utils_nlp.bert.token_classification import BertTokenClassifier, postprocess_token_labels\n",
    "from utils_nlp.bert.common_ner import create_data_loader, Language, Tokenizer\n",
    "from utils_nlp.dataset.wikigold import download, read_data, get_train_test_data, get_unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path configurations\n",
    "data_dir = \"./data\"\n",
    "data_file = \"./data/wikigold.conll.txt\"\n",
    "cache_dir=\".\"\n",
    "\n",
    "# set random seeds\n",
    "random_seed = 10\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# model configurations\n",
    "language = Language.ENGLISHLARGE\n",
    "do_lower_case = True\n",
    "max_seq_length = 150\n",
    "\n",
    "# training configurations\n",
    "device=\"gpu\"\n",
    "batch_size = 32\n",
    "num_train_epochs = 5\n",
    "\n",
    "# optimizer configurations\n",
    "learning_rate = 3e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training and testing dataset. \n",
    "The dataset used in this notebook is the [wikigold dataset](https://www.aclweb.org/anthology/W09-3302). The wikigold dataset consists of 145 mannually labelled Wikipedia articles, including 1841 sentences and 40k tokens in total. The dataset can be directly downloaded from [here](https://github.com/juand-r/entity-recognition-datasets/tree/master/data/wikigold). The `download` function downloads the data file to a user-specified directory.  \n",
    "\n",
    "The helper function `get_train_test_data` splits the dataset into training and testing sets according to `test_percentage`. Because this is a relatively small dataset, we set `test_percentage` to 0.5 in order to have enough data for model evaluation. Running this notebook multiple times with different random seeds produces similar results.   \n",
    "\n",
    "The helper function `get_unique_labels` returns the unique entity labels in the dataset. There are 5 unique labels in the   original dataset: 'O' (non-entity), 'I-LOC' (location), 'I-MISC' (miscellaneous), 'I-PER' (person), and 'I-ORG' (organization). An 'X' label is added for the trailing word pieces generated by BERT, because BERT uses WordPiece tokenizer.  \n",
    "\n",
    "The maximum number of words in a sentence is 144, so we set `max_seq_length` to 150 above, because the number of tokens will grow after WordPiece tokenization. Ideally, it would be better to set `max_seq_length` to even larger, but 150 allows model training to be done on a single NVIDIA Tesla K80 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length in training data is: 89\n",
      "Maximum sequence length in testing data is: 144\n",
      "\n",
      "Unique entity labels: \n",
      "['O', 'I-LOC', 'I-MISC', 'I-PER', 'I-ORG', 'X']\n",
      "\n",
      "Sample sentence: \n",
      "It also launched Power98FM 8 months later .\n",
      "\n",
      "Sample sentence labels: \n",
      "['O', 'O', 'O', 'I-ORG', 'O', 'O', 'O', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "download(data_dir)\n",
    "wikigold_text = read_data(data_file)\n",
    "train_text, train_labels, test_text, test_labels = get_train_test_data(wikigold_text, test_percentage=0.5)\n",
    "label_list = get_unique_labels()\n",
    "print('\\nUnique entity labels: \\n{}\\n'.format(label_list))\n",
    "print('Sample sentence: \\n{}\\n'.format(train_text[0]))\n",
    "print('Sample sentence labels: \\n{}\\n'.format(train_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Preprocessing\n",
    "The `preprocess_ner_tokens` method of the `Tokenizer` class converts raw string data to numerical features, involving the following steps:\n",
    "1. WordPiece tokenization.\n",
    "2. Convert tokens and labels to numerical values, i.e. token ids and label ids.\n",
    "3. Sequence padding or truncation according to the `max_seq_length` configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dictionary that maps labels to numerical values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_map = {label: i for i, label in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(language=language, \n",
    "                      to_lower=do_lower_case, \n",
    "                      cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create numerical features**  \n",
    "Note there is an argument called `trailing_piece_tag`. BERT uses a WordPiece tokenizer which breaks down some words into multiple tokens, e.g. \"playing\" is tokenized into \"play\" and \"##ing\". Since the input data only come with one token label for \"playing\", within `prerocess_ner_tokens`, the original token label is assigned to the first token \"play\" and the second token \"##ing\" is labeled as \"X\". By default, `trailing_piece_tag` is set to \"X\". If \"X\" already exists in your data, you can set `trailing_piece_tag` to another value that doesn't exist in your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_token_ids, train_input_mask, train_trailing_token_mask, train_label_ids = \\\n",
    "    tokenizer.preprocess_ner_tokens(text=train_text,\n",
    "                                    label_map=label_map,\n",
    "                                    max_seq_length=max_seq_length,\n",
    "                                    labels=train_labels,\n",
    "                                    trailing_piece_tag=\"X\")\n",
    "test_token_ids, test_input_mask, test_trailing_token_mask, test_label_ids = \\\n",
    "    tokenizer.preprocess_ner_tokens(text=test_text,\n",
    "                                    label_map=label_map,\n",
    "                                    max_seq_length=max_seq_length,\n",
    "                                    labels=test_labels,\n",
    "                                    trailing_piece_tag=\"X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tokenizer.preprocess_ner_tokens` outputs three or four list of numerical features lists, each sublist contains features of an input sentence: \n",
    "1. token ids: list of numerical values each corresponds to a token.\n",
    "2. attention mask: list of 1s and 0s, 1 for input tokens and 0 for padded tokens, so that padded tokens are not attended to. \n",
    "3. trailing word piece mask: boolean list, True for the first word piece of each original word, False for the trailing word pieces, e.g. ##ing. This mask is useful for removing predictions on trailing word pieces, so that each original word in the input text has a unique predicted label. \n",
    "4. label ids: list of numerical values each corresponds to an entity label, if `labels` is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample token ids:\n",
      "[2009, 2036, 3390, 2373, 2683, 2620, 16715, 1022, 2706, 2101, 1012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample attention mask:\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample trailing token mask:\n",
      "[True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "\n",
      "Sample label ids:\n",
      "[0, 0, 0, 4, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample token ids:\\n{}\\n\".format(train_token_ids[0]))\n",
    "print(\"Sample attention mask:\\n{}\\n\".format(train_input_mask[0]))\n",
    "print(\"Sample trailing token mask:\\n{}\\n\".format(train_trailing_token_mask[0]))\n",
    "print(\"Sample label ids:\\n{}\\n\".format(train_label_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Token Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_classifier = BertTokenClassifier(language=Language.ENGLISH,\n",
    "                                       num_labels=len(label_list),\n",
    "                                       cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n",
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Only 1 CUDA device is available. Data parallelism is not possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  59%|█████▊    | 17/29 [00:31<00:22,  1.87s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 17/29 [00:49<00:22,  1.87s/it]\u001b[A\n",
      "Epoch:  20%|██        | 1/5 [00:54<03:36, 54.24s/it]7s/it]\u001b[A\n",
      "Iteration:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7232020918665261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  55%|█████▌    | 16/29 [00:30<00:24,  1.89s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 16/29 [00:45<00:24,  1.89s/it]\u001b[A\n",
      "Epoch:  40%|████      | 2/5 [01:48<02:43, 54.34s/it]8s/it]\u001b[A\n",
      "Iteration:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.19114394537333784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  55%|█████▌    | 16/29 [00:30<00:24,  1.90s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 16/29 [00:41<00:24,  1.90s/it]\u001b[A\n",
      "Epoch:  60%|██████    | 3/5 [02:43<01:49, 54.50s/it]9s/it]\u001b[A\n",
      "Iteration:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.08570333865695987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  55%|█████▌    | 16/29 [00:30<00:24,  1.90s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 16/29 [00:46<00:24,  1.90s/it]\u001b[A\n",
      "Epoch:  80%|████████  | 4/5 [03:38<00:54, 54.62s/it]9s/it]\u001b[A\n",
      "Iteration:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04018309917943231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  55%|█████▌    | 16/29 [00:30<00:24,  1.91s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 16/29 [00:41<00:24,  1.91s/it]\u001b[A\n",
      "Epoch: 100%|██████████| 5/5 [04:33<00:00, 54.74s/it]0s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.024413088625618095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "token_classifier.fit(token_ids=train_token_ids, \n",
    "                     input_mask=train_input_mask, \n",
    "                     labels=train_label_ids,\n",
    "                     num_epochs=num_train_epochs, \n",
    "                     batch_size=batch_size, \n",
    "                     learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 29/29 [00:19<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss: 0.14181747210436854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_label_ids = token_classifier.predict(token_ids=test_token_ids, \n",
    "                                          input_mask=test_input_mask, \n",
    "                                          labels=test_label_ids, \n",
    "                                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "The `predict` method of the token classifier outputs label ids for all tokens, including the padded tokens. `postprocess_token_labels` is a helper function that removes the predictions on padded tokens. If a `label_map` is provided, it maps the numerical label ids back to original token labels which are usually string type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "     MISC       0.62      0.74      0.68       406\n",
      "      PER       0.95      0.91      0.93       583\n",
      "      ORG       0.75      0.75      0.75       549\n",
      "        X       0.95      0.98      0.97      1728\n",
      "      LOC       0.85      0.83      0.84       550\n",
      "\n",
      "micro avg       0.87      0.89      0.88      3816\n",
      "macro avg       0.87      0.89      0.88      3816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_tags_no_padding = postprocess_token_labels(pred_label_ids, \n",
    "                                                test_input_mask, \n",
    "                                                label_map)\n",
    "true_tags_no_padding =  postprocess_token_labels(test_label_ids, \n",
    "                                                 test_input_mask, \n",
    "                                                 label_map)\n",
    "print(classification_report(true_tags_no_padding, pred_tags_no_padding, digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`postprocess_token_labels` also provides an option to remove the predictions on trailing word pieces, e.g. ##ing, so that the final predicted labels correspond to the original words in the input text. The `trailing_token_mask` is obtained from `tokenizer.preprocess_ner_tokens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "     MISC       0.59      0.71      0.65       358\n",
      "      PER       0.94      0.90      0.92       501\n",
      "      ORG       0.71      0.72      0.71       468\n",
      "      LOC       0.83      0.82      0.82       505\n",
      "\n",
      "micro avg       0.75      0.80      0.77      1832\n",
      "macro avg       0.78      0.80      0.79      1832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_tags_no_padding_no_trailing = postprocess_token_labels(pred_label_ids, \n",
    "                                                            test_input_mask, \n",
    "                                                            label_map, \n",
    "                                                            remove_trailing_word_pieces=True, \n",
    "                                                            trailing_token_mask=test_trailing_token_mask)\n",
    "true_tags_no_padding_no_trailing = postprocess_token_labels(test_label_ids, \n",
    "                                                            test_input_mask, \n",
    "                                                            label_map, \n",
    "                                                            remove_trailing_word_pieces=True, \n",
    "                                                            trailing_token_mask=test_trailing_token_mask)\n",
    "print(classification_report(true_tags_no_padding_no_trailing, pred_tags_no_padding_no_trailing, digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the metrics are worse after exluding trailing word pieces, because they are easy to predict. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
