{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Pipelines with Azure Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we fine-tune and evaluate a number of pretrained models on a subset of the [MultiNLI](https://www.nyu.edu/projects/bowman/multinli/) dataset using [Azure Machine Learning Pipelines](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-ml-pipelines). Pipelines allow us to create sequential steps for preprocessing and training workflows, in addition to parallel steps that run independenly on a cluster of nodes. We demonstrate how one can submit model training jobs for multiple models, each consisting of multiple steps.\n",
    "\n",
    "We use a [sequence classifier](../../../utils_nlp/models/transformers/sequence_classification.py) that wraps [Hugging Face's PyTorch implementation](https://github.com/huggingface/transformers) of different transformers, like [BERT](https://github.com/google-research/bert), [XLNet](https://github.com/zihangdai/xlnet), and [RoBERTa](https://github.com/pytorch/fairseq).\n",
    "\n",
    "Below is a general illustration of the pipeline and its preprocessing and training steps.\n",
    "\n",
    "<img src=\"https://nlpbp.blob.core.windows.net/images/tc_pipeline_graph.PNG\" width=\"500\">\n",
    "\n",
    "The pipeline steps we chose are generic [Python script steps](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.python_script_step.pythonscriptstep?view=azure-ml-py) of the Azure ML SDK. This allows us to run parametrized Python scripts on a remote target. For this example, we will create pipeline steps that execute the preprocessing and training scripts provided in the [scripts](scripts) folder, with different arguments for different model types.\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "- [Define Parameters](#Define-Parameters)\n",
    "- [Create AML Workspace and Compute Target](#Create-AML-Workspace-and-Compute-Target)\n",
    "- [Upload Training Data to Workspace](#Upload-Training-Data-to-Workspace)\n",
    "- [Setup Execution Environment](#Setup-Execution-Environment)\n",
    "- [Define Pipeline Graph](#Define-Pipeline-Graph)\n",
    "- [Run Pipeline](#Run-Pipeline)\n",
    "- [Retrieve a Trained Model from Pipeline](#Retrieve-a-Trained-Model-from-Pipeline)\n",
    "- [Test Model](#Test-Model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from azureml.core import Datastore, Environment, Experiment\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, PipelineRun\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from utils_nlp.azureml import azureml_utils\n",
    "from utils_nlp.dataset.multinli import load_pandas_df\n",
    "from utils_nlp.models.transformers.sequence_classification import Processor, SequenceClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSCRIPTION_ID = \"\"\n",
    "RESOURCE_GROUP = \"ignite-demo\"\n",
    "WORKSPACE_NAME = \"ignite-nlp-amlws\"\n",
    "WORKSPACE_REGION = \"eastus\"\n",
    "\n",
    "# remote target\n",
    "CLUSTER_NAME = \"ignite-nlp-clstr\"  # 2-16 chars\n",
    "VM_SIZE = \"STANDARD_NC12\"\n",
    "MIN_NODES = 0\n",
    "MAX_NODES = 2\n",
    "\n",
    "# local data\n",
    "TEMP_DIR = \"temp\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"label\"\n",
    "TRAIN_SAMPLE_SIZE = 10000\n",
    "# remote data\n",
    "REMOTE_DATA_CONTAINER = \"data\"\n",
    "\n",
    "# remote env config\n",
    "PIP_PACKAGES = [\"azureml-sdk==1.0.65\", \"torch==1.1\", \"tqdm==4.31.1\", \"transformers==2.1.1\"]\n",
    "CONDA_PACKAGES = [\"numpy\", \"scikit-learn\", \"pandas\"]\n",
    "UTILS_NLP_WHL_DIR = \"../../../dist\"\n",
    "PYTHON_VERSION = \"3.6.8\"\n",
    "USE_GPU = True\n",
    "\n",
    "# pipeline scripts\n",
    "SCRIPTS_DIR = \"scripts\"\n",
    "PREPROCESS_SCRIPT = \"preprocess.py\"\n",
    "TRAIN_SCRIPT = \"train.py\"\n",
    "\n",
    "# pretrained models\n",
    "MODEL_NAMES = [\"bert-base-uncased\", \"xlnet-base-cased\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AML Workspace and Compute Target\n",
    "\n",
    "The following code block creates or retrieves an existing Azure ML workspace and a corresponding Azure ML compute target. For deep learning tasks, it is recommended that your compute nodes are GPU-enabled. Here, we're using a scalable cluster of size *(min_nodes, max_nodes)*. Setting *min_nodes* to zero ensures that the nodes are shutdown when not in use. Azure ML will allocate nodes as needed, up to *max_nodes*, and based on the jobs submitted to the compute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create/get AML workspace\n",
    "ws = azureml_utils.get_or_create_workspace(\n",
    "    subscription_id=SUBSCRIPTION_ID,\n",
    "    resource_group=RESOURCE_GROUP,\n",
    "    workspace_name=WORKSPACE_NAME,\n",
    "    workspace_region=WORKSPACE_REGION,\n",
    ")\n",
    "\n",
    "# create/get compute target\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=CLUSTER_NAME)\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=VM_SIZE, min_nodes=MIN_NODES, max_nodes=MAX_NODES, vm_priority=\"lowpriority\"\n",
    "    )\n",
    "    compute_target = ComputeTarget.create(\n",
    "        workspace=ws, name=CLUSTER_NAME, provisioning_configuration=compute_config\n",
    "    )\n",
    "    compute_target.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Training Data to Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use a subset of the MultiNLI dataset for fine-tuning the specified pre-trained models. The dataset contains a column of sentences (*sentence1*) which we will use as text input, and a *genre* column which we use as class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333700</th>\n",
       "      <td>um-hum yeah well it's so neat because it's rig...</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122350</th>\n",
       "      <td>Here it was: a chance to work on the Range, to...</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210049</th>\n",
       "      <td>Nowadays it would take more time scrounging ab...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251559</th>\n",
       "      <td>The brand that we now think of as irresistible...</td>\n",
       "      <td>slate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320033</th>\n",
       "      <td>well see i'm not either because i'm i'm really...</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text      label\n",
       "333700  um-hum yeah well it's so neat because it's rig...  telephone\n",
       "122350  Here it was: a chance to work on the Range, to...    fiction\n",
       "210049  Nowadays it would take more time scrounging ab...     travel\n",
       "251559  The brand that we now think of as irresistible...      slate\n",
       "320033  well see i'm not either because i'm i'm really...  telephone"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training data sample\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "df = load_pandas_df(TEMP_DIR, \"train\")\n",
    "df = df[df[\"gold_label\"] == \"neutral\"] # filter duplicate sentences\n",
    "df = df.sample(TRAIN_SAMPLE_SIZE)\n",
    "df[TEXT_COL] = df[\"sentence1\"]\n",
    "df[LABEL_COL] = df[\"genre\"]\n",
    "df[[TEXT_COL, LABEL_COL]].to_csv(\n",
    "    os.path.join(TEMP_DIR, TRAIN_FILE), header=True, index=None, quoting=1\n",
    ")\n",
    "# inspect dataset\n",
    "df[[TEXT_COL, LABEL_COL]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Azure ML workspace comes with a default datastore that is linked to an Azure Blob storage in the same resource group. We will use this datastore to upload the CSV data file. We will also use it for the intermediate output of the pipeline steps, as well as for the final output of the training step. In practice, one can create other datastores and link them to existing Blob Storage containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading temp/train.csv\n",
      "Uploaded temp/train.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_94015c4f86d545338f3b403f66a0c90d"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload data to datastore\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload_files(\n",
    "    files=[os.path.join(TEMP_DIR, TRAIN_FILE)],\n",
    "    target_path=REMOTE_DATA_CONTAINER,\n",
    "    overwrite=True,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Execution Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the *pip* and *conda* dependencies listed in the parameters section, we would need to include the packaged utils_nlp wheel file (this can be created by running *python3 setup.py bdist_wheel* from the root dir). The utils_nlp folder of this repo includes the transformer procesor and the classifier that we will fine-tune on the remote target. The *preprocess.py* and *train.py* [scripts](scripts) import the *utils_nlp* package, as they call the preprocessing and classification functions of its wrapper classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate utils_nlp whl file\n",
    "utils_nlp_whl_file = [x for x in os.listdir(UTILS_NLP_WHL_DIR) if x.endswith(\".whl\")][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda env setup\n",
    "conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=CONDA_PACKAGES,\n",
    "    pip_packages=PIP_PACKAGES,\n",
    "    python_version=PYTHON_VERSION,\n",
    ")\n",
    "nlp_repo_whl = Environment.add_private_pip_wheel(\n",
    "    workspace=ws,\n",
    "    file_path=os.path.join(UTILS_NLP_WHL_DIR, utils_nlp_whl_file),\n",
    "    exist_ok=True,\n",
    ")\n",
    "conda_dependencies.add_pip_package(nlp_repo_whl)\n",
    "run_config = RunConfiguration(conda_dependencies=conda_dependencies)\n",
    "run_config.environment.docker.enabled = True\n",
    "if USE_GPU:\n",
    "    run_config.environment.docker.base_image = azureml.core.runconfig.DEFAULT_GPU_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pipeline Graph\n",
    "\n",
    "As shown in the diagram earlier, the pipeline can be represented as a graph, where nodes represent execution steps. In this example we create a pipeline with two steps for each pretrained model we want to fine-tune. The processing and fine-tuning steps need to be executed in order. However, each sequence of these two steps can be executed in parallel for many types of models on multiple nodes of the compute cluster.\n",
    "\n",
    "For text classification, a number of pretrained-models are available from [Hugging Face's transformers package](https://github.com/huggingface/transformers), which is used within *utils_nlp*. Here, we include preprocessing and training steps for the *MODEL_NAMES* defined in the parameters section. You can list the supported pretrained models using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bert-base-uncased', 'bert-large-uncased', 'bert-base-cased', 'bert-large-cased', 'bert-base-multilingual-uncased', 'bert-base-multilingual-cased', 'bert-base-chinese', 'bert-base-german-cased', 'bert-large-uncased-whole-word-masking', 'bert-large-cased-whole-word-masking', 'bert-large-uncased-whole-word-masking-finetuned-squad', 'bert-large-cased-whole-word-masking-finetuned-squad', 'bert-base-cased-finetuned-mrpc', 'bert-base-german-dbmdz-cased', 'bert-base-german-dbmdz-uncased', 'roberta-base', 'roberta-large', 'roberta-large-mnli', 'xlnet-base-cased', 'xlnet-large-cased', 'distilbert-base-uncased', 'distilbert-base-uncased-distilled-squad']\n"
     ]
    }
   ],
   "source": [
    "print(SequenceClassifier.list_supported_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = DataReference(\n",
    "    datastore=ds,\n",
    "    data_reference_name=\"input_dir\",\n",
    "    path_on_datastore=REMOTE_DATA_CONTAINER,\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "# create pipeline steps\n",
    "all_steps = []\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "\n",
    "    preprocess_dir = PipelineData(\n",
    "        name=\"preprocessed\",\n",
    "        datastore=ds,\n",
    "        output_path_on_compute=REMOTE_DATA_CONTAINER + \"/\" + \"preprocessed_\" + model_name,\n",
    "    )\n",
    "\n",
    "    output_dir = PipelineData(\n",
    "        name=\"trained\",\n",
    "        datastore=ds,\n",
    "        output_path_on_compute=REMOTE_DATA_CONTAINER + \"/\" + \"trained_\" + model_name,\n",
    "    )\n",
    "\n",
    "    preprocess_step = PythonScriptStep(\n",
    "        name=\"preprocess_step_{}\".format(model_name),\n",
    "        arguments=[input_dir, TRAIN_FILE, preprocess_dir, TEXT_COL, LABEL_COL, model_name],\n",
    "        script_name=PREPROCESS_SCRIPT,\n",
    "        inputs=[input_dir],\n",
    "        outputs=[preprocess_dir],\n",
    "        source_directory=SCRIPTS_DIR,\n",
    "        compute_target=compute_target,\n",
    "        runconfig=run_config,\n",
    "        allow_reuse=False,\n",
    "    )\n",
    "\n",
    "    train_step = PythonScriptStep(\n",
    "        name=\"train_step_{}\".format(model_name),\n",
    "        arguments=[preprocess_dir, output_dir, model_name, MAX_NODES],\n",
    "        script_name=TRAIN_SCRIPT,\n",
    "        inputs=[preprocess_dir],\n",
    "        outputs=[output_dir],\n",
    "        source_directory=SCRIPTS_DIR,\n",
    "        compute_target=compute_target,\n",
    "        runconfig=run_config,\n",
    "        allow_reuse=False,\n",
    "    )\n",
    "\n",
    "    train_step.run_after(preprocess_step)\n",
    "\n",
    "    all_steps.append(preprocess_step)\n",
    "    all_steps.append(train_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following image is an example of how the pipeline graph generated by Azure ML looks like. This particular graph example represents a pipeline submitted for 2 models with a total of 4 steps.\n",
    "\n",
    "<img src=\"https://nlpbp.blob.core.windows.net/images/pipeline_graph_example.PNG\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Pipeline\n",
    "\n",
    "Once the pipeline and its steps are defined, we can create an experiment in the Azure ML workspace and submit a pipeline run as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step preprocess_step_bert-base-uncased [d9bfc2e0][de904fdd-2eeb-41c6-bbbd-16edc5548e44], (This step will run and generate new outputs)\n",
      "Created step train_step_bert-base-uncased [0f64eed6][530a94a4-7fa1-4213-a494-5baa5318bcc9], (This step will run and generate new outputs)\n",
      "Created step preprocess_step_xlnet-base-cased [5f60180f][9eb101b3-cd67-48db-9246-eb7e5d4b1785], (This step will run and generate new outputs)\n",
      "Created step train_step_xlnet-base-cased [5f6b7056][9b187e56-e44c-4c04-a31d-5788cb58412b], (This step will run and generate new outputs)\n",
      "Using data reference input_dir for StepId [aba9341b][c1b309f5-1049-4014-8fd7-794c0b242c46], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Using data reference input_dir for StepId [24795823][c1b309f5-1049-4014-8fd7-794c0b242c46], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted pipeline run: 68e2c2c4-cfe7-417e-978f-957a2febd8c6\n",
      "PipelineRunId: 68e2c2c4-cfe7-417e-978f-957a2febd8c6\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/9086b59a-02d7-4687-b3fd-e39fa5e0fd9b/resourceGroups/ignite-demo/providers/Microsoft.MachineLearningServices/workspaces/ignite-nlp-amlws/experiments/nlpatIgnite_014933/runs/68e2c2c4-cfe7-417e-978f-957a2febd8c6\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: ebd5e908-034e-482e-acfb-95cb23255b63\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/9086b59a-02d7-4687-b3fd-e39fa5e0fd9b/resourceGroups/ignite-demo/providers/Microsoft.MachineLearningServices/workspaces/ignite-nlp-amlws/experiments/nlpatIgnite_014933/runs/ebd5e908-034e-482e-acfb-95cb23255b63\n",
      "StepRun( preprocess_step_bert-base-uncased ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt\n",
      "========================================================================================================================\n",
      "2019-10-16T01:55:13Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ignite-nlp-amlws/azureml/ebd5e908-034e-482e-acfb-95cb23255b63/mounts/workspaceblobstore\n",
      "2019-10-16T01:55:13Z Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/ignite-nlp-amlws/azureml/ebd5e908-034e-482e-acfb-95cb23255b63/mounts/workspaceblobstore\n",
      "2019-10-16T01:55:13Z Successfully mounted azureml-blobstore-b441ee2a-b335-4171-9766-395a267a0db2 container from ignitenlstoragedbbd0cb09 account at /mnt/batch/tasks/shared/LS_root/jobs/ignite-nlp-amlws/azureml/ebd5e908-034e-482e-acfb-95cb23255b63/mounts/workspaceblobstore\n",
      "2019-10-16T01:55:13Z No unmanaged file systems configured\n",
      "2019-10-16T01:55:14Z Starting output-watcher...\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_79c60456c523f591a63f904cd43533f4\n",
      "f7277927d38a: Pulling fs layer\n",
      "8d3eac894db4: Pulling fs layer\n",
      "edf72af6d627: Pulling fs layer\n",
      "3e4f86211d23: Pulling fs layer\n",
      "d6e9603ff777: Pulling fs layer\n",
      "5cad422780e2: Pulling fs layer\n",
      "8130687c8acb: Pulling fs layer\n",
      "c11e9246d621: Pulling fs layer\n",
      "0dfae24cbbd9: Pulling fs layer\n",
      "0bb049a6d391: Pulling fs layer\n",
      "988ac06e9a72: Pulling fs layer\n",
      "1d903ffe89fe: Pulling fs layer\n",
      "4c5e9e6c7e14: Pulling fs layer\n",
      "7ebd3e323491: Pulling fs layer\n",
      "8796a8f9e018: Pulling fs layer\n",
      "362d975917fe: Pulling fs layer\n",
      "a0018081f252: Pulling fs layer\n",
      "87fbc3c14102: Pulling fs layer\n",
      "d6e9603ff777: Waiting\n",
      "faa1628e02d5: Pulling fs layer\n",
      "251c682773cd: Pulling fs layer\n",
      "fe780f880265: Pulling fs layer\n",
      "b841f14b6b1c: Pulling fs layer\n",
      "5cad422780e2: Waiting\n",
      "0bb049a6d391: Waiting\n",
      "4709d720c04b: Pulling fs layer\n",
      "988ac06e9a72: Waiting\n",
      "1d903ffe89fe: Waiting\n",
      "c11e9246d621: Waiting\n",
      "faa1628e02d5: Waiting\n",
      "4c5e9e6c7e14: Waiting\n",
      "0dfae24cbbd9: Waiting\n",
      "251c682773cd: Waiting\n",
      "7ebd3e323491: Waiting\n",
      "4709d720c04b: Waiting\n",
      "8796a8f9e018: Waiting\n",
      "fe780f880265: Waiting\n",
      "87fbc3c14102: Waiting\n",
      "b841f14b6b1c: Waiting\n",
      "a0018081f252: Waiting\n",
      "3e4f86211d23: Waiting\n",
      "8d3eac894db4: Verifying Checksum\n",
      "8d3eac894db4: Download complete\n",
      "3e4f86211d23: Verifying Checksum\n",
      "3e4f86211d23: Download complete\n",
      "edf72af6d627: Verifying Checksum\n",
      "edf72af6d627: Download complete\n",
      "d6e9603ff777: Verifying Checksum\n",
      "d6e9603ff777: Download complete\n",
      "f7277927d38a: Verifying Checksum\n",
      "f7277927d38a: Download complete\n",
      "8130687c8acb: Verifying Checksum\n",
      "8130687c8acb: Download complete\n",
      "f7277927d38a: Pull complete\n",
      "8d3eac894db4: Pull complete\n",
      "edf72af6d627: Pull complete\n",
      "3e4f86211d23: Pull complete\n",
      "d6e9603ff777: Pull complete\n",
      "5cad422780e2: Pull complete\n",
      "8130687c8acb: Pull complete\n",
      "0bb049a6d391: Verifying Checksum\n",
      "0bb049a6d391: Download complete\n",
      "c11e9246d621: Verifying Checksum\n",
      "c11e9246d621: Download complete\n",
      "988ac06e9a72: Verifying Checksum\n",
      "988ac06e9a72: Download complete\n",
      "1d903ffe89fe: Verifying Checksum\n",
      "1d903ffe89fe: Download complete\n",
      "4c5e9e6c7e14: Verifying Checksum\n",
      "4c5e9e6c7e14: Download complete\n",
      "7ebd3e323491: Verifying Checksum\n",
      "7ebd3e323491: Download complete\n",
      "362d975917fe: Verifying Checksum\n",
      "362d975917fe: Download complete\n",
      "a0018081f252: Verifying Checksum\n",
      "a0018081f252: Download complete\n",
      "87fbc3c14102: Verifying Checksum\n",
      "87fbc3c14102: Download complete\n",
      "0dfae24cbbd9: Verifying Checksum\n",
      "0dfae24cbbd9: Download complete\n",
      "8796a8f9e018: Verifying Checksum\n",
      "8796a8f9e018: Download complete\n",
      "faa1628e02d5: Download complete\n",
      "251c682773cd: Download complete\n",
      "fe780f880265: Download complete\n",
      "4709d720c04b: Download complete\n",
      "b841f14b6b1c: Verifying Checksum\n",
      "c11e9246d621: Pull complete\n",
      "0dfae24cbbd9: Pull complete\n",
      "0bb049a6d391: Pull complete\n",
      "988ac06e9a72: Pull complete\n",
      "1d903ffe89fe: Pull complete\n",
      "4c5e9e6c7e14: Pull complete\n",
      "7ebd3e323491: Pull complete\n",
      "8796a8f9e018: Pull complete\n",
      "362d975917fe: Pull complete\n",
      "a0018081f252: Pull complete\n",
      "87fbc3c14102: Pull complete\n",
      "faa1628e02d5: Pull complete\n",
      "251c682773cd: Pull complete\n",
      "fe780f880265: Pull complete\n",
      "b841f14b6b1c: Pull complete\n",
      "4709d720c04b: Pull complete\n",
      "Digest: sha256:8000189784d02583385269dbf8a6b8d0927267420b66530001ad2f4b65a94ca4\n",
      "Status: Downloaded newer image for ignitenlpamld8282028.azurecr.io/azureml/azureml_79c60456c523f591a63f904cd43533f4:latest\n",
      "34e4dd18844fd838cfbeef76c2fe86e1260663bbd9bfe30d8ab4d0c720c12028\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 138\n",
      "Entering Run History Context Manager.\n",
      "\n",
      "  0%|          | 0/231508 [00:00<?, ?B/s]\n",
      "100%|██████████| 231508/231508 [00:00<00:00, 33459044.50B/s]\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "1 items cleaning up...\n",
      "Cleanup took 0.0006034374237060547 seconds\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt\n",
      "===============================================================================================================\n",
      "Starting job release. Current time:2019-10-16T01:57:30.360736\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 179\n",
      "Job release is complete. Current time:2019-10-16T01:57:31.798515\n",
      "\n",
      "StepRun(preprocess_step_bert-base-uncased) Execution Summary\n",
      "=============================================================\n",
      "StepRun( preprocess_step_bert-base-uncased ) Status: Finished\n",
      "{'runId': 'ebd5e908-034e-482e-acfb-95cb23255b63', 'target': 'ignite-nlp-clstr', 'status': 'Completed', 'startTimeUtc': '2019-10-16T01:55:03.788347Z', 'endTimeUtc': '2019-10-16T01:57:44.147848Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '2735c4ee-f582-4a06-a31c-ed5f8d3f1eb8', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': '68e2c2c4-cfe7-417e-978f-957a2febd8c6', '_azureml.ComputeTargetType': 'batchai', 'AzureML.DerivedImageName': 'azureml/azureml_79c60456c523f591a63f904cd43533f4', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'runDefinition': {'script': 'preprocess.py', 'arguments': ['$AZUREML_DATAREFERENCE_input_dir', 'train.csv', '$AZUREML_DATAREFERENCE_preprocessed', 'text', 'label', 'bert-base-uncased'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'ignite-nlp-clstr', 'dataReferences': {'input_dir': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'data', 'pathOnCompute': None, 'overwrite': False}, 'preprocessed': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/ebd5e908-034e-482e-acfb-95cb23255b63/preprocessed', 'pathOnCompute': 'data/preprocessed_bert-base-uncased', 'overwrite': False}}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment nlpatIgnite_014933 Environment', 'version': 'Autosave_2019-10-16T01:50:13Z_b643da0f', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge'], 'dependencies': ['python=3.6.8', {'pip': ['azureml-sdk==1.0.65', 'torch==1.1', 'tqdm==4.31.1', 'transformers==2.1.1', 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/Environment/azureml-private-packages/utils_nlp-1.0.0-py3-none-any.whl']}, 'numpy', 'scikit-learn', 'pandas'], 'name': 'azureml_7bc8a6b5673da8c9051f3434792cb5f9'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.ebd5e908-034e-482e-acfb-95cb23255b63/azureml-logs/55_azureml-execution-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt?sv=2018-11-09&sr=b&sig=yNWnLxuOHVDJf23TYXAZAiY0%2FeAX%2FOK%2BUnhvQUsX9Dc%3D&st=2019-10-16T01%3A47%3A51Z&se=2019-10-16T09%3A57%3A51Z&sp=r', 'azureml-logs/65_job_prep-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.ebd5e908-034e-482e-acfb-95cb23255b63/azureml-logs/65_job_prep-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt?sv=2018-11-09&sr=b&sig=dKKWsjee6IKMFO8tZvQfl2c%2FEvhXSmAt%2F9uMhKGUJ2M%3D&st=2019-10-16T01%3A47%3A51Z&se=2019-10-16T09%3A57%3A51Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.ebd5e908-034e-482e-acfb-95cb23255b63/azureml-logs/70_driver_log.txt?sv=2018-11-09&sr=b&sig=ugFZXjUL6ftTN6Xwnw8T%2Bryk7Q%2B61fTSmdBTV0klfRE%3D&st=2019-10-16T01%3A47%3A51Z&se=2019-10-16T09%3A57%3A51Z&sp=r', 'azureml-logs/75_job_post-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.ebd5e908-034e-482e-acfb-95cb23255b63/azureml-logs/75_job_post-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt?sv=2018-11-09&sr=b&sig=L608os%2FrDKvJ0zy9vxkUS0ZvtQgHxEfgQvhrgwXkeAo%3D&st=2019-10-16T01%3A47%3A51Z&se=2019-10-16T09%3A57%3A51Z&sp=r', 'logs/azureml/138_azureml.log': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.ebd5e908-034e-482e-acfb-95cb23255b63/logs/azureml/138_azureml.log?sv=2018-11-09&sr=b&sig=s1iwIWFyjoezISJu%2BDthCAh5GRb4ZydLFf9FUjIg9AU%3D&st=2019-10-16T01%3A47%3A51Z&se=2019-10-16T09%3A57%3A51Z&sp=r', 'logs/azureml/azureml.log': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.ebd5e908-034e-482e-acfb-95cb23255b63/logs/azureml/azureml.log?sv=2018-11-09&sr=b&sig=VTTJd76gRj9CzLk3OHJp79gfIHNA0Z9F37YL8yJlZ9o%3D&st=2019-10-16T01%3A47%3A51Z&se=2019-10-16T09%3A57%3A51Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.ebd5e908-034e-482e-acfb-95cb23255b63/logs/azureml/executionlogs.txt?sv=2018-11-09&sr=b&sig=Sm7nJMEUzqoFdiCmBxe5s98AS%2BAylecOVRP95Oky8dw%3D&st=2019-10-16T01%3A47%3A51Z&se=2019-10-16T09%3A57%3A51Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.ebd5e908-034e-482e-acfb-95cb23255b63/logs/azureml/stderrlogs.txt?sv=2018-11-09&sr=b&sig=xkG8%2FNFmyKKXC1UBtV3OxAkkvnVbnLs5WMB%2F67gOJfE%3D&st=2019-10-16T01%3A47%3A51Z&se=2019-10-16T09%3A57%3A51Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.ebd5e908-034e-482e-acfb-95cb23255b63/logs/azureml/stdoutlogs.txt?sv=2018-11-09&sr=b&sig=7%2BOwcFBK997l93lmvRzXr3i3TNOJWoTS6kyjtsFd7BY%3D&st=2019-10-16T01%3A47%3A51Z&se=2019-10-16T09%3A57%3A51Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 1b5b1ca5-2a4d-40d2-b555-91fe269543b6\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/9086b59a-02d7-4687-b3fd-e39fa5e0fd9b/resourceGroups/ignite-demo/providers/Microsoft.MachineLearningServices/workspaces/ignite-nlp-amlws/experiments/nlpatIgnite_014933/runs/1b5b1ca5-2a4d-40d2-b555-91fe269543b6\n",
      "\n",
      "StepRun(preprocess_step_xlnet-base-cased) Execution Summary\n",
      "============================================================\n",
      "StepRun( preprocess_step_xlnet-base-cased ) Status: Finished\n",
      "{'runId': '1b5b1ca5-2a4d-40d2-b555-91fe269543b6', 'target': 'ignite-nlp-clstr', 'status': 'Completed', 'startTimeUtc': '2019-10-16T01:55:02.485661Z', 'endTimeUtc': '2019-10-16T01:57:42.032728Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '2735c4ee-f582-4a06-a31c-ed5f8d3f1eb8', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': '68e2c2c4-cfe7-417e-978f-957a2febd8c6', '_azureml.ComputeTargetType': 'batchai', 'AzureML.DerivedImageName': 'azureml/azureml_79c60456c523f591a63f904cd43533f4', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'runDefinition': {'script': 'preprocess.py', 'arguments': ['$AZUREML_DATAREFERENCE_input_dir', 'train.csv', '$AZUREML_DATAREFERENCE_preprocessed', 'text', 'label', 'xlnet-base-cased'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'ignite-nlp-clstr', 'dataReferences': {'input_dir': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'data', 'pathOnCompute': None, 'overwrite': False}, 'preprocessed': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/1b5b1ca5-2a4d-40d2-b555-91fe269543b6/preprocessed', 'pathOnCompute': 'data/preprocessed_xlnet-base-cased', 'overwrite': False}}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment nlpatIgnite_014933 Environment', 'version': 'Autosave_2019-10-16T01:50:13Z_b643da0f', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge'], 'dependencies': ['python=3.6.8', {'pip': ['azureml-sdk==1.0.65', 'torch==1.1', 'tqdm==4.31.1', 'transformers==2.1.1', 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/Environment/azureml-private-packages/utils_nlp-1.0.0-py3-none-any.whl']}, 'numpy', 'scikit-learn', 'pandas'], 'name': 'azureml_7bc8a6b5673da8c9051f3434792cb5f9'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_d1a60f800b713a447df92c06af2a65d82318837ba3be777a4b550fe7d66f4339_p.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1b5b1ca5-2a4d-40d2-b555-91fe269543b6/azureml-logs/55_azureml-execution-tvmps_d1a60f800b713a447df92c06af2a65d82318837ba3be777a4b550fe7d66f4339_p.txt?sv=2018-11-09&sr=b&sig=Pyrg8N8FTMTk8TTn0K%2F5vKyzceSstcTEC5cYcMpef3k%3D&st=2019-10-16T01%3A48%3A01Z&se=2019-10-16T09%3A58%3A01Z&sp=r', 'azureml-logs/65_job_prep-tvmps_d1a60f800b713a447df92c06af2a65d82318837ba3be777a4b550fe7d66f4339_p.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1b5b1ca5-2a4d-40d2-b555-91fe269543b6/azureml-logs/65_job_prep-tvmps_d1a60f800b713a447df92c06af2a65d82318837ba3be777a4b550fe7d66f4339_p.txt?sv=2018-11-09&sr=b&sig=a5Nv48oQ4zJTPNL9WUnrXhAO756WclfqDtopxjLIeIU%3D&st=2019-10-16T01%3A48%3A01Z&se=2019-10-16T09%3A58%3A01Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1b5b1ca5-2a4d-40d2-b555-91fe269543b6/azureml-logs/70_driver_log.txt?sv=2018-11-09&sr=b&sig=jsj%2BmE5a2aL7OO69K8%2BgoVOWC6XuAEIuHFW8KL1r6b8%3D&st=2019-10-16T01%3A48%3A01Z&se=2019-10-16T09%3A58%3A01Z&sp=r', 'azureml-logs/75_job_post-tvmps_d1a60f800b713a447df92c06af2a65d82318837ba3be777a4b550fe7d66f4339_p.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1b5b1ca5-2a4d-40d2-b555-91fe269543b6/azureml-logs/75_job_post-tvmps_d1a60f800b713a447df92c06af2a65d82318837ba3be777a4b550fe7d66f4339_p.txt?sv=2018-11-09&sr=b&sig=veMBIwDMvaqVDmVgSQkPvmtbh72f96Z0EhBtZ%2BS42YQ%3D&st=2019-10-16T01%3A48%3A01Z&se=2019-10-16T09%3A58%3A01Z&sp=r', 'logs/azureml/138_azureml.log': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1b5b1ca5-2a4d-40d2-b555-91fe269543b6/logs/azureml/138_azureml.log?sv=2018-11-09&sr=b&sig=tknuyu0tl0IN20rqd2XzA7W6MalV9oomT3hOIzCDhZM%3D&st=2019-10-16T01%3A48%3A01Z&se=2019-10-16T09%3A58%3A01Z&sp=r', 'logs/azureml/azureml.log': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1b5b1ca5-2a4d-40d2-b555-91fe269543b6/logs/azureml/azureml.log?sv=2018-11-09&sr=b&sig=Fv4iSzCZFe4IjgBo3F76j1pt8AfNH71W3jhMA1TTM70%3D&st=2019-10-16T01%3A48%3A01Z&se=2019-10-16T09%3A58%3A01Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1b5b1ca5-2a4d-40d2-b555-91fe269543b6/logs/azureml/executionlogs.txt?sv=2018-11-09&sr=b&sig=r3dP155Vz9iXiGjKqzDn7slcyYY38xGh%2FE0Cn80Stgo%3D&st=2019-10-16T01%3A48%3A01Z&se=2019-10-16T09%3A58%3A01Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1b5b1ca5-2a4d-40d2-b555-91fe269543b6/logs/azureml/stderrlogs.txt?sv=2018-11-09&sr=b&sig=MyZFUvu%2FcWJSzbvHIzKq1O9Zhw2kpQxx%2BFk24AhsNIw%3D&st=2019-10-16T01%3A48%3A01Z&se=2019-10-16T09%3A58%3A01Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1b5b1ca5-2a4d-40d2-b555-91fe269543b6/logs/azureml/stdoutlogs.txt?sv=2018-11-09&sr=b&sig=2pOf0PvSqcrYEomSq11F9OVp0P81xR8vi9MhRmVlQCw%3D&st=2019-10-16T01%3A48%3A01Z&se=2019-10-16T09%3A58%3A01Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: 358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/9086b59a-02d7-4687-b3fd-e39fa5e0fd9b/resourceGroups/ignite-demo/providers/Microsoft.MachineLearningServices/workspaces/ignite-nlp-amlws/experiments/nlpatIgnite_014933/runs/358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9\n",
      "StepRun( train_step_xlnet-base-cased ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 138\n",
      "Entering Run History Context Manager.\n",
      "CUDA is available\n",
      "\n",
      "  0%|          | 0/641 [00:00<?, ?B/s]\n",
      "100%|██████████| 641/641 [00:00<00:00, 621917.39B/s]\n",
      "\n",
      "  0%|          | 0/467042463 [00:00<?, ?B/s]\n",
      "  1%|          | 4521984/467042463 [00:00<00:10, 45219559.69B/s]\n",
      "  2%|▏         | 9005056/467042463 [00:00<00:10, 45100981.10B/s]\n",
      "  3%|▎         | 14234624/467042463 [00:00<00:09, 47039352.20B/s]\n",
      "  4%|▍         | 19543040/467042463 [00:00<00:09, 48699916.40B/s]\n",
      "  5%|▌         | 24870912/467042463 [00:00<00:08, 49979557.77B/s]\n",
      "  6%|▋         | 30128128/467042463 [00:00<00:08, 50728944.39B/s]\n",
      "  8%|▊         | 35325952/467042463 [00:00<00:08, 51094162.68B/s]\n",
      "  9%|▊         | 40543232/467042463 [00:00<00:08, 51412838.69B/s]\n",
      " 10%|▉         | 45735936/467042463 [00:00<00:08, 51562342.26B/s]\n",
      " 11%|█         | 50970624/467042463 [00:01<00:08, 51794431.46B/s]\n",
      " 12%|█▏        | 56133632/467042463 [00:01<00:07, 51739912.73B/s]\n",
      " 13%|█▎        | 61383680/467042463 [00:01<00:07, 51965295.43B/s]\n",
      " 14%|█▍        | 66521088/467042463 [00:01<00:07, 51734860.36B/s]\n",
      " 15%|█▌        | 71788544/467042463 [00:01<00:07, 52011555.78B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 76961792/467042463 [00:01<00:07, 51680049.81B/s]\n",
      " 18%|█▊        | 82134016/467042463 [00:01<00:07, 51692086.24B/s]\n",
      " 19%|█▊        | 87347200/467042463 [00:01<00:07, 51819930.07B/s]\n",
      " 20%|█▉        | 92548096/467042463 [00:01<00:07, 51875917.26B/s]\n",
      " 21%|██        | 97757184/467042463 [00:01<00:07, 51933123.08B/s]\n",
      " 22%|██▏       | 102946816/467042463 [00:02<00:07, 50424484.33B/s]\n",
      " 23%|██▎       | 108169216/467042463 [00:02<00:07, 50949311.41B/s]\n",
      " 24%|██▍       | 113512448/467042463 [00:02<00:06, 51665688.09B/s]\n",
      " 25%|██▌       | 118735872/467042463 [00:02<00:06, 51833971.17B/s]\n",
      " 27%|██▋       | 123924480/467042463 [00:02<00:06, 51798589.69B/s]\n",
      " 28%|██▊       | 129107968/467042463 [00:02<00:06, 51750107.00B/s]\n",
      " 29%|██▉       | 134333440/467042463 [00:02<00:06, 51900221.26B/s]\n",
      " 30%|██▉       | 139548672/467042463 [00:02<00:06, 51972349.24B/s]\n",
      " 31%|███       | 144754688/467042463 [00:02<00:06, 51998007.54B/s]\n",
      " 32%|███▏      | 149955584/467042463 [00:02<00:06, 51765194.72B/s]\n",
      " 33%|███▎      | 155155456/467042463 [00:03<00:06, 51834196.52B/s]\n",
      " 34%|███▍      | 160361472/467042463 [00:03<00:05, 51901313.01B/s]\n",
      " 35%|███▌      | 165637120/467042463 [00:03<00:05, 52154878.85B/s]\n",
      " 37%|███▋      | 170874880/467042463 [00:03<00:05, 52219202.15B/s]\n",
      " 38%|███▊      | 176103424/467042463 [00:03<00:05, 52238249.54B/s]\n",
      " 39%|███▉      | 181327872/467042463 [00:03<00:05, 52112853.29B/s]\n",
      " 40%|███▉      | 186540032/467042463 [00:03<00:05, 52022256.53B/s]\n",
      " 41%|████      | 191742976/467042463 [00:03<00:05, 51715884.71B/s]\n",
      " 42%|████▏     | 196915200/467042463 [00:03<00:05, 51165793.13B/s]\n",
      " 43%|████▎     | 202034176/467042463 [00:03<00:05, 50309054.62B/s]\n",
      " 44%|████▍     | 207418368/467042463 [00:04<00:05, 51318500.77B/s]\n",
      " 46%|████▌     | 212728832/467042463 [00:04<00:04, 51839115.00B/s]\n",
      " 47%|████▋     | 218033152/467042463 [00:04<00:04, 52193877.98B/s]\n",
      " 48%|████▊     | 223290368/467042463 [00:04<00:04, 52306692.97B/s]\n",
      " 49%|████▉     | 228525056/467042463 [00:04<00:04, 52040595.68B/s]\n",
      " 50%|█████     | 233876480/467042463 [00:04<00:04, 52471976.35B/s]\n",
      " 51%|█████     | 239140864/467042463 [00:04<00:04, 52522270.59B/s]\n",
      " 52%|█████▏    | 244542464/467042463 [00:04<00:04, 52331376.43B/s]\n",
      " 53%|█████▎    | 249778176/467042463 [00:04<00:04, 48609681.14B/s]\n",
      " 55%|█████▍    | 255164416/467042463 [00:04<00:04, 50074229.26B/s]\n",
      " 56%|█████▌    | 260489216/467042463 [00:05<00:04, 50984459.35B/s]\n",
      " 57%|█████▋    | 265799680/467042463 [00:05<00:03, 51599559.84B/s]\n",
      " 58%|█████▊    | 271116288/467042463 [00:05<00:03, 52056761.42B/s]\n",
      " 59%|█████▉    | 276485120/467042463 [00:05<00:03, 52531544.22B/s]\n",
      " 60%|██████    | 281869312/467042463 [00:05<00:03, 52916511.85B/s]\n",
      " 61%|██████▏   | 287173632/467042463 [00:05<00:03, 52867002.68B/s]\n",
      " 63%|██████▎   | 292468736/467042463 [00:05<00:03, 52681573.53B/s]\n",
      " 64%|██████▍   | 297743360/467042463 [00:05<00:03, 52692988.68B/s]\n",
      " 65%|██████▍   | 303020032/467042463 [00:05<00:03, 52713594.83B/s]\n",
      " 66%|██████▌   | 308338688/467042463 [00:05<00:03, 52853862.45B/s]\n",
      " 67%|██████▋   | 313655296/467042463 [00:06<00:02, 52946591.37B/s]\n",
      " 68%|██████▊   | 318952448/467042463 [00:06<00:02, 52950978.04B/s]\n",
      " 69%|██████▉   | 324249600/467042463 [00:06<00:02, 52873447.67B/s]\n",
      " 71%|███████   | 329538560/467042463 [00:06<00:02, 52769666.24B/s]\n",
      " 72%|███████▏  | 334836736/467042463 [00:06<00:02, 52830267.16B/s]\n",
      " 73%|███████▎  | 340120576/467042463 [00:06<00:02, 52749650.46B/s]\n",
      " 74%|███████▍  | 345396224/467042463 [00:06<00:02, 51975333.62B/s]\n",
      " 75%|███████▌  | 350628864/467042463 [00:06<00:02, 52079542.47B/s]\n",
      " 76%|███████▌  | 356005888/467042463 [00:06<00:02, 52572518.25B/s]\n",
      " 77%|███████▋  | 361281536/467042463 [00:06<00:02, 52625071.20B/s]\n",
      " 79%|███████▊  | 366654464/467042463 [00:07<00:01, 52950657.88B/s]\n",
      " 80%|███████▉  | 372007936/467042463 [00:07<00:01, 53123040.85B/s]\n",
      " 81%|████████  | 377322496/467042463 [00:07<00:01, 52956508.18B/s]\n",
      " 82%|████████▏ | 382648320/467042463 [00:07<00:01, 53046607.66B/s]\n",
      " 83%|████████▎ | 388035584/467042463 [00:07<00:01, 53286670.52B/s]\n",
      " 84%|████████▍ | 393365504/467042463 [00:07<00:01, 53209697.03B/s]\n",
      " 85%|████████▌ | 398728192/467042463 [00:07<00:01, 53332704.37B/s]\n",
      " 87%|████████▋ | 404062208/467042463 [00:07<00:01, 53123372.58B/s]\n",
      " 88%|████████▊ | 409375744/467042463 [00:07<00:01, 52901127.17B/s]\n",
      " 89%|████████▉ | 414690304/467042463 [00:07<00:00, 52973492.29B/s]\n",
      " 90%|████████▉ | 419988480/467042463 [00:08<00:00, 51666634.80B/s]\n",
      " 91%|█████████ | 425263104/467042463 [00:08<00:00, 51983883.06B/s]\n",
      " 92%|█████████▏| 430494720/467042463 [00:08<00:00, 52080058.92B/s]\n",
      " 93%|█████████▎| 435746816/467042463 [00:08<00:00, 52209634.46B/s]\n",
      " 94%|█████████▍| 440987648/467042463 [00:08<00:00, 52267940.82B/s]\n",
      " 96%|█████████▌| 446217216/467042463 [00:08<00:00, 52122138.85B/s]\n",
      " 97%|█████████▋| 451549184/467042463 [00:08<00:00, 52471592.52B/s]\n",
      " 98%|█████████▊| 456798208/467042463 [00:08<00:00, 52421759.11B/s]\n",
      " 99%|█████████▉| 462156800/467042463 [00:08<00:00, 52763557.95B/s]\n",
      "100%|██████████| 467042463/467042463 [00:08<00:00, 52047102.15B/s]\n",
      "/azureml-envs/azureml_7bc8a6b5673da8c9051f3434792cb5f9/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "1 items cleaning up...\n",
      "Cleanup took 0.0005419254302978516 seconds\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt\n",
      "===============================================================================================================\n",
      "Starting job release. Current time:2019-10-16T02:07:29.537953\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 8354\n",
      "Job release is complete. Current time:2019-10-16T02:07:31.007589\n",
      "\n",
      "StepRun(train_step_xlnet-base-cased) Execution Summary\n",
      "=======================================================\n",
      "StepRun( train_step_xlnet-base-cased ) Status: Finished\n",
      "{'runId': '358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9', 'target': 'ignite-nlp-clstr', 'status': 'Completed', 'startTimeUtc': '2019-10-16T01:58:00.870065Z', 'endTimeUtc': '2019-10-16T02:07:43.772955Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '2735c4ee-f582-4a06-a31c-ed5f8d3f1eb8', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': '68e2c2c4-cfe7-417e-978f-957a2febd8c6', '_azureml.ComputeTargetType': 'batchai', 'AzureML.DerivedImageName': 'azureml/azureml_79c60456c523f591a63f904cd43533f4', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'runDefinition': {'script': 'train.py', 'arguments': ['$AZUREML_DATAREFERENCE_preprocessed', '$AZUREML_DATAREFERENCE_trained', 'xlnet-base-cased', '2'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'ignite-nlp-clstr', 'dataReferences': {'preprocessed': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/1b5b1ca5-2a4d-40d2-b555-91fe269543b6/preprocessed', 'pathOnCompute': None, 'overwrite': False}, 'trained': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9/trained', 'pathOnCompute': 'data/trained_xlnet-base-cased', 'overwrite': False}}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment nlpatIgnite_014933 Environment', 'version': 'Autosave_2019-10-16T01:50:13Z_b643da0f', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge'], 'dependencies': ['python=3.6.8', {'pip': ['azureml-sdk==1.0.65', 'torch==1.1', 'tqdm==4.31.1', 'transformers==2.1.1', 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/Environment/azureml-private-packages/utils_nlp-1.0.0-py3-none-any.whl']}, 'numpy', 'scikit-learn', 'pandas'], 'name': 'azureml_7bc8a6b5673da8c9051f3434792cb5f9'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9/azureml-logs/55_azureml-execution-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt?sv=2018-11-09&sr=b&sig=kBTIAVMCe%2FbGvIsM4BGxmJGRtbfC%2F%2Fnw6GPpJ1nBw9w%3D&st=2019-10-16T01%3A57%3A49Z&se=2019-10-16T10%3A07%3A49Z&sp=r', 'azureml-logs/65_job_prep-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9/azureml-logs/65_job_prep-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt?sv=2018-11-09&sr=b&sig=bThmuqFapB9AOtSdwq9OlgIBWq%2B16DShDw6oDi%2BsbKU%3D&st=2019-10-16T01%3A57%3A49Z&se=2019-10-16T10%3A07%3A49Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9/azureml-logs/70_driver_log.txt?sv=2018-11-09&sr=b&sig=KGgYAU0pukuI28mYAL%2BwFuErKNA08U7dIDc6k9PAPRY%3D&st=2019-10-16T01%3A57%3A49Z&se=2019-10-16T10%3A07%3A49Z&sp=r', 'azureml-logs/75_job_post-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9/azureml-logs/75_job_post-tvmps_13e9df76c1820554ddbdafbd3d559ea8447b4c9db4aa8344cf0437152ecc1556_p.txt?sv=2018-11-09&sr=b&sig=AeZsik1Q1cxUFwhldE8hMISkdW8BoP%2FDvaGgPUkwpx0%3D&st=2019-10-16T01%3A57%3A49Z&se=2019-10-16T10%3A07%3A49Z&sp=r', 'logs/azureml/138_azureml.log': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9/logs/azureml/138_azureml.log?sv=2018-11-09&sr=b&sig=DxvJAfNRxVAO%2BJfQknH%2BhJucC5wnuN%2BoS61GrSJrjeY%3D&st=2019-10-16T01%3A57%3A49Z&se=2019-10-16T10%3A07%3A49Z&sp=r', 'logs/azureml/azureml.log': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9/logs/azureml/azureml.log?sv=2018-11-09&sr=b&sig=5CytjQGM4yLjmt%2FU5SRsgfamWceXjsgyWJqBzHXSvMQ%3D&st=2019-10-16T01%3A57%3A49Z&se=2019-10-16T10%3A07%3A49Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9/logs/azureml/executionlogs.txt?sv=2018-11-09&sr=b&sig=4tfNbYbsEuURur0EtgbFmv2%2FQcK30w09ZBXgwH6pRQU%3D&st=2019-10-16T01%3A57%3A49Z&se=2019-10-16T10%3A07%3A49Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9/logs/azureml/stderrlogs.txt?sv=2018-11-09&sr=b&sig=kKDPRe98WhvITbSgA1bXS%2BaueFFV79B1N%2B%2BbkWhAV9g%3D&st=2019-10-16T01%3A57%3A49Z&se=2019-10-16T10%3A07%3A49Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.358d7dc7-f0e5-4e3d-b1a3-c2e771476bb9/logs/azureml/stdoutlogs.txt?sv=2018-11-09&sr=b&sig=WhEmCwIswEkaEom1IzOFH0inN%2FYv8KhcjzkpPWuOhes%3D&st=2019-10-16T01%3A57%3A49Z&se=2019-10-16T10%3A07%3A49Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 1f98ff68-ccd0-4eeb-894d-7aef446385ea\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/9086b59a-02d7-4687-b3fd-e39fa5e0fd9b/resourceGroups/ignite-demo/providers/Microsoft.MachineLearningServices/workspaces/ignite-nlp-amlws/experiments/nlpatIgnite_014933/runs/1f98ff68-ccd0-4eeb-894d-7aef446385ea\n",
      "\n",
      "StepRun(train_step_bert-base-uncased) Execution Summary\n",
      "========================================================\n",
      "StepRun( train_step_bert-base-uncased ) Status: Finished\n",
      "{'runId': '1f98ff68-ccd0-4eeb-894d-7aef446385ea', 'target': 'ignite-nlp-clstr', 'status': 'Completed', 'startTimeUtc': '2019-10-16T01:58:06.496085Z', 'endTimeUtc': '2019-10-16T02:05:42.715641Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '2735c4ee-f582-4a06-a31c-ed5f8d3f1eb8', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': '68e2c2c4-cfe7-417e-978f-957a2febd8c6', '_azureml.ComputeTargetType': 'batchai', 'AzureML.DerivedImageName': 'azureml/azureml_79c60456c523f591a63f904cd43533f4', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'runDefinition': {'script': 'train.py', 'arguments': ['$AZUREML_DATAREFERENCE_preprocessed', '$AZUREML_DATAREFERENCE_trained', 'bert-base-uncased', '2'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'ignite-nlp-clstr', 'dataReferences': {'preprocessed': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/ebd5e908-034e-482e-acfb-95cb23255b63/preprocessed', 'pathOnCompute': None, 'overwrite': False}, 'trained': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/1f98ff68-ccd0-4eeb-894d-7aef446385ea/trained', 'pathOnCompute': 'data/trained_bert-base-uncased', 'overwrite': False}}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment nlpatIgnite_014933 Environment', 'version': 'Autosave_2019-10-16T01:50:13Z_b643da0f', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge'], 'dependencies': ['python=3.6.8', {'pip': ['azureml-sdk==1.0.65', 'torch==1.1', 'tqdm==4.31.1', 'transformers==2.1.1', 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/Environment/azureml-private-packages/utils_nlp-1.0.0-py3-none-any.whl']}, 'numpy', 'scikit-learn', 'pandas'], 'name': 'azureml_7bc8a6b5673da8c9051f3434792cb5f9'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_d1a60f800b713a447df92c06af2a65d82318837ba3be777a4b550fe7d66f4339_p.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1f98ff68-ccd0-4eeb-894d-7aef446385ea/azureml-logs/55_azureml-execution-tvmps_d1a60f800b713a447df92c06af2a65d82318837ba3be777a4b550fe7d66f4339_p.txt?sv=2018-11-09&sr=b&sig=rBUm7zWzU8qetTb0H4XDdUMS8p57ljKMztlTTmIJF5I%3D&st=2019-10-16T01%3A57%3A50Z&se=2019-10-16T10%3A07%3A50Z&sp=r', 'azureml-logs/65_job_prep-tvmps_d1a60f800b713a447df92c06af2a65d82318837ba3be777a4b550fe7d66f4339_p.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1f98ff68-ccd0-4eeb-894d-7aef446385ea/azureml-logs/65_job_prep-tvmps_d1a60f800b713a447df92c06af2a65d82318837ba3be777a4b550fe7d66f4339_p.txt?sv=2018-11-09&sr=b&sig=%2BLKkWzah982p07VWSHz%2BU2CYzjyvhE2VkZNnjIE%2B5RA%3D&st=2019-10-16T01%3A57%3A50Z&se=2019-10-16T10%3A07%3A50Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1f98ff68-ccd0-4eeb-894d-7aef446385ea/azureml-logs/70_driver_log.txt?sv=2018-11-09&sr=b&sig=zWe1abWOWD2nZbQhADZdNejlTCjKAZk7Qml8fvGFkIo%3D&st=2019-10-16T01%3A57%3A50Z&se=2019-10-16T10%3A07%3A50Z&sp=r', 'azureml-logs/75_job_post-tvmps_d1a60f800b713a447df92c06af2a65d82318837ba3be777a4b550fe7d66f4339_p.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1f98ff68-ccd0-4eeb-894d-7aef446385ea/azureml-logs/75_job_post-tvmps_d1a60f800b713a447df92c06af2a65d82318837ba3be777a4b550fe7d66f4339_p.txt?sv=2018-11-09&sr=b&sig=en%2Fswg6xXyb6ad%2Bw%2Fk0EPZczLLY%2FwlnJjGSS4pDA%2B7M%3D&st=2019-10-16T01%3A57%3A50Z&se=2019-10-16T10%3A07%3A50Z&sp=r', 'logs/azureml/138_azureml.log': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1f98ff68-ccd0-4eeb-894d-7aef446385ea/logs/azureml/138_azureml.log?sv=2018-11-09&sr=b&sig=Lqh161DJcFINFnRds8n8FHT5cW1ZHo6Ys0PJ0QwI9Xo%3D&st=2019-10-16T01%3A57%3A50Z&se=2019-10-16T10%3A07%3A50Z&sp=r', 'logs/azureml/azureml.log': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1f98ff68-ccd0-4eeb-894d-7aef446385ea/logs/azureml/azureml.log?sv=2018-11-09&sr=b&sig=IDlJHVLfmQCq8mhFPLVd7IYVIBj7xTkFIavaWn2ic%2F8%3D&st=2019-10-16T01%3A57%3A50Z&se=2019-10-16T10%3A07%3A50Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1f98ff68-ccd0-4eeb-894d-7aef446385ea/logs/azureml/executionlogs.txt?sv=2018-11-09&sr=b&sig=s6n1Z%2FgzWOxfrFy2Jg2B80EmiL27ChLXLZ4P%2Fj%2FtX6o%3D&st=2019-10-16T01%3A57%3A50Z&se=2019-10-16T10%3A07%3A50Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1f98ff68-ccd0-4eeb-894d-7aef446385ea/logs/azureml/stderrlogs.txt?sv=2018-11-09&sr=b&sig=XXVJEJgKsiqUt4LvmJPYieREUP81W4Otk3EhocNiyS8%3D&st=2019-10-16T01%3A57%3A50Z&se=2019-10-16T10%3A07%3A50Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.1f98ff68-ccd0-4eeb-894d-7aef446385ea/logs/azureml/stdoutlogs.txt?sv=2018-11-09&sr=b&sig=GJST6kVfuup5syjIPnfxfJ6logTfpy%2BUWVOeAkks8gc%3D&st=2019-10-16T01%3A57%3A50Z&se=2019-10-16T10%3A07%3A50Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '68e2c2c4-cfe7-417e-978f-957a2febd8c6', 'status': 'Completed', 'startTimeUtc': '2019-10-16T01:50:07.495022Z', 'endTimeUtc': '2019-10-16T02:07:48.086051Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': None, 'runType': 'HTTP', 'azureml.parameters': '{}'}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.68e2c2c4-cfe7-417e-978f-957a2febd8c6/logs/azureml/executionlogs.txt?sv=2018-11-09&sr=b&sig=Ot1DO2IfqF9M3tkTfWNu3R94f4IlKhFp09zEkqtbz6U%3D&st=2019-10-16T01%3A57%3A52Z&se=2019-10-16T10%3A07%3A52Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.68e2c2c4-cfe7-417e-978f-957a2febd8c6/logs/azureml/stderrlogs.txt?sv=2018-11-09&sr=b&sig=hMalfwS%2ByYqltGM0NN7fTkIlP7sdPU%2Fy2hjrxKSxfR4%3D&st=2019-10-16T01%3A57%3A52Z&se=2019-10-16T10%3A07%3A52Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://ignitenlstoragedbbd0cb09.blob.core.windows.net/azureml/ExperimentRun/dcid.68e2c2c4-cfe7-417e-978f-957a2febd8c6/logs/azureml/stdoutlogs.txt?sv=2018-11-09&sr=b&sig=5%2B6tYb3fKImY9eD%2BYZYS%2BxouURkBjjc1wR3sv%2B4Y33w%3D&st=2019-10-16T01%3A57%3A52Z&se=2019-10-16T10%3A07%3A52Z&sp=r'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create pipeline\n",
    "pipeline = Pipeline(workspace=ws, steps=[all_steps])\n",
    "experiment_name = \"nlpatIgnite_\" + datetime.now().strftime(\"%H%M%S\")\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "pipeline_run = experiment.submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=False)\n",
    "pipeline_run_id = pipeline_run.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve a Trained Model from Pipeline\n",
    "\n",
    "The Azure ML SDK allows retrieving the pipeline runs and steps using the run id and step name. The following example downloads the output of the training step of the first model in *MODEL_NAMES*, which includes the fine-tuned classifier and the label_encoder used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve an existing training step & download corresponding model\n",
    "# (from an existing experiment and pipeline run)\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "pipeline_run = PipelineRun(experiment, pipeline_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step_run = pipeline_run.find_step_run(\"train_step_{}\".format(MODEL_NAMES[0]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download\n",
    "train_step_run.get_output_data(output_dir.name).download(local_path=TEMP_DIR)\n",
    "\n",
    "# load classifier and label encoder\n",
    "trained_dir = (\n",
    "    \"./temp/azureml/\" + train_step_run.id + \"/\" + output_dir.name \n",
    ")\n",
    "classifier = pickle.load(open(trained_dir + \"/\" + MODEL_NAMES[0] + \"_clf\", \"rb\"))\n",
    "label_encoder = pickle.load(open(trained_dir + \"/\" + MODEL_NAMES[0] + \"_le\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model\n",
    "Finally, we can test the model by scoring some text input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['fiction'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "test_input = [\"Let's go to Orlando. I've heard it's a nice place\"]\n",
    "processor = Processor(model_name=MODEL_NAMES[0], cache_dir=TEMP_DIR)\n",
    "test_ds = processor.preprocess(test_input, max_len=150)\n",
    "pred = classifier.predict(test_ds, device=\"cpu\")\n",
    "label_encoder.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:nlp_gpu]",
   "language": "python",
   "name": "conda-env-nlp_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
