# Model Explainability

This folder contains examples and best practices, written in Jupyter notebooks, for explaining and
interpreting models. Being able to explain and understand machine learning models does not only help
guiding further model improvements. More importantly, it's critical for gaining user's trust of the
models and detecting biases caused by the training data.

## Summary

|Notebook|Environment|Description|Dataset|
|---|:---:|---|---|
|[DUUDNM](interpret_dnn_layers.ipynb)|Local| Interpreting DNN Layers using Mutual Information.||
