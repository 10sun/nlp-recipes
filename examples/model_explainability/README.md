# Model Explainability

This folder contains examples and best practices, written in Jupyter notebooks, for explaining and
interpreting models. Being able to explain and understand machine learning models does not only help
guiding further model improvements. More importantly, it helps gaining user's trust of the models and
detect biases caused by the training data.

## Summary

|Notebook|Environment|Description|Dataset|
|---|:---:|---|---|
|[DUUDNM](interpret_dnn_layers.ipynb)|Local| Interpreting DNN Layers using Mutual Information.||
