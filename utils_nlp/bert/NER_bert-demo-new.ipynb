{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition Using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required packages\n",
    "* pytorch-pretrained-bert\n",
    "* pandas\n",
    "* seqeval\n",
    "* unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import random\n",
    "\n",
    "bert_utils_path = os.path.abspath('../../utils_nlp/bert')\n",
    "if bert_utils_path not in sys.path:\n",
    "    sys.path.insert(0, bert_utils_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from configs import PathConfig, GlobalConfig, DeviceConfig, ModelConfig, OptimizerConfig, TrainConfig, EvalConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_config_dict = {\"data_dir\": \"./data/NER/\", \n",
    "                    \"output_dir\": \"./NER_output/\"}\n",
    "path_config = PathConfig(path_config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "global_config_dict = {\"fp16\": False}\n",
    "global_config = GlobalConfig(global_config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device name: Tesla K80\n",
      "number of gpus: 1\n"
     ]
    }
   ],
   "source": [
    "device_config_dict = {\"no_cuda\": False}\n",
    "device_config = DeviceConfig(device_config_dict)\n",
    "print(\"device name: {}\".format(torch.cuda.get_device_name(0)))\n",
    "print(\"number of gpus: {}\".format(device_config.n_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_config_dict = {\"bert_model\": \"bert-base-uncased\",\n",
    "                     \"max_seq_length\": 75,\n",
    "                     \"num_labels\": 18,\n",
    "                     \"model_type\": \"token\"}\n",
    "model_config = ModelConfig(model_config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer_config_dict = {\"no_decay_params\": ['bias', 'gamma', 'beta'],\n",
    "                         \"learning_rate\": 3e-5}\n",
    "optimizer_config = OptimizerConfig(optimizer_config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_config_dict = {\"train_batch_size\": 32,\n",
    "                     \"num_train_epochs\": 5}\n",
    "train_config = TrainConfig(train_config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_config = EvalConfig({\"eval_batch_size\":32})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa16fad6150>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(global_config.seed)\n",
    "np.random.seed(global_config.seed)\n",
    "torch.manual_seed(global_config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and validation examples\n",
    "KaggleNERProcessor is a dataset specific class that generates training and evaluation examples in the format accepted by all utility functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bert_data_utils import KaggleNERProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kaggle_ner_processor = KaggleNERProcessor(data_dir=\"./data/NER/ner_dataset.csv\", dev_percentage = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_examples = kaggle_ner_processor.get_train_examples(data_dir=\"./data/NER/ner_dataset.csv\")\n",
    "dev_examples = kaggle_ner_processor.get_dev_examples(data_dir=\"./data/NER/ner_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set(kaggle_ner_processor.train_sentence_nums)\n",
    "b = set(kaggle_ner_processor.dev_sentence_nums)\n",
    "a.intersection(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_list = kaggle_ner_processor.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence: \n",
      "Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "\n",
      "Sample sentence labels: \n",
      "['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'B-org', 'O', 'O', 'O', 'O', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Sample sentence: \\n{}\\n'.format(train_examples[0].text_a))\n",
    "print('Sample sentence labels: \\n{}\\n'.format(train_examples[1].label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloaders\n",
    "These two utility functions convert training and evaluation examples to Pytorch dataloaders which can be used for model training and evaluation. The following steps are performed:\n",
    "1. Tokenization\n",
    "2. Convert tokens and labels to numerical values\n",
    "3. Sequence padding or truncation\n",
    "4. Convert numpy arrays to Pytorch tensors\n",
    "5. Create dataloader for sampling and serving data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bert_utils import create_train_dataloader, create_eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataloader = create_train_dataloader(train_examples=train_examples,\n",
    "                                           model_config=model_config,\n",
    "                                           train_config=train_config,\n",
    "                                           label_list=label_list,\n",
    "                                           device_config=device_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valid_dataloader, _ = create_eval_dataloader(eval_examples=dev_examples, \n",
    "                                             model_config=model_config, \n",
    "                                             eval_config=eval_config, \n",
    "                                             label_list=label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample token ids:\n",
      "tensor([ 1057, 29625,  2015, 29625, 29624,  3709,  2749,  1999,  7041,  2360,\n",
      "         2027,  2730,  2321, 17671,  2076,  2019, 11585,  3169,  1999,  1996,\n",
      "         2264,  1010,  2096,  2334,  4584,  2758,  2216,  2730,  2020,  9272,\n",
      "         1012,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n",
      "\n",
      "Sample attention mask:\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0])\n",
      "\n",
      "Sample label ids:\n",
      "tensor([ 1, 17, 17, 17, 17, 17,  1,  1, 13,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_dataloader)\n",
    "first = next(it)\n",
    "print(\"Sample token ids:\\n{}\\n\".format(first[0][0]))\n",
    "print(\"Sample attention mask:\\n{}\\n\".format(first[1][0]))\n",
    "print(\"Sample label ids:\\n{}\\n\".format(first[3][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bert_utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = load_model(model_config=model_config, \n",
    "                   path_config=path_config, \n",
    "                   device_config=device_config,\n",
    "                   global_config=global_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pytorch_pretrained_bert.modeling.BertForTokenClassification"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bert_utils import configure_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer, optimizer_config, _ = configure_optimizer(optimizer_config=optimizer_config,\n",
    "                                                     global_config=global_config, \n",
    "                                                     train_config=train_config, \n",
    "                                                     device_config=device_config, \n",
    "                                                     model=model, \n",
    "                                                     num_train_examples=len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.adam.Adam"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 3e-05\n",
       "    weight_decay: 0.01\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 3e-05\n",
       "    weight_decay: 0.0\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['weight_decay']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bert_utils import train_token_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.24524948639923594\n",
      "Validation loss: 0.17619687835375467\n",
      "Validation Accuracy: 0.6607947530864196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 1/5 [22:30<1:30:01, 1350.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.5384509750068662\n",
      "Train loss: 0.23885687313051557\n",
      "Validation loss: 0.22382892300685248\n",
      "Validation Accuracy: 0.9795953703703708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 2/5 [45:12<1:07:41, 1353.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.773664250148345\n",
      "Train loss: 0.2708684699437281\n",
      "Validation loss: 0.26138194382190705\n",
      "Validation Accuracy: 0.9756471193415636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 3/5 [1:07:54<45:12, 1356.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.7539385259446953\n",
      "Train loss: 0.2847153783242202\n",
      "Validation loss: 0.2587072236339251\n",
      "Validation Accuracy: 0.9763917695473245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 4/5 [1:30:36<22:38, 1358.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.7518122751436396\n",
      "Train loss: 0.2878860058476962\n",
      "Validation loss: 0.28233432402213415\n",
      "Validation Accuracy: 0.9749407407407401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 100%|██████████| 5/5 [1:53:16<00:00, 1358.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.7332092615906728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, train_loss = train_token_model(model=model, \n",
    "                                      train_dataloader=train_dataloader, \n",
    "                                      valid_dataloader=valid_dataloader,\n",
    "                                      label_list=label_list,\n",
    "                                      optimizer=optimizer,\n",
    "                                      train_config=train_config, \n",
    "                                      model_config=model_config, \n",
    "                                      optimizer_config=optimizer_config,\n",
    "                                      device_config=device_config,\n",
    "                                      global_config=global_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bert_utils import eval_token_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2580980388323466\n",
      "Validation Accuracy: 0.9766516460905346\n",
      "Validation F1-Score: 0.7453125410892262\n"
     ]
    }
   ],
   "source": [
    "preds, eval_loss, eval_accuracy = eval_token_model(model=model, \n",
    "                                                   eval_dataloader=valid_dataloader, \n",
    "                                                   model_config=model_config, \n",
    "                                                   device_config=device_config, \n",
    "                                                   label_list=label_list,\n",
    "                                                   eval_func=flat_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
