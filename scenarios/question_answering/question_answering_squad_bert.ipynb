{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering on the SQuAD Dataset using BERT\n",
    "## Summary\n",
    "This notebook demonstrates how to fine tune [pretrained BERT model](https://github.com/huggingface/pytorch-transformers) for extractive question answering task. Utility functions and classes in the NLP Best Practices repo are used to facilitate data preprocessing, model training, model scoring, result postprocessing, and model evaluation. \n",
    "\n",
    "BERT[\\[1\\]](#References) is a powerful pre-trained lanaguage model that can be used for multiple NLP tasks, including text classification, question answering, named entity recognition, etc. It's able to achieve state of the art performance with only a few epochs of fine tuning on task specific datasets.  \n",
    "The figure below illustrates how BERT can be fine tuned for extractive question answering task. The question and paragraph tokens are concatenated as a single input token sequence with a special token [SEP] between them. For the paragraph tokens, BERT predicts the probabilities of each token being the start and end of the answer span. The tokens with the highest sum of starting probability and ending probability define the span of the predicted answer\n",
    "\n",
    "<img src=\"https://nlpbp.blob.core.windows.net/images/bert_qa.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "nlp_path = os.path.abspath('../../')\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "\n",
    "from utils_nlp.dataset.squad import load_pandas_df\n",
    "from utils_nlp.models.bert.common import Language, Tokenizer\n",
    "from utils_nlp.models.bert.question_answering import BERTQAExtractor\n",
    "from utils_nlp.models.bert.qa_utils import postprocess_answers, evaluate_qa\n",
    "from utils_nlp.common.timer import Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUAD_VERSION = \"v1.1\" \n",
    "CACHE_DIR = \"./temp\"\n",
    "\n",
    "LANGUAGE = Language.ENGLISHLARGEWWM\n",
    "DO_LOWER_CASE = True\n",
    "\n",
    "MAX_SEQ_LENGTH = 384\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 3e-5\n",
    "WARMUP = 0.1\n",
    "\n",
    "DOC_TEXT_COL = \"doc_text\"\n",
    "QUESTION_TEXT_COL = \"question_text\"\n",
    "ANSWER_START_COL = \"answer_start\"\n",
    "ANSWER_TEXT_COL = \"answer_text\"\n",
    "QA_ID_COL = \"qa_id\"\n",
    "IS_IMPOSSIBLE_COL = \"is_impossible\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if  torch.cuda.device_count() > 0:\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The SQuAD Dataset\n",
    "Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable. [\\[2, 3\\]](#References)\n",
    "\n",
    "<img src=\"https://nlpbp.blob.core.windows.net/images/squad.png\">\n",
    "\n",
    "There has been two versions of SQuAD datasets. SQuAD 1.1 contains 100,000+ question-answer pairs on 500+ articles. SQuAD 2.0 adds 50,000 new, unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. These datasets are available at [https://rajpurkar.github.io/SQuAD-explorer/](https://rajpurkar.github.io/SQuAD-explorer/). Each dataset comes with a training dataset and a development dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utility function `load_pandas_df` downloads the dataset specified by `squad_version` and `file_split` to `local_cache_path` if it doesn't exist already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_pandas_df(local_cache_path=\".\", squad_version=\"v1.1\", file_split=\"train\")\n",
    "dev_df = load_pandas_df(local_cache_path=\".\", squad_version=\"v1.1\", file_split=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_text</th>\n",
       "      <th>question_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>is_impossible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>188</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>279</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>381</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>92</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_text  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                       question_text  answer_start  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...           515   \n",
       "1  What is in front of the Notre Dame Main Building?           188   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...           279   \n",
       "3                  What is the Grotto at Notre Dame?           381   \n",
       "4  What sits on top of the Main Building at Notre...            92   \n",
       "\n",
       "                               answer_text                     qa_id  \\\n",
       "0               Saint Bernadette Soubirous  5733be284776f41900661182   \n",
       "1                a copper statue of Christ  5733be284776f4190066117f   \n",
       "2                        the Main Building  5733be284776f41900661180   \n",
       "3  a Marian place of prayer and reflection  5733be284776f41900661181   \n",
       "4       a golden statue of the Virgin Mary  5733be284776f4190066117e   \n",
       "\n",
       "   is_impossible  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_text</th>\n",
       "      <th>question_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>is_impossible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>[177, 177, 177]</td>\n",
       "      <td>[Denver Broncos, Denver Broncos, Denver Broncos]</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>[249, 249, 249]</td>\n",
       "      <td>[Carolina Panthers, Carolina Panthers, Carolin...</td>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>[403, 355, 355]</td>\n",
       "      <td>[Santa Clara, California, Levi's Stadium, Levi...</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team won Super Bowl 50?</td>\n",
       "      <td>[177, 177, 177]</td>\n",
       "      <td>[Denver Broncos, Denver Broncos, Denver Broncos]</td>\n",
       "      <td>56be4db0acb8001400a502ef</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>What color was used to emphasize the 50th anni...</td>\n",
       "      <td>[488, 488, 521]</td>\n",
       "      <td>[gold, gold, gold]</td>\n",
       "      <td>56be4db0acb8001400a502f0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_text  \\\n",
       "0  Super Bowl 50 was an American football game to...   \n",
       "1  Super Bowl 50 was an American football game to...   \n",
       "2  Super Bowl 50 was an American football game to...   \n",
       "3  Super Bowl 50 was an American football game to...   \n",
       "4  Super Bowl 50 was an American football game to...   \n",
       "\n",
       "                                       question_text     answer_start  \\\n",
       "0  Which NFL team represented the AFC at Super Bo...  [177, 177, 177]   \n",
       "1  Which NFL team represented the NFC at Super Bo...  [249, 249, 249]   \n",
       "2                Where did Super Bowl 50 take place?  [403, 355, 355]   \n",
       "3                  Which NFL team won Super Bowl 50?  [177, 177, 177]   \n",
       "4  What color was used to emphasize the 50th anni...  [488, 488, 521]   \n",
       "\n",
       "                                         answer_text  \\\n",
       "0   [Denver Broncos, Denver Broncos, Denver Broncos]   \n",
       "1  [Carolina Panthers, Carolina Panthers, Carolin...   \n",
       "2  [Santa Clara, California, Levi's Stadium, Levi...   \n",
       "3   [Denver Broncos, Denver Broncos, Denver Broncos]   \n",
       "4                                 [gold, gold, gold]   \n",
       "\n",
       "                      qa_id  is_impossible  \n",
       "0  56be4db0acb8001400a502ec          False  \n",
       "1  56be4db0acb8001400a502ed          False  \n",
       "2  56be4db0acb8001400a502ee          False  \n",
       "3  56be4db0acb8001400a502ef          False  \n",
       "4  56be4db0acb8001400a502f0          False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(language=LANGUAGE, to_lower=DO_LOWER_CASE, cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tokenizer_qa` method of `Tokenizer` tokenizes the input paragraph, question, and answer texts and converts them into the format required by pre-trained BERT model, involving the following steps:\n",
    "* WordPiece tokenization.\n",
    "* Convert character-based answer span indices to token-based indices.\n",
    "* Truncate the question token list if it's longer than `max_query_length`.\n",
    "* Split the paragraph into multiple segments if it's longer than `MAX_SEQ_LENGTH` - `max_query_length` - 3. (The \"-3\" is for the special [CLS] token and two [SEP] tokens.)\n",
    "* Add the special tokens [CLS] and [SEP].\n",
    "* Pad the concatenated token sequence to `MAX_SEQ_LENGTH` if it's shorter.\n",
    "* Convert the tokens into token indices corresponding to the BERT tokenizer's vocabulary.\n",
    "\n",
    "In additional to the features required by BERT, `tokenize_qa` outputs a few additional fields needed by postprocessing. See the `QAFeatures` class in [qa_utils.py](../../utils_nlp/models/bert/qa_utils.py) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, qa_examples = tokenizer.tokenize_qa(\n",
    "    doc_text=train_df[DOC_TEXT_COL], \n",
    "    question_text=train_df[QUESTION_TEXT_COL], \n",
    "    answer_start=train_df[ANSWER_START_COL], \n",
    "    answer_text=train_df[ANSWER_TEXT_COL],\n",
    "    qa_id=train_df[QA_ID_COL],\n",
    "    is_impossible=train_df[IS_IMPOSSIBLE_COL],\n",
    "    is_training=True,\n",
    "    max_len=MAX_SEQ_LENGTH,\n",
    "    max_query_length=64,\n",
    "    cache_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_features, dev_examples = tokenizer.tokenize_qa(\n",
    "    doc_text=dev_df[DOC_TEXT_COL], \n",
    "    question_text=dev_df[QUESTION_TEXT_COL], \n",
    "    answer_start=dev_df[ANSWER_START_COL], \n",
    "    answer_text=dev_df[ANSWER_TEXT_COL],\n",
    "    qa_id=dev_df[QA_ID_COL],\n",
    "    is_impossible=dev_df[IS_IMPOSSIBLE_COL],\n",
    "    is_training=False,\n",
    "    max_len=MAX_SEQ_LENGTH,\n",
    "    max_query_length=64,\n",
    "    cache_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_id\n",
      "1000000000\n",
      "\n",
      "qa_id\n",
      "5733be284776f41900661182\n",
      "\n",
      "tokens\n",
      "['[CLS]', 'to', 'whom', 'did', 'the', 'virgin', 'mary', 'allegedly', 'appear', 'in', '1858', 'in', 'lou', '##rdes', 'france', '?', '[SEP]', 'architectural', '##ly', ',', 'the', 'school', 'has', 'a', 'catholic', 'character', '.', 'atop', 'the', 'main', 'building', \"'\", 's', 'gold', 'dome', 'is', 'a', 'golden', 'statue', 'of', 'the', 'virgin', 'mary', '.', 'immediately', 'in', 'front', 'of', 'the', 'main', 'building', 'and', 'facing', 'it', ',', 'is', 'a', 'copper', 'statue', 'of', 'christ', 'with', 'arms', 'up', '##rai', '##sed', 'with', 'the', 'legend', '\"', 've', '##ni', '##te', 'ad', 'me', 'om', '##nes', '\"', '.', 'next', 'to', 'the', 'main', 'building', 'is', 'the', 'basilica', 'of', 'the', 'sacred', 'heart', '.', 'immediately', 'behind', 'the', 'basilica', 'is', 'the', 'gr', '##otto', ',', 'a', 'marian', 'place', 'of', 'prayer', 'and', 'reflection', '.', 'it', 'is', 'a', 'replica', 'of', 'the', 'gr', '##otto', 'at', 'lou', '##rdes', ',', 'france', 'where', 'the', 'virgin', 'mary', 'reputed', '##ly', 'appeared', 'to', 'saint', 'bern', '##ade', '##tte', 'so', '##ub', '##iro', '##us', 'in', '1858', '.', 'at', 'the', 'end', 'of', 'the', 'main', 'drive', '(', 'and', 'in', 'a', 'direct', 'line', 'that', 'connects', 'through', '3', 'statues', 'and', 'the', 'gold', 'dome', ')', ',', 'is', 'a', 'simple', ',', 'modern', 'stone', 'statue', 'of', 'mary', '.', '[SEP]']\n",
      "\n",
      "token_to_orig_map\n",
      "{17: 0, 18: 0, 19: 0, 20: 1, 21: 2, 22: 3, 23: 4, 24: 5, 25: 6, 26: 6, 27: 7, 28: 8, 29: 9, 30: 10, 31: 10, 32: 10, 33: 11, 34: 12, 35: 13, 36: 14, 37: 15, 38: 16, 39: 17, 40: 18, 41: 19, 42: 20, 43: 20, 44: 21, 45: 22, 46: 23, 47: 24, 48: 25, 49: 26, 50: 27, 51: 28, 52: 29, 53: 30, 54: 30, 55: 31, 56: 32, 57: 33, 58: 34, 59: 35, 60: 36, 61: 37, 62: 38, 63: 39, 64: 39, 65: 39, 66: 40, 67: 41, 68: 42, 69: 43, 70: 43, 71: 43, 72: 43, 73: 44, 74: 45, 75: 46, 76: 46, 77: 46, 78: 46, 79: 47, 80: 48, 81: 49, 82: 50, 83: 51, 84: 52, 85: 53, 86: 54, 87: 55, 88: 56, 89: 57, 90: 58, 91: 58, 92: 59, 93: 60, 94: 61, 95: 62, 96: 63, 97: 64, 98: 65, 99: 65, 100: 65, 101: 66, 102: 67, 103: 68, 104: 69, 105: 70, 106: 71, 107: 72, 108: 72, 109: 73, 110: 74, 111: 75, 112: 76, 113: 77, 114: 78, 115: 79, 116: 79, 117: 80, 118: 81, 119: 81, 120: 81, 121: 82, 122: 83, 123: 84, 124: 85, 125: 86, 126: 87, 127: 87, 128: 88, 129: 89, 130: 90, 131: 91, 132: 91, 133: 91, 134: 92, 135: 92, 136: 92, 137: 92, 138: 93, 139: 94, 140: 94, 141: 95, 142: 96, 143: 97, 144: 98, 145: 99, 146: 100, 147: 101, 148: 102, 149: 102, 150: 103, 151: 104, 152: 105, 153: 106, 154: 107, 155: 108, 156: 109, 157: 110, 158: 111, 159: 112, 160: 113, 161: 114, 162: 115, 163: 115, 164: 115, 165: 116, 166: 117, 167: 118, 168: 118, 169: 119, 170: 120, 171: 121, 172: 122, 173: 123, 174: 123}\n",
      "\n",
      "token_is_max_context\n",
      "{17: True, 18: True, 19: True, 20: True, 21: True, 22: True, 23: True, 24: True, 25: True, 26: True, 27: True, 28: True, 29: True, 30: True, 31: True, 32: True, 33: True, 34: True, 35: True, 36: True, 37: True, 38: True, 39: True, 40: True, 41: True, 42: True, 43: True, 44: True, 45: True, 46: True, 47: True, 48: True, 49: True, 50: True, 51: True, 52: True, 53: True, 54: True, 55: True, 56: True, 57: True, 58: True, 59: True, 60: True, 61: True, 62: True, 63: True, 64: True, 65: True, 66: True, 67: True, 68: True, 69: True, 70: True, 71: True, 72: True, 73: True, 74: True, 75: True, 76: True, 77: True, 78: True, 79: True, 80: True, 81: True, 82: True, 83: True, 84: True, 85: True, 86: True, 87: True, 88: True, 89: True, 90: True, 91: True, 92: True, 93: True, 94: True, 95: True, 96: True, 97: True, 98: True, 99: True, 100: True, 101: True, 102: True, 103: True, 104: True, 105: True, 106: True, 107: True, 108: True, 109: True, 110: True, 111: True, 112: True, 113: True, 114: True, 115: True, 116: True, 117: True, 118: True, 119: True, 120: True, 121: True, 122: True, 123: True, 124: True, 125: True, 126: True, 127: True, 128: True, 129: True, 130: True, 131: True, 132: True, 133: True, 134: True, 135: True, 136: True, 137: True, 138: True, 139: True, 140: True, 141: True, 142: True, 143: True, 144: True, 145: True, 146: True, 147: True, 148: True, 149: True, 150: True, 151: True, 152: True, 153: True, 154: True, 155: True, 156: True, 157: True, 158: True, 159: True, 160: True, 161: True, 162: True, 163: True, 164: True, 165: True, 166: True, 167: True, 168: True, 169: True, 170: True, 171: True, 172: True, 173: True, 174: True}\n",
      "\n",
      "input_ids\n",
      "[101, 2000, 3183, 2106, 1996, 6261, 2984, 9382, 3711, 1999, 8517, 1999, 10223, 26371, 2605, 1029, 102, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, 23052, 2012, 10223, 26371, 1010, 2605, 2073, 1996, 6261, 2984, 22353, 2135, 2596, 2000, 3002, 16595, 9648, 4674, 2061, 12083, 9711, 2271, 1999, 8517, 1012, 2012, 1996, 2203, 1997, 1996, 2364, 3298, 1006, 1998, 1999, 1037, 3622, 2240, 2008, 8539, 2083, 1017, 11342, 1998, 1996, 2751, 8514, 1007, 1010, 2003, 1037, 3722, 1010, 2715, 2962, 6231, 1997, 2984, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "input_mask\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "segment_ids\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "start_position\n",
      "130\n",
      "\n",
      "end_position\n",
      "137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_feature = train_features[0]\n",
    "for f in type(sample_feature)._fields:\n",
    "    print(f)\n",
    "    print(getattr(sample_feature, f))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERTQAExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_extractor = BERTQAExtractor(language=LANGUAGE, cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/11081 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/11081 [00:02<8:40:15,  2.82s/it]\u001b[A\n",
      "Iteration:   0%|          | 2/11081 [00:05<8:43:26,  2.83s/it]\u001b[A\n",
      "Iteration:   0%|          | 3/11081 [00:08<8:26:28,  2.74s/it]\u001b[A\n",
      "Iteration:   0%|          | 4/11081 [00:10<8:15:06,  2.68s/it]\u001b[A\n",
      "Iteration:   0%|          | 5/11081 [00:13<8:12:04,  2.67s/it]\u001b[A\n",
      "Iteration:   0%|          | 6/11081 [00:16<8:09:11,  2.65s/it]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-cc147effa346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                      model_output_dir=CACHE_DIR)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time : {:.3f} hrs\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-dbf3f1bd8433>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, num_gpus, num_epochs, batch_size, lr, warmup_proportion, max_grad_norm, model_output_dir)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(self, p, dim, keepdim)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34mr\"\"\"See :func: `torch.norm`\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbtrifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"nuc\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fro\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    qa_extractor.fit(train_features,\n",
    "                     num_epochs=NUM_EPOCHS,\n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     lr=LEARNING_RATE,\n",
    "                     cache_model=True)\n",
    "print(\"Training time : {:.3f} hrs\".format(t.interval / 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Note that the `BERTQAExtractor.predict` only outputs the probabilities of each token being the start and end of the answer span. the `postprocess_answers` method takes these probabilities and generates the final answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 339/339 [12:09<00:00,  1.96s/it]\n"
     ]
    }
   ],
   "source": [
    "qa_results = qa_extractor.predict(dev_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocess and Generate the Final Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answers, answer_probs, nbest_answers = postprocess_answers(qa_results,\n",
    "                                                                 dev_examples, \n",
    "                                                                 dev_features, \n",
    "                                                                 do_lower_case=DO_LOWER_CASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph:\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "\n",
      "Question:\n",
      "Which NFL team represented the AFC at Super Bowl 50?\n",
      "\n",
      "Ground truth answers:\n",
      "['Denver Broncos', 'Denver Broncos', 'Denver Broncos']\n",
      "\n",
      "Predicted answer:\n",
      "Denver Broncos\n",
      "\n",
      "Top N best answers\n",
      "[OrderedDict([('text', 'Denver Broncos'), ('probability', 0.9922386565723612), ('start_logit', 6.457600116729736), ('end_logit', 7.544598579406738)]), OrderedDict([('text', 'The American Football Conference (AFC) champion Denver Broncos'), ('probability', 0.0024902275495739343), ('start_logit', 0.47001054883003235), ('end_logit', 7.544598579406738)]), OrderedDict([('text', 'Denver'), ('probability', 0.002078899167012311), ('start_logit', 6.457600116729736), ('end_logit', 1.3764734268188477)]), OrderedDict([('text', 'Broncos'), ('probability', 0.0014206958156199507), ('start_logit', -0.09121678024530411), ('end_logit', 7.544598579406738)]), OrderedDict([('text', 'AFC) champion Denver Broncos'), ('probability', 0.0009138801521539591), ('start_logit', -0.5324193835258484), ('end_logit', 7.544598579406738)]), OrderedDict([('text', 'American Football Conference (AFC) champion Denver Broncos'), ('probability', 0.0003375065394515181), ('start_logit', -1.528533935546875), ('end_logit', 7.544598579406738)]), OrderedDict([('text', 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'), ('probability', 0.0002868909583168286), ('start_logit', 6.457600116729736), ('end_logit', -0.6040181517601013)]), OrderedDict([('text', 'champion Denver Broncos'), ('probability', 5.445156214085013e-05), ('start_logit', -3.3528072834014893), ('end_logit', 7.544598579406738)]), OrderedDict([('text', '(AFC) champion Denver Broncos'), ('probability', 4.2917797000105455e-05), ('start_logit', -3.590832233428955), ('end_logit', 7.544598579406738)]), OrderedDict([('text', 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10'), ('probability', 2.940544190105009e-05), ('start_logit', 6.457600116729736), ('end_logit', -2.8819406032562256)]), OrderedDict([('text', '. The American Football Conference (AFC) champion Denver Broncos'), ('probability', 2.8697268184186325e-05), ('start_logit', -3.993316888809204), ('end_logit', 7.544598579406738)]), OrderedDict([('text', 'Football Conference (AFC) champion Denver Broncos'), ('probability', 1.711850561012247e-05), ('start_logit', -4.509958744049072), ('end_logit', 7.544598579406738)]), OrderedDict([('text', 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina'), ('probability', 1.4181261167331012e-05), ('start_logit', 6.457600116729736), ('end_logit', -3.611198902130127)]), OrderedDict([('text', 'NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos'), ('probability', 1.2744835695260053e-05), ('start_logit', -4.80499267578125), ('end_logit', 7.544598579406738)]), OrderedDict([('text', 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title'), ('probability', 1.1077291027276738e-05), ('start_logit', 6.457600116729736), ('end_logit', -3.8582231998443604)]), OrderedDict([('text', 'National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos'), ('probability', 9.7220324549356e-06), ('start_logit', -5.075724124908447), ('end_logit', 7.544598579406738)]), OrderedDict([('text', 'The American Football Conference (AFC) champion Denver'), ('probability', 5.2174262151444625e-06), ('start_logit', 0.47001054883003235), ('end_logit', 1.3764734268188477)]), OrderedDict([('text', 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl'), ('probability', 5.075086555090117e-06), ('start_logit', 6.457600116729736), ('end_logit', -4.638776779174805)]), OrderedDict([('text', 'AFC) champion Denver'), ('probability', 1.914725529465801e-06), ('start_logit', -0.5324193835258484), ('end_logit', 1.3764734268188477)]), OrderedDict([('text', 'The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'), ('probability', 7.200120287514044e-07), ('start_logit', 0.47001054883003235), ('end_logit', -0.6040181517601013)])]\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Paragraph:\n",
      "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "\n",
      "Question:\n",
      "What day was the Super Bowl played on?\n",
      "\n",
      "Ground truth answers:\n",
      "['February 7, 2016', 'February 7', 'February 7, 2016']\n",
      "\n",
      "Predicted answer:\n",
      "February 7, 2016\n",
      "\n",
      "Top N best answers\n",
      "[OrderedDict([('text', 'February 7, 2016'), ('probability', 0.9655787482249194), ('start_logit', 6.548739433288574), ('end_logit', 7.086097240447998)]), OrderedDict([('text', 'February 7'), ('probability', 0.01862466290894872), ('start_logit', 6.548739433288574), ('end_logit', 3.1378562450408936)]), OrderedDict([('text', 'February 7, 2016,'), ('probability', 0.012456731641300216), ('start_logit', 6.548739433288574), ('end_logit', 2.735630750656128)]), OrderedDict([('text', 'The game was played on February 7, 2016'), ('probability', 0.0014503883502971489), ('start_logit', 0.047843120992183685), ('end_logit', 7.086097240447998)]), OrderedDict([('text', 'February'), ('probability', 0.0005215214923012275), ('start_logit', 6.548739433288574), ('end_logit', -0.437635213136673)]), OrderedDict([('text', 'February 7,'), ('probability', 0.0004851495985087041), ('start_logit', 6.548739433288574), ('end_logit', -0.5099284052848816)]), OrderedDict([('text', '2016'), ('probability', 0.00031466798356096913), ('start_logit', -1.4802254438400269), ('end_logit', 7.086097240447998)]), OrderedDict([('text', '7, 2016'), ('probability', 0.00028965978077914544), ('start_logit', -1.5630364418029785), ('end_logit', 7.086097240447998)]), OrderedDict([('text', \"February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl\"), ('probability', 4.522074913009336e-05), ('start_logit', 6.548739433288574), ('end_logit', -2.8828296661376953)]), OrderedDict([('text', 'played on February 7, 2016'), ('probability', 3.774586738706949e-05), ('start_logit', -3.600867509841919), ('end_logit', 7.086097240447998)]), OrderedDict([('text', \"February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"), ('probability', 3.5630943620980354e-05), ('start_logit', 6.548739433288574), ('end_logit', -3.121171236038208)]), OrderedDict([('text', 'The game was played on February 7'), ('probability', 2.7975961733841195e-05), ('start_logit', 0.047843120992183685), ('end_logit', 3.1378562450408936)]), OrderedDict([('text', '. The game was played on February 7, 2016'), ('probability', 2.7766534218164095e-05), ('start_logit', -3.907912015914917), ('end_logit', 7.086097240447998)]), OrderedDict([('text', 'on February 7, 2016'), ('probability', 2.5246606446775242e-05), ('start_logit', -4.0030517578125), ('end_logit', 7.086097240447998)]), OrderedDict([('text', 'The game was played on February 7, 2016,'), ('probability', 1.8711160004850492e-05), ('start_logit', 0.047843120992183685), ('end_logit', 2.735630750656128)]), OrderedDict([('text', 'game was played on February 7, 2016'), ('probability', 1.598705338086199e-05), ('start_logit', -4.459964275360107), ('end_logit', 7.086097240447998)]), OrderedDict([('text', \"February 7, 2016, at Levi's Stadium\"), ('probability', 1.2473322527585323e-05), ('start_logit', 6.548739433288574), ('end_logit', -4.170793533325195)]), OrderedDict([('text', \"February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th\"), ('probability', 1.13027886176087e-05), ('start_logit', 6.548739433288574), ('end_logit', -4.269336223602295)]), OrderedDict([('text', \"February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl,\"), ('probability', 1.0945571769144622e-05), ('start_logit', 6.548739433288574), ('end_logit', -4.301450729370117)]), OrderedDict([('text', \"February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California\"), ('probability', 9.463460547530285e-06), ('start_logit', 6.548739433288574), ('end_logit', -4.4469475746154785)])]\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Paragraph:\n",
      "CBS broadcast Super Bowl 50 in the U.S., and charged an average of $5 million for a 30-second commercial during the game. The Super Bowl 50 halftime show was headlined by the British rock group Coldplay with special guest performers Beyoncé and Bruno Mars, who headlined the Super Bowl XLVII and Super Bowl XLVIII halftime shows, respectively. It was the third-most watched U.S. broadcast ever.\n",
      "\n",
      "Question:\n",
      "Who were special guests for the Super Bowl halftime show?\n",
      "\n",
      "Ground truth answers:\n",
      "['Beyoncé and Bruno Mars', 'Beyoncé and Bruno Mars', 'Beyoncé and Bruno Mars']\n",
      "\n",
      "Predicted answer:\n",
      "Beyoncé and Bruno Mars\n",
      "\n",
      "Top N best answers\n",
      "[OrderedDict([('text', 'Beyoncé and Bruno Mars'), ('probability', 0.9928656868744075), ('start_logit', 5.466784954071045), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'Beyoncé and Bruno Mars,'), ('probability', 0.004024734730817854), ('start_logit', 5.466784954071045), ('end_logit', 1.6932624578475952)]), OrderedDict([('text', 'Coldplay with special guest performers Beyoncé and Bruno Mars'), ('probability', 0.001533261216652038), ('start_logit', -1.006413459777832), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'special guest performers Beyoncé and Bruno Mars'), ('probability', 0.0003596912948688246), ('start_logit', -2.456319570541382), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'British rock group Coldplay with special guest performers Beyoncé and Bruno Mars'), ('probability', 0.0002350787949595041), ('start_logit', -2.8816449642181396), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'rock group Coldplay with special guest performers Beyoncé and Bruno Mars'), ('probability', 0.00011685183996018169), ('start_logit', -3.5806589126586914), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'Mars'), ('probability', 0.00011117578642411756), ('start_logit', -3.630453109741211), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'the British rock group Coldplay with special guest performers Beyoncé and Bruno Mars'), ('probability', 0.00011086461379141587), ('start_logit', -3.633255958557129), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'Beyoncé and Bruno Mars, who headlined the Super Bowl XLVII'), ('probability', 0.00010285367318230111), ('start_logit', 5.466784954071045), ('end_logit', -1.973644495010376)]), OrderedDict([('text', 'group Coldplay with special guest performers Beyoncé and Bruno Mars'), ('probability', 9.802565883876958e-05), ('start_logit', -3.7563364505767822), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'and Bruno Mars'), ('probability', 9.254187048682431e-05), ('start_logit', -3.8139045238494873), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'Beyoncé'), ('probability', 9.007158476003941e-05), ('start_logit', 5.466784954071045), ('end_logit', -2.10634708404541)]), OrderedDict([('text', 'performers Beyoncé and Bruno Mars'), ('probability', 6.164692532917996e-05), ('start_logit', -4.220142364501953), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'guest performers Beyoncé and Bruno Mars'), ('probability', 5.755492625632492e-05), ('start_logit', -4.288825988769531), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'Beyoncé and Bruno'), ('probability', 3.894306331427947e-05), ('start_logit', 5.466784954071045), ('end_logit', -2.9448511600494385)]), OrderedDict([('text', 'Bruno Mars'), ('probability', 3.7886579085276824e-05), ('start_logit', -4.706968784332275), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'by the British rock group Coldplay with special guest performers Beyoncé and Bruno Mars'), ('probability', 2.131352863729503e-05), ('start_logit', -5.282223701477051), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'play with special guest performers Beyoncé and Bruno Mars'), ('probability', 1.4244151935501176e-05), ('start_logit', -5.6852192878723145), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'with special guest performers Beyoncé and Bruno Mars'), ('probability', 1.3985006860479863e-05), ('start_logit', -5.703579902648926), ('end_logit', 7.201398849487305)]), OrderedDict([('text', 'Beyoncé and Bruno Mars, who headlined the Super Bowl XLVII and Super Bowl XLVIII'), ('probability', 1.3587879432032175e-05), ('start_logit', 5.466784954071045), ('end_logit', -3.9977736473083496)])]\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 10, 100]:\n",
    "    print('Paragraph:')\n",
    "    print(dev_df.iloc[i]['doc_text'])\n",
    "    print()\n",
    "    print('Question:')\n",
    "    print(dev_df.iloc[i]['question_text'])\n",
    "    print()\n",
    "    print('Ground truth answers:')\n",
    "    print(dev_df.iloc[i]['answer_text'])\n",
    "    print()\n",
    "    print('Predicted answer:')\n",
    "    print(final_answers[dev_df.iloc[i]['qa_id']])\n",
    "    print()\n",
    "    print('Top N best answers')\n",
    "    print(nbest_answers[dev_df.iloc[i]['qa_id']])\n",
    "    print('-------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question answering task is usually evaluated on two metrics: exact match (EM) and F1 score.   \n",
    "The exact match is computed by first performing some simple normalization (e.g. remove punctuation and convert to lower case) on the ground truth and predicted answers and check if they match exactly after normalization.   \n",
    "F1 score is computed from token-level precision and recall by comparing the ground truth and predicted answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 86.07379375591296,\n",
      "  \"f1\": 92.45589503088394,\n",
      "  \"total\": 10570,\n",
      "  \"HasAns_exact\": 86.07379375591296,\n",
      "  \"HasAns_f1\": 92.45589503088394,\n",
      "  \"HasAns_total\": 10570\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('exact', 86.07379375591296),\n",
       "             ('f1', 92.45589503088394),\n",
       "             ('total', 10570),\n",
       "             ('HasAns_exact', 86.07379375591296),\n",
       "             ('HasAns_f1', 92.45589503088394),\n",
       "             ('HasAns_total', 10570)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_result = evaluate_qa(qa_ids=dev_df['qa_id'], \n",
    "                                actuals=dev_df['answer_text'], \n",
    "                                preds=final_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:27:07.310707\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_extractor_cached = BERTQAExtractor(language=LANGUAGE, cache_dir='/home/hlu/notebooks/NLP/scenarios/question_answering/temp/', load_from_cache=True)\n",
    "# dev_features_cached = torch.load('/home/hlu/notebooks/NLP/scenarios/question_answering/temp/cached_features')\n",
    "# dev_examples_cached = torch.load('/home/hlu/notebooks/NLP/scenarios/question_answering/temp/cached_examples')\n",
    "# qa_results_new = qa_extractor_cached.predict(dev_features_cached)\n",
    "# final_answers_new, _, _ = postprocess_answers(qa_results_new,\n",
    "#                                               dev_examples_cached, \n",
    "#                                               dev_features_cached, \n",
    "#                                               do_lower_case=DO_LOWER_CASE)\n",
    "# evaluate_qa(qa_ids=dev_df['qa_id'], \n",
    "#             actuals=dev_df['answer_text'], \n",
    "#             preds=final_answers_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_features_short = []\n",
    "# qa_id_short = []\n",
    "# for example in dev_examples_cached[:10]:\n",
    "#     qa_id = example.qa_id\n",
    "#     qa_id_short.append(qa_id)\n",
    "#     for f in dev_features_cached:\n",
    "#         if f.qa_id == qa_id:\n",
    "#             dev_features_short.append(f)\n",
    "# answer_text_short = dev_df.loc[dev_df[\"qa_id\"].isin(qa_id_short), 'answer_text']\n",
    "# qa_results_new_short = qa_extractor_cached.predict(dev_features_short)\n",
    "# final_answers_new_short, _, _ = postprocess_answers(qa_results_new_short,\n",
    "#                                               dev_examples_cached[:10], \n",
    "#                                               dev_features_short, \n",
    "#                                               do_lower_case=DO_LOWER_CASE)\n",
    "# evaluate_qa(qa_ids=qa_id_short, \n",
    "#             actuals=answer_text_short, \n",
    "#             preds=final_answers_new_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_answers_new, final_probs, nbest_answers = postprocess_answers(qa_results_new,\n",
    "#                                                 dev_examples_cached, \n",
    "#                                                 dev_features_cached, \n",
    "#                                                 do_lower_case=DO_LOWER_CASE)\n",
    "# for dev_e in dev_examples_cached:\n",
    "#     qa_id = dev_e.qa_id\n",
    "#     count = 0\n",
    "#     dev_f_list = []\n",
    "#     for dev_f in dev_features_cached:\n",
    "#         if dev_f.qa_id == qa_id:\n",
    "#             count += 1\n",
    "#             dev_f_list.append(dev_f)\n",
    "#     if count == 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina, [*BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding*](https://arxiv.org/abs/1810.04805), ACL, 2018.\n",
    "2. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, [*SQuAD: 100,000+ Questions for Machine Comprehension of Text*](https://arxiv.org/abs/1606.05250), EMNLP, 2016.\n",
    "3. Pranav Rajpurkar, Robin Jia, Percy Liang, [*Know What You Don't Know: Unanswerable Questions for SQuAD*](https://arxiv.org/abs/1806.03822), ACL, 2018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_gpu",
   "language": "python",
   "name": "nlp_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
