{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from allennlp.predictors import Predictor#, BidafPredictor\n",
    "# from allennlp.models.archival import load_archive\n",
    "# from allennlp.data import DatasetReader, Instance\n",
    "# from allennlp.common import Params\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from utils_nlp.azureml import azureml_utils\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_jsonnet not loaded, treating C:\\Users\\cocochra\\AppData\\Local\\Temp\\tmpywtpft2j\\config.json as json\n",
      "C:\\Users\\cocochra\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "C:\\Users\\cocochra\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_gpu\\lib\\site-packages\\allennlp\\data\\token_indexers\\token_characters_indexer.py:55: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "archive_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/bidaf-model-2017.09.15-charpad.tar.gz'\n",
    "model = Predictor.from_path(archive_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict on One Sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage = \"The history of the penny of Great Britain and the United Kingdom from 1714 to 1901, \\\n",
    "the period in which the House of Hanover reigned, saw its transformation from a small \\\n",
    "silver coin to a larger bronze piece. All bear the portrait of the monarch on the obverse; \\\n",
    "copper and bronze pennies have a depiction of Britannia on the reverse. During most of the 18th century, \\\n",
    "the penny was a small silver coin rarely seen in circulation. Beginning in 1787, \\\n",
    "the chronic shortage of good money resulted in the wide circulation of private tokens, \\\n",
    "including ones valued at one penny. In 1797 Matthew Boulton gained a government contract \\\n",
    "and struck millions of pennies. The copper penny continued to be issued until 1860, \\\n",
    "when they were replaced by lighter bronze coins; the Bun penny, \\\n",
    "named for the hairstyle of Queen Victoria on it, was issued from then until 1894. \\\n",
    "The final years of her reign saw the Old head pennies, coined from 1895 until her death in 1901\\\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How was the penny called due to Queen Victoria hairstyle?\"\n",
    "question2 = \"When did Matthew boulton gain the government contract?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = model.predict(question, passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bun penny'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans['best_span_str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\n",
      "You have logged in. Now let us find all the subscriptions to which you have access...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n"
     ]
    }
   ],
   "source": [
    "ws = azureml_utils.get_or_create_workspace(\n",
    "    subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "    resource_group=\"<RESOURCE_GROUP>\",\n",
    "    workspace_name=\"<WORKSPACE_NAME>\",\n",
    "    workspace_region=\"<WORKSPACE_REGION>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: MAIDAPTest\n",
      "Azure region: eastus2\n",
      "Subscription id: 15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\n",
      "Resource group: nlprg\n"
     ]
    }
   ],
   "source": [
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x config.json\n",
      "x vocabulary/\n",
      "x vocabulary/non_padded_namespaces.txt\n",
      "x vocabulary/tokens.txt\n",
      "x weights.th\n"
     ]
    }
   ],
   "source": [
    "bidaf_model_url = 'https://s3-us-west-2.amazonaws.com/allennlp/models/bidaf-model-2017.09.15-charpad.tar.gz'\n",
    "urllib.request.urlretrieve(bidaf_model_url, filename=\"bidaf.tar.gz\")\n",
    "!tar xvzf bidaf.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model bidaf\n"
     ]
    }
   ],
   "source": [
    "bidaf_model = Model.register(workspace = ws,\n",
    "                       model_path =\"bidaf.tar.gz\",\n",
    "                       model_name = \"bidaf\",\n",
    "                       tags = {\"bidaf\": \"demo\"},\n",
    "                       description = \"BiDAF Pretrained Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "from allennlp.predictors import Predictor\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    bidaf_dir_path = Model.get_model_path('bidaf')\n",
    "    model = Predictor.from_path(bidaf_dir_path)\n",
    "\n",
    "def run(rawdata):\n",
    "    try:\n",
    "        data = json.loads(rawdata)\n",
    "        passage = data['passage']\n",
    "        question = data['question']\n",
    "        result = model.predict(question, passage)[\"best_span_str\"]\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n",
    "    return json.dumps({\"result\":result.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automlenv.yml'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myenv = CondaDependencies.create(conda_packages=['pytorch==0.4.1','torchvision==0.2.1'],\n",
    "                                 pip_packages=['allennlp==0.7.2','azureml-sdk[automl]==1.0.43.*'], \n",
    "                                 python_version = '3.7')\n",
    "myenv.add_channel('conda-forge')\n",
    "myenv.add_channel('pytorch')\n",
    "\n",
    "conda_env_file_name = 'automlenv.yml'\n",
    "myenv.save_to_file('.', conda_env_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running.........................................................................\n",
      "FailedImage creation operation finished for image bidaf-image:11, operation \"Failed\"\n",
      "Image creation failed with\n",
      "StatusCode: 400\n",
      "Message: Docker image build failed.\n"
     ]
    }
   ],
   "source": [
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = conda_env_file_name,\n",
    "                                                  description = \"Image with BiDAF model\",\n",
    "                                                  tags = {'area': \"nlp\", 'type': \"question-answering BiDAF\"})\n",
    "\n",
    "image = ContainerImage.create(name = \"bidaf-image\",\n",
    "                              models = [bidaf_model],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://maidaptest3334372853.blob.core.windows.net/azureml/ImageLogs/a2d41a70-c4d5-4cef-87ec-b7ada8888aa8/build.log?sv=2018-03-28&sr=b&sig=6HvEyf10RZjvUUdgJvSDZXmzNPkx0nKngRXKronyQOk%3D&st=2019-06-28T01%3A52%3A07Z&se=2019-07-28T01%3A57%3A07Z&sp=rl\n"
     ]
    }
   ],
   "source": [
    "print(image.image_build_log_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the web service configuration\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores = CPU_CORES, \n",
    "                                               memory_gb = MEMORY_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy image as web service\n",
    "aci_service = Webservice.deploy_from_image(workspace = ws, \n",
    "                                           name = 'aci-automl-service-1',\n",
    "                                           image = image,\n",
    "                                           deployment_config = aci_config)\n",
    "\n",
    "aci_service.wait_for_deployment(show_output = True)\n",
    "print(aci_service.state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
