{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Microsoft Corporation. All rights reserved.*\n",
    "\n",
    "*Licensed under the MIT License.*\n",
    "\n",
    "# Classification of Arabic News Articles using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils_nlp.dataset.dac import load_pandas_df\n",
    "from utils_nlp.eval.classification import eval_classification\n",
    "from utils_nlp.bert.sequence_classification import BERTSequenceClassifier\n",
    "from utils_nlp.bert.common import Language, Tokenizer\n",
    "from utils_nlp.common.timer import Timer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we fine-tune and evaluate a pretrained [BERT](https://arxiv.org/abs/1810.04805) model on an Arabic dataset of news articles. The [dataset](https://data.mendeley.com/datasets/v524p5dhpj/2) includes articles from 3 different newspapers, and the articles are categorized into 5 classes: *sports, politics, culture, economy and diverse*. The data is described in more detail in this [paper](http://article.nadiapub.com/IJGDC/vol11_no9/9.pdf).\n",
    "\n",
    "We use a [sequence classifier](../../utils_nlp/bert/sequence_classification.py) that wraps [Hugging Face's PyTorch implementation](https://github.com/huggingface/pytorch-pretrained-BERT) of Google's [BERT](https://github.com/google-research/bert). The classifier loads a pretrained [multilingual BERT model](https://github.com/google-research/bert/blob/master/multilingual.md) that was trained on 104 languages, including Arabic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../../../temp\"\n",
    "BERT_CACHE_DIR = \"../../../temp\"\n",
    "LANGUAGE = Language.MULTILINGUAL\n",
    "MAX_LEN = 200\n",
    "BATCH_SIZE = 32\n",
    "NUM_GPUS = 2\n",
    "NUM_EPOCHS = 1\n",
    "TRAIN_SIZE = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset\n",
    "We start by loading the data. The following lines also download the file if it doesn't exist, and extract the csv file into the specified data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_pandas_df(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>targe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بين أستوديوهات ورزازات وصحراء مرزوكة وآثار ولي...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>قررت النجمة الأمريكية أوبرا وينفري ألا يقتصر ع...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>أخبارنا المغربية الوزاني تصوير الشملالي ألهب ا...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اخبارنا المغربية قال ابراهيم الراشدي محامي سعد...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>تزال صناعة الجلود في المغرب تتبع الطريقة التقل...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  targe\n",
       "0  بين أستوديوهات ورزازات وصحراء مرزوكة وآثار ولي...      0\n",
       "1  قررت النجمة الأمريكية أوبرا وينفري ألا يقتصر ع...      0\n",
       "2  أخبارنا المغربية الوزاني تصوير الشملالي ألهب ا...      0\n",
       "3  اخبارنا المغربية قال ابراهيم الراشدي محامي سعد...      0\n",
       "4  تزال صناعة الجلود في المغرب تتبع الطريقة التقل...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the text and label columns\n",
    "text_col = df.columns[0]\n",
    "label_col = df.columns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the distribution of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    46522\n",
       "3    20505\n",
       "1    16728\n",
       "2    14235\n",
       "0    13738\n",
       "Name: targe, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[label_col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare the counts with those presented in the author's [paper](http://article.nadiapub.com/IJGDC/vol11_no9/9.pdf), and infer the following label mapping:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0   culture\n",
       "1   diverse\n",
       "2   economy\n",
       "3  politics\n",
       "4    sports"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordered list of labels\n",
    "labels = [\"culture\", \"diverse\", \"economy\", \"politics\", \"sports\"]\n",
    "num_labels = len(labels)\n",
    "pd.DataFrame({\"label\": labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the data for training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 83796\n",
      "Number of testing examples: 27932\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, train_size = TRAIN_SIZE, random_state=0)\n",
    "print(\"Number of training examples: {}\".format(df_train.shape[0]))\n",
    "print(\"Number of testing examples: {}\".format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we tokenize the text documents and convert them to lists of tokens. The following steps instantiate a BERT tokenizer given the language, and tokenize the text of the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(LANGUAGE, cache_dir=BERT_CACHE_DIR)\n",
    "tokens_train = tokenizer.tokenize(df_train[text_col].astype(str))\n",
    "tokens_test = tokenizer.tokenize(df_test[text_col].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we perform the following preprocessing steps in the cell below:\n",
    "- Convert the tokens into token indices corresponding to the BERT tokenizer's vocabulary\n",
    "- Add the special tokens [CLS] and [SEP] to mark the beginning and end of a sentence\n",
    "- Pad or truncate the token lists to the specified max length\n",
    "- Return mask lists that indicate paddings' positions\n",
    "- Return token type id lists that indicate which sentence the tokens belong to (not needed for one-sequence classification)\n",
    "\n",
    "*See the original [implementation](https://github.com/google-research/bert/blob/master/run_classifier.py) for more information on BERT's input format.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train, mask_train, _ = tokenizer.preprocess_classification_tokens(\n",
    "    tokens_train, MAX_LEN\n",
    ")\n",
    "tokens_test, mask_test, _ = tokenizer.preprocess_classification_tokens(\n",
    "    tokens_test, MAX_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "Next, we create a sequence classifier that loads a pre-trained BERT model, given the language and number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BERTSequenceClassifier(\n",
    "    language=LANGUAGE, num_labels=num_labels, cache_dir=BERT_CACHE_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "We train the classifier using the training examples. This involves fine-tuning the BERT Transformer and learning a linear classification layer on top of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/1; batch:1->262/2618; loss:1.632097\n",
      "epoch:1/1; batch:263->524/2618; loss:0.402912\n",
      "epoch:1/1; batch:525->786/2618; loss:0.324510\n",
      "epoch:1/1; batch:787->1048/2618; loss:0.477946\n",
      "epoch:1/1; batch:1049->1310/2618; loss:0.333729\n",
      "epoch:1/1; batch:1311->1572/2618; loss:0.021917\n",
      "epoch:1/1; batch:1573->1834/2618; loss:0.031262\n",
      "epoch:1/1; batch:1835->2096/2618; loss:0.264172\n",
      "epoch:1/1; batch:2097->2358/2618; loss:0.034074\n",
      "epoch:1/1; batch:2359->2618/2618; loss:0.033827\n",
      "[Training time: 1.400 hrs]\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    classifier.fit(\n",
    "        token_ids=tokens_train,\n",
    "        input_mask=mask_train,\n",
    "        labels=list(df_train[label_col]),    \n",
    "        num_gpus=NUM_GPUS,        \n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,    \n",
    "        verbose=True,\n",
    "    )    \n",
    "print(\"[Training time: {:.3f} hrs]\".format(t.interval / 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score\n",
    "We score the test set using the trained classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27936it [08:35, 56.23it/s]                           \n"
     ]
    }
   ],
   "source": [
    "preds = classifier.predict(\n",
    "    token_ids=tokens_test, input_mask=mask_test, num_gpus=NUM_GPUS, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results\n",
    "Finally, we compute the accuracy, precision, recall, and F1 metrics of the evaluation on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     culture       0.96      0.93      0.94      3479\n",
      "     diverse       0.92      0.98      0.95      4091\n",
      "     economy       0.91      0.88      0.89      3517\n",
      "    politics       0.90      0.90      0.90      5222\n",
      "      sports       0.99      0.99      0.99     11623\n",
      "\n",
      "    accuracy                           0.95     27932\n",
      "   macro avg       0.94      0.94      0.94     27932\n",
      "weighted avg       0.95      0.95      0.95     27932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test[label_col], preds, target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
