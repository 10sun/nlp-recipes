{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Microsoft Corporation. All rights reserved.*\n",
    "\n",
    "\n",
    "*Licensed under the MIT License.*\n",
    "\n",
    "# Text Classification of Yahoo Answers using BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import utils_nlp.dataset.yahoo_answers as ya_dataset\n",
    "from utils_nlp.eval.classification import eval_classification\n",
    "from utils_nlp.bert.sequence_classification import SequenceClassifier\n",
    "from utils_nlp.bert.common import Language, Tokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../../../.../temp\"\n",
    "TRAIN_FILE = \"yahoo_answers_csv/train.csv\"\n",
    "TEST_FILE = \"yahoo_answers_csv/test.csv\"\n",
    "BERT_CACHE_DIR = \"../../../temp\"\n",
    "MAX_LEN = 100\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = \"gpu\"\n",
    "UPDATE_EMBEDDINGS = False\n",
    "NUM_EPOCHS = 1\n",
    "NUM_ROWS_TRAIN = 15000  # number of training examples to read\n",
    "NUM_ROWS_TEST = 10000  # number of test examples to read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya_dataset.download(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train = ya_dataset.read_data(os.path.join(DATA_FOLDER, TRAIN_FILE), nrows=NUM_ROWS_TRAIN)\n",
    "df_test = ya_dataset.read_data(os.path.join(DATA_FOLDER, TEST_FILE), nrows=NUM_ROWS_TEST)\n",
    "\n",
    "# get labels\n",
    "labels_train = ya_dataset.get_labels(df_train)\n",
    "labels_test = ya_dataset.get_labels(df_test)\n",
    "\n",
    "num_labels = len(np.unique(labels_train))\n",
    "\n",
    "# get text\n",
    "text_train = ya_dataset.get_text(df_train)\n",
    "text_test = ya_dataset.get_text(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(Language.ENGLISH, to_lower=False, cache_dir=BERT_CACHE_DIR)\n",
    "\n",
    "# tokenize\n",
    "tokens_train = tokenizer.tokenize(text_train)\n",
    "tokens_test = tokenizer.tokenize(text_test)\n",
    "\n",
    "# get BERT-format tokens (padded and truncated)\n",
    "tokens_train, mask_train = tokenizer.preprocess_classification_tokens(tokens_train, MAX_LEN)\n",
    "tokens_test, mask_test = tokenizer.preprocess_classification_tokens(tokens_test, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SequenceClassifier(\n",
    "    language=Language.ENGLISH, num_labels=num_labels, cache_dir=BERT_CACHE_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "classifier.fit(\n",
    "    tokens=tokens_train,\n",
    "    input_mask=mask_train,\n",
    "    labels=labels_train,    \n",
    "    device=DEVICE,\n",
    "    use_multiple_gpus=True,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.predict(tokens=tokens_test, input_mask=mask_test, device=DEVICE, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "eval_results = eval_classification(labels_test, preds)\n",
    "print(\"\\n accuracy: {}\".format(eval_results[\"accuracy\"]))\n",
    "pd.DataFrame(eval_results)[[\"precision\", \"recall\", \"f1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
