{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pipelines and AutoML for Predicting Sentence Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use AzureML pipelines and AutoML to streamline the creation of a machine learning workflow for predicting sentence similarity. The pipeline contains two steps:   \n",
    "1. PythonScriptStep: uses a popular sentence embedding model from Google, Universal Sentence Encoder, to convert our sentence data into numerical data\n",
    "2. AutoMLStep: demonstrates how to use AutoML to automate model selection for predicting sentence similarity scores (regression)\n",
    "\n",
    "An AmlCompute target is used to run the pipeline, Azure Datastores are used for storing of our data, and logging is utilized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are AzureML Pipelines?\n",
    "\n",
    "AzureML Pipelines \"define reusable machine learning workflows that can be used as a template for your machine learning scenarios\" (https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-ml-pipelines). Pipelines allow you to optimize your workflow and spend time on machine learning rather than infrastructure. A Pipeline is defined by a series of steps; the following steps are available: AdlaStep, AutoMLStep, AzureBatchStep, DataTransferStep, DatabricksStep, EstimatorStep, HyperDriveStep, ModuleStep, MpiStep, and PythonScriptStep (see [here](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/?view=azure-ml-py) for details of each step). When the pipeline is run, cached results are used for all steps that have not changed, optimizing the run time. Data sources and intermediate data can be used across multiple steps in a pipeline, saving time and resources. Below we see an example of an AzureML pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pipelines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Azure AutoML?\n",
    "\n",
    "Automated machine learning (AutoML) is a capability of Microsoft's Azure Machine Learning service. The goal of AutoML is to \"improve the productivity of data scientists and democratize AI\" [1] by allowing for the rapid development and deployment of machine learning models. To acheive this goal, AutoML automates the process of selecting a ML model and tuning the model. All the user is required to provide is a dataset (suitable for a classification, regression, or time-series forecasting problem) and a metric to optimize in choosing the model and hyperparameters. The user is also given the ability to set time and cost constraints for the model selection and tuning.\n",
    "\n",
    "[1]https://azure.microsoft.com/en-us/blog/new-automated-machine-learning-capabilities-in-azure-machine-learning-service/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](automl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AutoML model selection and tuning process can be easily tracked through the Azure portal or directly in python notebooks through the use of widgets. AutoML quickly selects a high quilty machine learning model tailored for your prediction problem. In this notebook, we walk through the steps of preparing data, setting up an AutoML experiment, and evaluating the results of our best model. More information about running AutoML experiments in Python can be found [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Problem\n",
    "\n",
    "The regression problem we will demonstrate is predicting sentence similarity scores on the STS Benchmark dataset. The [STS Benchmark dataset](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark#STS_benchmark_dataset_and_companion_dataset) contains a selection of English datasets that were used in Semantic Textual Similarity (STS) tasks 2012-2017. The dataset contains 8,628 sentence pairs with a human-labeled integer representing the sentences' similarity (ranging from 0, for no meaning overlap, to 5, meaning equivalence).\n",
    "\n",
    "For each sentence in the sentence pair, we will use Google's pretrained Universal Sentence Encoder (details provided below) to generate a $512$-dimensional embedding. Both embeddings in the sentence pair will be concatenated and the resulting $1024$-dimensional vector will be used as features in our regression problem. Our target variable is the sentence similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0618 22:40:59.654601 10096 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n",
      "System version: 3.6.7 |Anaconda, Inc.| (default, Dec 10 2018, 20:35:02) [MSC v.1915 64 bit (AMD64)]\n",
      "Azure ML SDK Version: 1.0.41\n",
      "Pandas version: 0.23.4\n",
      "Tensorflow Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Set the environment path to find NLP\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "import logging\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial import distance\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Import utils\n",
    "from utils_nlp.azureml import azureml_utils\n",
    "from utils_nlp.dataset import stsbenchmark\n",
    "from utils_nlp.dataset.preprocess import (\n",
    "    to_lowercase,\n",
    "    to_spacy_tokens,\n",
    "    rm_spacy_stopwords,\n",
    ")\n",
    "\n",
    "# Tensorflow dependencies for Google Universal Sentence Encoder\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "tf.logging.set_verbosity(tf.logging.ERROR) # reduce logging output\n",
    "\n",
    "# AzureML packages\n",
    "import azureml as aml\n",
    "import logging\n",
    "from azureml.telemetry import set_diagnostics_collection\n",
    "set_diagnostics_collection(send_diagnostics=True)\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core import Datastore, Experiment\n",
    "from azureml.data.data_reference import DataReference  \n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.train.automl import AutoMLStep\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Azure ML SDK Version:\", aml.core.VERSION)\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow Version:\", tf.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_PATH = '../../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STS Benchmark Dataset**\n",
    "\n",
    "As described above, the STS Benchmark dataset contains 8.6K sentence pairs along with a human-annotated score for how similiar the two sentences are. We will load the training, development (validation), and test sets provided by STS Benchmark and preprocess the data (lowercase the text, drop irrelevant columns, and rename the remaining columns) using the utils contained in this repo. Each dataset will ultimately have three columns: _sentence1_ and _sentence2_ which contain the text of the sentences in the sentence pair, and _score_ which contains the human-annotated similarity score of the sentence pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 401/401 [00:01<00:00, 232KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to ../../data\\raw\\stsbenchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 401/401 [00:02<00:00, 140KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to ../../data\\raw\\stsbenchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 401/401 [00:02<00:00, 165KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to ../../data\\raw\\stsbenchmark\n"
     ]
    }
   ],
   "source": [
    "# Load in the raw datasets as pandas dataframes\n",
    "train_raw = stsbenchmark.load_pandas_df(BASE_DATA_PATH, file_split=\"train\")\n",
    "dev_raw = stsbenchmark.load_pandas_df(BASE_DATA_PATH, file_split=\"dev\")\n",
    "test_raw = stsbenchmark.load_pandas_df(BASE_DATA_PATH, file_split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean each dataset by lowercasing text, removing irrelevant columns,\n",
    "# and renaming the remaining columns\n",
    "train_clean = stsbenchmark.clean_sts(train_raw)\n",
    "dev_clean = stsbenchmark.clean_sts(dev_raw)\n",
    "test_clean = stsbenchmark.clean_sts(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all text to lowercase\n",
    "train = to_lowercase(train_clean)\n",
    "dev = to_lowercase(dev_clean)\n",
    "test = to_lowercase(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 5749 sentences\n",
      "Development set has 1500 sentences\n",
      "Testing set has 1379 sentences\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set has {} sentences\".format(len(train)))\n",
    "print(\"Development set has {} sentences\".format(len(dev)))\n",
    "print(\"Testing set has {} sentences\".format(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>a plane is taking off.</td>\n",
       "      <td>an air plane is taking off.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.80</td>\n",
       "      <td>a man is playing a large flute.</td>\n",
       "      <td>a man is playing a flute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.80</td>\n",
       "      <td>a man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>a man is spreading shredded cheese on an uncoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.60</td>\n",
       "      <td>three men are playing chess.</td>\n",
       "      <td>two men are playing chess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.25</td>\n",
       "      <td>a man is playing the cello.</td>\n",
       "      <td>a man seated is playing the cello.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                      sentence1  \\\n",
       "0   5.00                         a plane is taking off.   \n",
       "1   3.80                a man is playing a large flute.   \n",
       "2   3.80  a man is spreading shreded cheese on a pizza.   \n",
       "3   2.60                   three men are playing chess.   \n",
       "4   4.25                    a man is playing the cello.   \n",
       "\n",
       "                                           sentence2  \n",
       "0                        an air plane is taking off.  \n",
       "1                          a man is playing a flute.  \n",
       "2  a man is spreading shredded cheese on an uncoo...  \n",
       "3                         two men are playing chess.  \n",
       "4                 a man seated is playing the cello.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the cleaned data\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "    \n",
    "train.to_csv(\"data/train.csv\", index=False)\n",
    "test.to_csv(\"data/test.csv\", index=False)\n",
    "dev.to_csv(\"data/dev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Set up AzureML Workspace, Experiment, Compute & Datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Link to or create a workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0618 22:55:15.048929 10096 authentication.py:494] Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0618 22:55:15.432929 37988 _profile.py:1082] Note, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\n",
      "W0618 22:55:30.586771 10096 _profile.py:774] You have logged in. Now let us find all the subscriptions to which you have access...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n",
      "Workspace name: MAIDAPTest\n",
      "Azure region: eastus2\n",
      "Subscription id: 15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\n",
      "Resource group: nlprg\n"
     ]
    }
   ],
   "source": [
    "ws = azureml_utils.get_or_create_workspace(\n",
    "    subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "    resource_group=\"<RESOURCE_GROUP>\",\n",
    "    workspace_name=\"<WORKSPACE_NAME>\",\n",
    "    workspace_region=\"<WORKSPACE_REGION>\"\n",
    ")\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Set up an experiment and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a folder for the project\n",
    "project_folder = './automl-sentence-similarity'\n",
    "if not os.path.exists(project_folder):\n",
    "    os.makedirs(project_folder)\n",
    "\n",
    "# Set up an experiment\n",
    "experiment_name = 'automl-sentence-similarity'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "run = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c. Link compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-06-19T02:52:52.599000+00:00', 'errors': None, 'creationTime': '2019-05-20T22:09:40.142683+00:00', 'modifiedTime': '2019-05-20T22:10:11.888950+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "# choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current AmlCompute. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d. Upload data to datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./data\\dev.csv\n",
      "Uploading ./data\\test.csv\n",
      "Uploading ./data\\train.csv\n",
      "Uploaded ./data\\dev.csv, 1 files out of an estimated total of 3\n",
      "Uploaded ./data\\train.csv, 2 files out of an estimated total of 3\n",
      "Uploaded ./data\\test.csv, 3 files out of an estimated total of 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_e806155bf4c3452596bd2c3ffa76743d"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a specific datastore or can call ws.get_default_datastore()\n",
    "datastore_name = 'workspacefilestore'\n",
    "ds = ws.datastores[datastore_name]\n",
    "\n",
    "# Upload files in data folder\n",
    "ds.upload(src_dir='./data', target_path='stsbenchmark_data', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a **DataReference** object that points to the data we just uploaded into the stsbenchmark_data folder. DataReference objects point to data that is accessible from a datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = DataReference(datastore=ds, \n",
    "                           data_reference_name=\"stsbenchmark\",\n",
    "                           path_on_datastore='stsbenchmark_data/',\n",
    "                           overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Set up run configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run config is ready\n"
     ]
    }
   ],
   "source": [
    "# create a new RunConfig object\n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Set compute target to AmlCompute\n",
    "conda_run_config.target = compute_target\n",
    "\n",
    "conda_run_config.environment.docker.enabled = True\n",
    "conda_run_config.environment.docker.base_image = aml.core.runconfig.DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "conda_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "conda_run_config.environment.python.conda_dependencies = CondaDependencies.create(pip_packages=['azureml-sdk[automl]', 'azureml-sdk', 'azureml-dataprep', 'azureml-train-automl==1.0.33'], \n",
    "                              conda_packages=['numpy', 'py-xgboost', 'pandas', 'tensorflow', 'tensorflow-hub', 'scikit-learn'], \n",
    "                              pin_sdk_version=False)\n",
    "\n",
    "print('run config is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. PythonScriptStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this pipeline step, we will convert our sentences into a numerical representation in order to use them in our machine learning model. We will embed both sentences using the Google Universal Sentence Encoder and concatenate their representations into a $1024$-dimensional vector to use as features for AutoML.\n",
    "\n",
    "**Google Universal Sentence Encoder: Overview**\n",
    "We'll use a popular sentence encoder called Google Universal Sentence Encoder (see [original paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf)). Google provides two pretrained models based on different design goals: a Transformer model (targets high accuracy even if this reduces model complexity) and a Deep Averaging Network model (DAN; targets efficient inference). Both models are trained on a variety of web sources (Wikipedia, news, question-answers pages, and discussion forums) and produced 512-dimensional embeddings. This notebook utilizes the Transformer-based encoding model which can be downloaded [here](https://tfhub.dev/google/universal-sentence-encoder-large/3) because of its better performance relative to the DAN model on the STS Benchmark dataset (see Table 2 in Google Research's [paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Google Universal Sentence Encoder: Transformer Model** The Transformer model produces sentence embeddings using the \"encoding sub-graph of the transformer architecture\" (original architecture introduced [here](https://arxiv.org/abs/1706.03762)). \"This sub-graph uses attention to compute context aware representations of words in a sentence that take into account both the ordering and identity of all the other workds. The context aware word representations are converted to a fixed length sentence encoding vector by computing the element-wise sum of the representations at each word position.\" The input to the model is lowercase PTB-tokenized strings and the model is designed to be useful for multiple different tasks by using multi-task learning. More details about the model can be found in the [paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf) by Google Research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the Pretrained Model**\n",
    "\n",
    "Tensorflow-hub provides the pretrained model for use by the public. We import the model from its url and then feed the model our sentences for it to encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./automl-sentence-similarity/embed.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $project_folder/embed.py\n",
    "import argparse\n",
    "import os\n",
    "import azureml.core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "tf.logging.set_verbosity(tf.logging.ERROR) # reduce logging output\n",
    "\n",
    "def google_encoder(dataset):\n",
    "    \"\"\" Function that embeds sentences using the Google Universal\n",
    "    Sentence Encoder pretrained model\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dataset: pandas dataframe with sentences and scores\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    emb1: 512-dimensional representation of sentence1\n",
    "    emb2: 512-dimensional representation of sentence2\n",
    "    \"\"\"\n",
    "    sts_input1 = tf.placeholder(tf.string, shape=(None))\n",
    "    sts_input2 = tf.placeholder(tf.string, shape=(None))\n",
    "\n",
    "    # Apply embedding model and normalize the input\n",
    "    sts_encode1 = tf.nn.l2_normalize(embedding_model(sts_input1), axis=1)\n",
    "    sts_encode2 = tf.nn.l2_normalize(embedding_model(sts_input2), axis=1)\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.tables_initializer())\n",
    "        emb1, emb2 = session.run(\n",
    "          [sts_encode1, sts_encode2],\n",
    "          feed_dict={\n",
    "              sts_input1: dataset['sentence1'],\n",
    "              sts_input2: dataset['sentence2']\n",
    "          })\n",
    "    return emb1, emb2\n",
    "\n",
    "def feature_engineering(dataset):\n",
    "    \"\"\"Extracts embedding features from the dataset and returns\n",
    "    features and target in a dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dataset: pandas dataframe with sentences and scores\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    df: pandas dataframe with embedding features\n",
    "    scores: list of target variables\n",
    "    \"\"\"\n",
    "    google_USE_emb1, google_USE_emb2 = google_encoder(dataset)\n",
    "    n_google = google_USE_emb1.shape[1] #length of the embeddings \n",
    "    df = np.concatenate((google_USE_emb1, google_USE_emb2), axis=1)\n",
    "    names = ['USEEmb1_'+str(i) for i in range(n_google)]+['USEEmb2_'+str(i) for i in range(n_google)]\n",
    "    df = pd.DataFrame(df, columns=names)\n",
    "    return df, dataset['score']\n",
    "\n",
    "def write_output(df, path, name):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    print(\"%s created\" % path)\n",
    "    df.to_csv(path + \"/\" + name, index=False)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--sentence_data\", type=str)\n",
    "parser.add_argument(\"--embedded_data\", type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "embedding_model = hub.Module(module_url)\n",
    "\n",
    "train = pd.read_csv(args.sentence_data + \"/train.csv\")\n",
    "dev = pd.read_csv(args.sentence_data + \"/dev.csv\")\n",
    "\n",
    "training_data, training_scores = feature_engineering(train)\n",
    "validation_data, validation_scores = feature_engineering(dev)\n",
    "\n",
    "write_output(training_data, args.embedded_data, \"X_train.csv\")\n",
    "write_output(pd.DataFrame(training_scores, columns=['score']), args.embedded_data, \"y_train.csv\")\n",
    "\n",
    "write_output(validation_data, args.embedded_data, \"X_dev.csv\")\n",
    "write_output(pd.DataFrame(validation_scores, columns=['score']), args.embedded_data, \"y_dev.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PipelineData** objects represent a piece of intermediate data in a pipeline. Generally they are produced by one step (as an output) and then consumed by the next step (as an input), introducing an implicit order between steps in a pipeline. We create a PipelineData object that can represent the data produced by our first pipeline step that will be consumed by our second pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_data = PipelineData(\"embedded_data\", datastore=ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedStep = PythonScriptStep(\n",
    "    name=\"Embed\",\n",
    "    script_name=\"embed.py\", \n",
    "    arguments=[\"--embedded_data\", embedded_data,\n",
    "               \"--sentence_data\", input_data],\n",
    "    inputs=[input_data],\n",
    "    outputs=[embedded_data],\n",
    "    compute_target=compute_target,\n",
    "    runconfig = conda_run_config,\n",
    "    hash_paths=[\"embed.py\"],\n",
    "    source_directory=project_folder,\n",
    "    allow_reuse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c. AutoMLStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./automl-sentence-similarity/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $project_folder/get_data.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_data():\n",
    "    X_train  = pd.read_csv(os.environ['AZUREML_DATAREFERENCE_embedded_data'] + \"/X_train.csv\")\n",
    "    y_train  = pd.read_csv(os.environ['AZUREML_DATAREFERENCE_embedded_data'] + \"/y_train.csv\")\n",
    "    X_dev  = pd.read_csv(os.environ['AZUREML_DATAREFERENCE_embedded_data'] + \"/X_dev.csv\")\n",
    "    y_dev  = pd.read_csv(os.environ['AZUREML_DATAREFERENCE_embedded_data'] + \"/y_dev.csv\")\n",
    "    return { \"X\" : X_train.values, \"y\" : y_train.values.flatten(), \"X_valid\": X_dev.values, \"y_valid\": y_dev.values.flatten()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PipelineData objects for tracking AutoML metrics \n",
    "metrics_output_name = 'metrics_output'\n",
    "best_model_output_name = 'best_model_output'\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                           datastore=ds,\n",
    "                           pipeline_output_name=metrics_output_name,\n",
    "                           training_output=TrainingOutput(type='Metrics'))\n",
    "model_data = PipelineData(name='model_data',\n",
    "                           datastore=ds,\n",
    "                           pipeline_output_name=best_model_output_name,\n",
    "                           training_output=TrainingOutput(type='Model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 5,\n",
    "    \"iterations\": 5,\n",
    "    \"primary_metric\": 'spearman_correlation',\n",
    "    \"preprocess\": True,\n",
    "    \"verbosity\": logging.INFO,\n",
    "}\n",
    "automl_config = AutoMLConfig(task = 'regression',\n",
    "                 debug_log = 'automl_errors.log',\n",
    "                 path = project_folder,\n",
    "                 compute_target=compute_target,\n",
    "                 run_configuration=conda_run_config,\n",
    "                 data_script = project_folder + \"/get_data.py\",\n",
    "                 **automl_settings\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_step = AutoMLStep(\n",
    "    name='AutoML',\n",
    "    automl_config=automl_config,\n",
    "    inputs=[embedded_data],\n",
    "    outputs=[metrics_data, model_data],\n",
    "    hash_paths=[\"get_data.py\"],\n",
    "    allow_reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_step.run_after(embedStep)\n",
    "pipeline = Pipeline(\n",
    "    description=\"pipeline_embed_automl\",\n",
    "    workspace=ws,    \n",
    "    steps=[automl_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step AutoML [320f0121][5913af95-9ebb-42c0-a650-7725b7fe0b54], (This step will run and generate new outputs)\n",
      "Created step Embed [81087fb9][d271deed-bd3b-4e41-9814-29fc11e585b4], (This step is eligible to reuse a previous run's output)\n",
      "Using data reference stsbenchmark for StepId [8ca56eac][e3340790-c54f-4147-8dd0-bcb80a9b7b46], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted pipeline run: 5549c561-26e2-4979-9f3f-0379e38de86a\n"
     ]
    }
   ],
   "source": [
    "pipeline_run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3361878269d34e4a9546fa54822e9e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 5549c561-26e2-4979-9f3f-0379e38de86a\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/nlprg/providers/Microsoft.MachineLearningServices/workspaces/MAIDAPTest/experiments/automl-sentence-similarity/runs/5549c561-26e2-4979-9f3f-0379e38de86a\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 3fffcae0-74f3-49c5-bb7d-f877bda582f7\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/nlprg/providers/Microsoft.MachineLearningServices/workspaces/MAIDAPTest/experiments/automl-sentence-similarity/runs/3fffcae0-74f3-49c5-bb7d-f877bda582f7\n",
      "\n",
      "StepRun(Embed) Execution Summary\n",
      "=================================\n",
      "StepRun( Embed ) Status: Finished\n",
      "{'runId': '3fffcae0-74f3-49c5-bb7d-f877bda582f7', 'target': 'gpucluster', 'status': 'Completed', 'startTimeUtc': '2019-06-19T03:30:21.798384Z', 'endTimeUtc': '2019-06-19T03:30:21.864304Z', 'properties': {'azureml.reusedrunid': 'f78cb325-802a-4779-ada8-05db82c97835', 'azureml.reusednodeid': '70352e68', 'azureml.reusedpipeline': '50a80cb2-8adb-4cd5-a337-c493404b7549', 'azureml.reusedpipelinerunid': '50a80cb2-8adb-4cd5-a337-c493404b7549', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '81087fb9', 'ContentSnapshotId': '8979e52a-3c38-432c-b9e3-a235b33b7d1e', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': '5549c561-26e2-4979-9f3f-0379e38de86a', 'AzureML.DerivedImageName': 'azureml/azureml_b2a8349416887710026a15e07f74a6a3'}, 'runDefinition': {'script': 'embed.py', 'arguments': ['--embedded_data', '$AZUREML_DATAREFERENCE_embedded_data', '--sentence_data', '$AZUREML_DATAREFERENCE_stsbenchmark'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'gpucluster', 'dataReferences': {'stsbenchmark': {'dataStoreName': 'workspacefilestore', 'mode': 'Mount', 'pathOnDataStore': 'stsbenchmark_data/', 'pathOnCompute': None, 'overwrite': False}, 'embedded_data': {'dataStoreName': 'workspacefilestore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/f78cb325-802a-4779-ada8-05db82c97835/embedded_data', 'pathOnCompute': None, 'overwrite': False}}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment automl-sentence-similarity Environment', 'version': 'Autosave_2019-06-18T20:46:30Z_9b3f4178', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk', 'azureml-dataprep', 'azureml-train-automl==1.0.33']}, 'numpy', 'py-xgboost', 'pandas', 'tensorflow', 'tensorflow-hub', 'scikit-learn'], 'channels': ['conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'enabled': True, 'sharedVolumes': True, 'gpuSupport': False, 'shmSize': '1g', 'arguments': [], 'baseImageRegistry': {'address': None, 'username': None, 'password': None}}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'vmPriority': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/20_image_build_log.txt?sv=2018-03-28&sr=b&sig=UnaDzx29AaHQ4bXCShTvUjr9zNTT%2B9u2uBDvfSdMMq8%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/70_driver_log.txt?sv=2018-03-28&sr=b&sig=XYlg%2FyRm0SUVCXbObSl5DCwjp3Bl3B6on4blzUoFqlo%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r', 'azureml-logs/driver_log.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/driver_log.txt?sv=2018-03-28&sr=b&sig=kprjz9j6n3Lzm%2FL8KxJkUBNvxW1BWMiS7hWfVsfpERw%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r', 'azureml-logs/55_batchai_stdout-job_post.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/55_batchai_stdout-job_post.txt?sv=2018-03-28&sr=b&sig=ioI%2Ff6h7kdlY11mw9PIgpLuPT%2FGMVXSXLRB34qHuJaA%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r', 'azureml-logs/55_batchai_execution.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/55_batchai_execution.txt?sv=2018-03-28&sr=b&sig=ROUL6b8kXIXxxUwuQouafOz3jRRpTEBkU3abanuluz8%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r', 'azureml-logs/56_batchai_stderr.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/56_batchai_stderr.txt?sv=2018-03-28&sr=b&sig=Te%2FTg7zxGNobQjnHM5Nvzv%2BCQ4LuWrvb29KKunFFRgQ%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r', 'azureml-logs/55_batchai_stdout.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/55_batchai_stdout.txt?sv=2018-03-28&sr=b&sig=AFfpczOOi6dGhkqDcREC4kscKdT%2FigM7OnLNAQZZthI%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r', 'azureml-logs/55_batchai_stdout-job_prep.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/55_batchai_stdout-job_prep.txt?sv=2018-03-28&sr=b&sig=PkUiUN6d9d9MCnCgxRUsdVBlvy2vq2sgyWTb%2FdeOf8g%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/logs/azureml/stdoutlogs.txt?sv=2018-03-28&sr=b&sig=wChazhC1Pscu1eFgEmq9nkZ3mxQl4J%2FmvKJoRD7GdBg%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/logs/azureml/stderrlogs.txt?sv=2018-03-28&sr=b&sig=N9oo4pCAB4A9gAPsEwKWzv%2BB1UJ%2BS2pnNGMc0Hv%2B%2F9k%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/logs/azureml/executionlogs.txt?sv=2018-03-28&sr=b&sig=lXcVv6kNYKwT2tWKIjFXWASrQSBs2RfNYTEqhairYfQ%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r', 'logs/azureml/138_azureml.log': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/logs/azureml/138_azureml.log?sv=2018-03-28&sr=b&sig=bwyQxhxb8UkX%2FAvYDXGAczSBrXieqOqfshRlwsyYai0%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r', 'logs/azureml/azureml.log': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/logs/azureml/azureml.log?sv=2018-03-28&sr=b&sig=N1CzC2OIPbDG6Ts9nzPVg1rN3%2BuTiXNHSM4A4UOv6YE%3D&st=2019-06-19T03%3A20%3A31Z&se=2019-06-19T11%3A30%3A31Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: 297207dd-e830-4133-af2b-1efff54ee11a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/nlprg/providers/Microsoft.MachineLearningServices/workspaces/MAIDAPTest/experiments/automl-sentence-similarity/runs/297207dd-e830-4133-af2b-1efff54ee11a\n",
      "StepRun( AutoML ) Status: NotStarted\n",
      "StepRun( AutoML ) Status: Running\n",
      "\n",
      "StepRun(AutoML) Execution Summary\n",
      "==================================\n",
      "StepRun( AutoML ) Status: Finished\n",
      "{'runId': '297207dd-e830-4133-af2b-1efff54ee11a', 'target': 'gpucluster', 'status': 'Completed', 'startTimeUtc': '2019-06-19T03:36:02.737145Z', 'endTimeUtc': '2019-06-19T03:44:50.348314Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '81120654-2a16-4013-96f7-922eda5e4e1e', 'StepType': 'AutoMLStep', 'azureml.pipelinerunid': '5549c561-26e2-4979-9f3f-0379e38de86a', 'num_iterations': '5', 'training_type': 'TrainFull', 'acquisition_function': 'EI', 'metrics': 'accuracy', 'primary_metric': 'spearman_correlation', 'train_split': '0', 'MaxTimeSeconds': '300', 'acquisition_parameter': '0', 'num_cross_validation': None, 'target': 'gpucluster', 'RawAMLSettingsString': \"{'name':'automl-sentence-similarity','subscription_id':'15ae9cb6-95c1-483d-a0e3-b1a1a3b06324','resource_group':'nlprg','workspace_name':'MAIDAPTest','path':'./automl-sentence-similarity','iterations':5,'data_script':'./automl-sentence-similarity/get_data.py','primary_metric':'spearman_correlation','task_type':'regression','compute_target':'gpucluster','spark_context':None,'validation_size':0.0,'n_cross_validations':None,'y_min':None,'y_max':None,'num_classes':None,'preprocess':True,'lag_length':0,'max_cores_per_iteration':1,'max_concurrent_iterations':1,'iteration_timeout_minutes':5,'mem_in_mb':None,'enforce_time_on_windows':True,'experiment_timeout_minutes':None,'experiment_exit_score':None,'blacklist_models':None,'whitelist_models':None,'auto_blacklist':True,'exclude_nan_labels':True,'verbosity':20,'debug_log':'automl_errors.log','debug_flag':None,'enable_ensembling':True,'ensemble_iterations':5,'model_explainability':False,'enable_tf':False,'enable_cache':True,'enable_subsampling':False,'subsample_seed':None,'cost_mode':0,'is_timeseries':False,'metric_operation':'maximize'}\", 'AMLSettingsJsonString': '{\"name\":\"automl-sentence-similarity\",\"subscription_id\":\"15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\",\"resource_group\":\"nlprg\",\"workspace_name\":\"MAIDAPTest\",\"path\":\"./automl-sentence-similarity\",\"iterations\":5,\"data_script\":\"./automl-sentence-similarity/get_data.py\",\"primary_metric\":\"spearman_correlation\",\"task_type\":\"regression\",\"compute_target\":\"gpucluster\",\"spark_context\":null,\"validation_size\":0.0,\"n_cross_validations\":null,\"y_min\":null,\"y_max\":null,\"num_classes\":null,\"preprocess\":true,\"lag_length\":0,\"max_cores_per_iteration\":1,\"max_concurrent_iterations\":1,\"iteration_timeout_minutes\":5,\"mem_in_mb\":null,\"enforce_time_on_windows\":true,\"experiment_timeout_minutes\":null,\"experiment_exit_score\":null,\"blacklist_models\":null,\"whitelist_models\":null,\"auto_blacklist\":true,\"exclude_nan_labels\":true,\"verbosity\":20,\"debug_log\":\"automl_errors.log\",\"debug_flag\":null,\"enable_ensembling\":true,\"ensemble_iterations\":5,\"model_explainability\":false,\"enable_tf\":false,\"enable_cache\":true,\"enable_subsampling\":false,\"subsample_seed\":null,\"cost_mode\":0,\"is_timeseries\":false,\"metric_operation\":\"maximize\"}', 'DataPrepJsonString': None, 'EnableSubsampling': 'False', 'runTemplate': 'AutoML', 'snapshotId': '81120654-2a16-4013-96f7-922eda5e4e1e', 'SetupRunId': '297207dd-e830-4133-af2b-1efff54ee11a_setup', 'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"dataset_classes\": 140, \"dataset_features\": 1024, \"dataset_samples\": 5749, \"is_sparse\": false, \"subsampling\": false}'}, 'logFiles': {'logs/azureml/stdoutlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.297207dd-e830-4133-af2b-1efff54ee11a/logs/azureml/stdoutlogs.txt?sv=2018-03-28&sr=b&sig=sc4OGsuRrBaBzm1%2F8U%2BXjdywdh00XNxmO9tISKxYRZM%3D&st=2019-06-19T03%3A37%3A03Z&se=2019-06-19T11%3A47%3A03Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.297207dd-e830-4133-af2b-1efff54ee11a/logs/azureml/stderrlogs.txt?sv=2018-03-28&sr=b&sig=M9aM0Xy%2FznTxVS1jkee1WL5GTKVblvYXOjaRKeh6Bp8%3D&st=2019-06-19T03%3A37%3A03Z&se=2019-06-19T11%3A47%3A03Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.297207dd-e830-4133-af2b-1efff54ee11a/logs/azureml/executionlogs.txt?sv=2018-03-28&sr=b&sig=kzTStpejzK%2Fk0h6gtKOj4WwJBYz6tp5DG7YnAgPJtJQ%3D&st=2019-06-19T03%3A37%3A03Z&se=2019-06-19T11%3A47%3A03Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '5549c561-26e2-4979-9f3f-0379e38de86a', 'status': 'Completed', 'startTimeUtc': '2019-06-19T03:30:19.54232Z', 'endTimeUtc': '2019-06-19T03:46:59.380629Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': None, 'runType': 'HTTP', 'azureml.parameters': '{}'}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.5549c561-26e2-4979-9f3f-0379e38de86a/logs/azureml/executionlogs.txt?sv=2018-03-28&sr=b&sig=xygOEA3uP72DELH6cKm1AtJ9wsQUrR6DhcGBIZC6Grc%3D&st=2019-06-19T03%3A37%3A06Z&se=2019-06-19T11%3A47%3A06Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.5549c561-26e2-4979-9f3f-0379e38de86a/logs/azureml/stdoutlogs.txt?sv=2018-03-28&sr=b&sig=mnwq58c19ZqTLxjJhnS99LTZAHISFgJua4XvFmVKxkE%3D&st=2019-06-19T03%3A37%3A06Z&se=2019-06-19T11%3A47%3A06Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.5549c561-26e2-4979-9f3f-0379e38de86a/logs/azureml/stderrlogs.txt?sv=2018-03-28&sr=b&sig=2dFSQk1r7iNsd18URUCgWlsEp%2FNStDu8Y2d3Q1fkat8%3D&st=2019-06-19T03%3A37%3A06Z&se=2019-06-19T11%3A47%3A06Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline.publish(\n",
    "    name=\"Sentence_Similarity_Pipeline\", \n",
    "    description=\"Sentence Similarity with Google USE Features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
