{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using AzureML Pipelines and AutoML for Predicting Sentence Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use AzureML pipelines and AutoML to streamline the creation of a machine learning workflow for predicting sentence similarity. The pipeline contains two steps:   \n",
    "1. PythonScriptStep: embeds sentences using a popular sentence embedding model, Google Universal Sentence Encoder\n",
    "2. AutoMLStep: demonstrates how to use AutoML to automate model selection for predicting sentence similarity (regression)\n",
    "\n",
    "This notebook showcases how to use the following AzureML features:  \n",
    "- AzureML Pipelines\n",
    "- AutoML\n",
    "- AmlCompute\n",
    "- Datastore\n",
    "- Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction](#1.-Introduction)  \n",
    "    * 1.1 [What are AzureML Pipelines?](#1.1-What-are-AzureML-Pipelines?)  \n",
    "    * 1.2 [What is Azure AutoML?](#1.2-What-is-Azure-AutoML?)  \n",
    "    * 1.3 [Modeling Problem](#1.3-Modeling-Problem)  \n",
    "    \n",
    "    \n",
    "2. [Data Preparation](#2.-Data-Preparation)  \n",
    "\n",
    "\n",
    "3. [AzureML Setup](#3.-AzureML-Setup)  \n",
    "    * 3.1 [Link to or create a `Workspace`](#3.1-Link-to-or-create-a-Workspace)  \n",
    "    * 3.2 [Set up an `Experiment` and logging](#3.2-Set-up-an-Experiment-and-logging)  \n",
    "    * 3.3 [Link `AmlCompute` compute target](#3.3-Link-AmlCompute-compute-target)  \n",
    "    * 3.4 [Upload data to `Datastore`](#3.4-Upload-data-to-Datastore)  \n",
    "    \n",
    "    \n",
    "4. [Create AzureML Pipeline](#4.-Create-AzureML-Pipeline)  \n",
    "    * 4.1 [Set up run configuration file](#4.1-Set-up-run-configuration-file)  \n",
    "    * 4.2 [PythonScriptStep](#4.2-PythonScriptStep)  \n",
    "        * 4.2.1 [Define python script to run](#4.2.1-Define-python-script-to-run)\n",
    "        * 4.2.2 [Create PipelineData object](#4.2.2-Create-PipelineData-object)\n",
    "        * 4.2.3 [Create PythonScriptStep](#4.2.3-Create-PythonScriptStep)\n",
    "        \n",
    "    * 4.3 [AutoMLStep](#4.3-AutoMLStep)\n",
    "        * 4.3.1 [Define get_data script to load data](#4.3.1-Define-get_data-script-to-load-data)\n",
    "        * 4.3.2 [Create AutoMLConfig object](#4.3.2-Create-AutoMLConfig-object)\n",
    "        * 4.3.3 [Create AutoMLStep](#4.3.3-Create-AutoMLStep)\n",
    "        \n",
    "        \n",
    "5. [Run Pipeline](#5.-Run-Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 What are AzureML Pipelines?\n",
    "\n",
    "AzureML Pipelines \"define reusable machine learning workflows that can be used as a template for your machine learning scenarios\" ([pipeline information](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-ml-pipelines)). Pipelines allow you to optimize your workflow and spend time on machine learning rather than infrastructure. A Pipeline is defined by a series of steps; the following steps are available: AdlaStep, AutoMLStep, AzureBatchStep, DataTransferStep, DatabricksStep, EstimatorStep, HyperDriveStep, ModuleStep, MpiStep, and PythonScriptStep (see [here](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/?view=azure-ml-py) for details of each step). When the pipeline is run, cached results are used for all steps that have not changed, optimizing the run time. Data sources and intermediate data can be used across multiple steps in a pipeline, saving time and resources. Below we see an example of an AzureML pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pipelines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 What is Azure AutoML?\n",
    "\n",
    "Automated machine learning (AutoML) is a capability of Microsoft's Azure Machine Learning service. The goal of AutoML is to \"improve the productivity of data scientists and democratize AI\" [1] by allowing for the rapid development and deployment of machine learning models. To acheive this goal, AutoML automates the process of selecting a ML model and tuning the model. All the user is required to provide is a dataset (suitable for a classification, regression, or time-series forecasting problem) and a metric to optimize in choosing the model and hyperparameters. The user is also given the ability to set time and cost constraints for the model selection and tuning.\n",
    "\n",
    "[1]https://azure.microsoft.com/en-us/blog/new-automated-machine-learning-capabilities-in-azure-machine-learning-service/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](automl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AutoML model selection and tuning process can be easily tracked through the Azure portal or directly in python notebooks through the use of widgets. AutoML quickly selects a high quilty machine learning model tailored for your prediction problem. In this notebook, we walk through the steps of preparing data, setting up an AutoML experiment, and evaluating the results of our best model. More information about running AutoML experiments in Python can be found [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Modeling Problem\n",
    "\n",
    "The regression problem we will demonstrate is predicting sentence similarity scores on the STS Benchmark dataset. The [STS Benchmark dataset](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark#STS_benchmark_dataset_and_companion_dataset) contains a selection of English datasets that were used in Semantic Textual Similarity (STS) tasks 2012-2017. The dataset contains 8,628 sentence pairs with a human-labeled integer representing the sentences' similarity (ranging from 0, for no meaning overlap, to 5, meaning equivalence).\n",
    "\n",
    "For each sentence in the sentence pair, we will use Google's pretrained Universal Sentence Encoder (details provided below) to generate a $512$-dimensional embedding. Both embeddings in the sentence pair will be concatenated and the resulting $1024$-dimensional vector will be used as features in our regression problem. Our target variable is the sentence similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n",
      "System version: 3.6.7 |Anaconda, Inc.| (default, Dec 10 2018, 20:35:02) [MSC v.1915 64 bit (AMD64)]\n",
      "Azure ML SDK Version: 1.0.41\n",
      "Pandas version: 0.23.4\n",
      "Tensorflow Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Set the environment path to find NLP\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "import logging\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial import distance\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Import utils\n",
    "from utils_nlp.azureml import azureml_utils\n",
    "from utils_nlp.dataset import stsbenchmark\n",
    "from utils_nlp.dataset.preprocess import (\n",
    "    to_lowercase,\n",
    "    to_spacy_tokens,\n",
    "    rm_spacy_stopwords,\n",
    ")\n",
    "\n",
    "# Tensorflow dependencies for Google Universal Sentence Encoder\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "tf.logging.set_verbosity(tf.logging.ERROR) # reduce logging output\n",
    "\n",
    "# AzureML packages\n",
    "import azureml as aml\n",
    "import logging\n",
    "from azureml.telemetry import set_diagnostics_collection\n",
    "set_diagnostics_collection(send_diagnostics=True)\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core import Datastore, Experiment\n",
    "from azureml.data.data_reference import DataReference  \n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.train.automl import AutoMLStep\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Azure ML SDK Version:\", aml.core.VERSION)\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow Version:\", tf.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_PATH = '../../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STS Benchmark Dataset**\n",
    "\n",
    "As described above, the STS Benchmark dataset contains 8.6K sentence pairs along with a human-annotated score for how similiar the two sentences are. We will load the training, development (validation), and test sets provided by STS Benchmark and preprocess the data (lowercase the text, drop irrelevant columns, and rename the remaining columns) using the utils contained in this repo. Each dataset will ultimately have three columns: _sentence1_ and _sentence2_ which contain the text of the sentences in the sentence pair, and _score_ which contains the human-annotated similarity score of the sentence pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 401/401 [00:02<00:00, 191KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to ../../data\\raw\\stsbenchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 401/401 [00:01<00:00, 211KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to ../../data\\raw\\stsbenchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 401/401 [00:01<00:00, 210KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to ../../data\\raw\\stsbenchmark\n"
     ]
    }
   ],
   "source": [
    "# Load in the raw datasets as pandas dataframes\n",
    "train_raw = stsbenchmark.load_pandas_df(BASE_DATA_PATH, file_split=\"train\")\n",
    "dev_raw = stsbenchmark.load_pandas_df(BASE_DATA_PATH, file_split=\"dev\")\n",
    "test_raw = stsbenchmark.load_pandas_df(BASE_DATA_PATH, file_split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean each dataset by lowercasing text, removing irrelevant columns,\n",
    "# and renaming the remaining columns\n",
    "train_clean = stsbenchmark.clean_sts(train_raw)\n",
    "dev_clean = stsbenchmark.clean_sts(dev_raw)\n",
    "test_clean = stsbenchmark.clean_sts(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all text to lowercase\n",
    "train = to_lowercase(train_clean)\n",
    "dev = to_lowercase(dev_clean)\n",
    "test = to_lowercase(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 5749 sentences\n",
      "Development set has 1500 sentences\n",
      "Testing set has 1379 sentences\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set has {} sentences\".format(len(train)))\n",
    "print(\"Development set has {} sentences\".format(len(dev)))\n",
    "print(\"Testing set has {} sentences\".format(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>a plane is taking off.</td>\n",
       "      <td>an air plane is taking off.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.80</td>\n",
       "      <td>a man is playing a large flute.</td>\n",
       "      <td>a man is playing a flute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.80</td>\n",
       "      <td>a man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>a man is spreading shredded cheese on an uncoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.60</td>\n",
       "      <td>three men are playing chess.</td>\n",
       "      <td>two men are playing chess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.25</td>\n",
       "      <td>a man is playing the cello.</td>\n",
       "      <td>a man seated is playing the cello.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                      sentence1  \\\n",
       "0   5.00                         a plane is taking off.   \n",
       "1   3.80                a man is playing a large flute.   \n",
       "2   3.80  a man is spreading shreded cheese on a pizza.   \n",
       "3   2.60                   three men are playing chess.   \n",
       "4   4.25                    a man is playing the cello.   \n",
       "\n",
       "                                           sentence2  \n",
       "0                        an air plane is taking off.  \n",
       "1                          a man is playing a flute.  \n",
       "2  a man is spreading shredded cheese on an uncoo...  \n",
       "3                         two men are playing chess.  \n",
       "4                 a man seated is playing the cello.  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the cleaned data\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "    \n",
    "train.to_csv(\"data/train.csv\", index=False)\n",
    "test.to_csv(\"data/test.csv\", index=False)\n",
    "dev.to_csv(\"data/dev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. AzureML Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set up the necessary components for running this as an AzureML experiment\n",
    "1. Create or link to an existing `Workspace`\n",
    "2. Set up an `Experiment` with `logging`\n",
    "3. Create or attach existing `AmlCompute`\n",
    "4. Upload our data to a `Datastore`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Link to or create a Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = azureml_utils.get_or_create_workspace(\n",
    "    subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "    resource_group=\"<RESOURCE_GROUP>\",\n",
    "    workspace_name=\"<WORKSPACE_NAME>\",\n",
    "    workspace_region=\"<WORKSPACE_REGION>\"\n",
    ")\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Set up an Experiment and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a folder for the project\n",
    "project_folder = './automl-sentence-similarity'\n",
    "if not os.path.exists(project_folder):\n",
    "    os.makedirs(project_folder)\n",
    "\n",
    "# Set up an experiment\n",
    "experiment_name = 'automl-sentence-similarity'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "#Add logging to our experiment\n",
    "run = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Link AmlCompute compute target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use AzureML Pipelines we need to link a compute target as they can not be run locally (see [compute options](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#supported-compute-targets) for explanation of the different options). We will use an AmlCompute target in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'currentNodeCount': 1, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 1, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-06-19T17:10:43.157000+00:00', 'errors': None, 'creationTime': '2019-05-20T22:09:40.142683+00:00', 'modifiedTime': '2019-05-20T22:10:11.888950+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "# choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current AmlCompute. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Upload data to Datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step uploads our local data to a `Datastore` so that the data is accessible from the remote compute target and creates a `DataReference` to point to the location of the data on the Datastore. A DataStore is backed either by a Azure File Storage (default option) or Azure Blob Storage ([how to decide between these options](https://docs.microsoft.com/en-us/azure/storage/common/storage-decide-blobs-files-disks)) and data is made accessible by mounting or copying data to the compute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./data\\dev.csv\n",
      "Uploading ./data\\test.csv\n",
      "Uploading ./data\\train.csv\n",
      "Uploaded ./data\\train.csv, 1 files out of an estimated total of 3\n",
      "Uploaded ./data\\dev.csv, 2 files out of an estimated total of 3\n",
      "Uploaded ./data\\test.csv, 3 files out of an estimated total of 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_dbe7476178794853924424fdfbc4dcc1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a specific datastore or you can call ws.get_default_datastore()\n",
    "datastore_name = 'workspacefilestore'\n",
    "ds = ws.datastores[datastore_name]\n",
    "\n",
    "# Upload files in data folder to the datastore\n",
    "ds.upload(src_dir='./data', target_path='stsbenchmark_data', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also set up a **DataReference** object that points to the data we just uploaded into the stsbenchmark_data folder. DataReference objects point to data that is accessible from a datastore and will be used an an input into our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = DataReference(datastore=ds, \n",
    "                           data_reference_name=\"stsbenchmark\",\n",
    "                           path_on_datastore='stsbenchmark_data/',\n",
    "                           overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create AzureML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up our pipeline which is made of two steps:  \n",
    "1. `PythonScriptStep`: takes each sentence pair from the data in the `Datastore` and concatenates the Google USE embeddings for each sentence into one vector. This step saves the embedding feature matrix back to our `Datastore` and uses a `PipelineData` object to represent this intermediate data.  \n",
    "2. `AutoMLStep`: takes the intermediate data produced by the previous step and passes it to an `AutoMLConfig` which performs the automatic model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Set up run configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set up a `RunConguration` object which configures the execution environment for an experiment (sets up the conda dependencies, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run config is ready\n"
     ]
    }
   ],
   "source": [
    "# create a new RunConfig object\n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Set compute target to AmlCompute\n",
    "conda_run_config.target = compute_target\n",
    "\n",
    "conda_run_config.environment.docker.enabled = True\n",
    "conda_run_config.environment.docker.base_image = aml.core.runconfig.DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "conda_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "conda_run_config.environment.python.conda_dependencies = CondaDependencies.create(pip_packages=['azureml-sdk[automl]', 'azureml-sdk', 'azureml-dataprep', 'azureml-train-automl==1.0.33'], \n",
    "                              conda_packages=['numpy', 'py-xgboost', 'pandas', 'tensorflow', 'tensorflow-hub', 'scikit-learn'], \n",
    "                              pin_sdk_version=False)\n",
    "\n",
    "print('run config is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 PythonScriptStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PythonScriptStep` is a step which runs a user-defined Python script ([documentation](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.python_script_step.pythonscriptstep?view=azure-ml-py) here). In this `PythonScriptStep`, we will convert our sentences into a numerical representation in order to use them in our machine learning model. We will embed both sentences using the Google Universal Sentence Encoder (provided by tensorflow-hub) and concatenate their representations into a $1024$-dimensional vector to use as features for AutoML.\n",
    "\n",
    "**Google Universal Sentence Encoder:**\n",
    "We'll use a popular sentence encoder called Google Universal Sentence Encoder (see [original paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf)). Google provides two pretrained models based on different design goals: a Transformer model (targets high accuracy even if this reduces model complexity) and a Deep Averaging Network model (DAN; targets efficient inference). Both models are trained on a variety of web sources (Wikipedia, news, question-answers pages, and discussion forums) and produced 512-dimensional embeddings. This notebook utilizes the Transformer-based encoding model which can be downloaded [here](https://tfhub.dev/google/universal-sentence-encoder-large/3) because of its better performance relative to the DAN model on the STS Benchmark dataset (see Table 2 in Google Research's [paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf)). The Transformer model produces sentence embeddings using the \"encoding sub-graph of the transformer architecture\" (original architecture introduced [here](https://arxiv.org/abs/1706.03762)). \"This sub-graph uses attention to compute context aware representations of words in a sentence that take into account both the ordering and identity of all the other workds. The context aware word representations are converted to a fixed length sentence encoding vector by computing the element-wise sum of the representations at each word position.\" The input to the model is lowercase PTB-tokenized strings and the model is designed to be useful for multiple different tasks by using multi-task learning. More details about the model can be found in the [paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf) by Google Research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Define python script to run\n",
    "\n",
    "Define the script (called embed.py) that the `PythonScriptStep` will execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./automl-sentence-similarity/embed.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $project_folder/embed.py\n",
    "import argparse\n",
    "import os\n",
    "import azureml.core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "tf.logging.set_verbosity(tf.logging.ERROR) # reduce logging output\n",
    "\n",
    "def google_encoder(dataset):\n",
    "    \"\"\" Function that embeds sentences using the Google Universal\n",
    "    Sentence Encoder pretrained model\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dataset: pandas dataframe with sentences and scores\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    emb1: 512-dimensional representation of sentence1\n",
    "    emb2: 512-dimensional representation of sentence2\n",
    "    \"\"\"\n",
    "    sts_input1 = tf.placeholder(tf.string, shape=(None))\n",
    "    sts_input2 = tf.placeholder(tf.string, shape=(None))\n",
    "\n",
    "    # Apply embedding model and normalize the input\n",
    "    sts_encode1 = tf.nn.l2_normalize(embedding_model(sts_input1), axis=1)\n",
    "    sts_encode2 = tf.nn.l2_normalize(embedding_model(sts_input2), axis=1)\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.tables_initializer())\n",
    "        emb1, emb2 = session.run(\n",
    "          [sts_encode1, sts_encode2],\n",
    "          feed_dict={\n",
    "              sts_input1: dataset['sentence1'],\n",
    "              sts_input2: dataset['sentence2']\n",
    "          })\n",
    "    return emb1, emb2\n",
    "\n",
    "def feature_engineering(dataset):\n",
    "    \"\"\"Extracts embedding features from the dataset and returns\n",
    "    features and target in a dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dataset: pandas dataframe with sentences and scores\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    df: pandas dataframe with embedding features\n",
    "    scores: list of target variables\n",
    "    \"\"\"\n",
    "    google_USE_emb1, google_USE_emb2 = google_encoder(dataset)\n",
    "    n_google = google_USE_emb1.shape[1] #length of the embeddings \n",
    "    df = np.concatenate((google_USE_emb1, google_USE_emb2), axis=1)\n",
    "    names = ['USEEmb1_'+str(i) for i in range(n_google)]+['USEEmb2_'+str(i) for i in range(n_google)]\n",
    "    df = pd.DataFrame(df, columns=names)\n",
    "    return df, dataset['score']\n",
    "\n",
    "def write_output(df, path, name):\n",
    "    \"\"\"Write dataframes to correct path\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    print(\"%s created\" % path)\n",
    "    df.to_csv(path + \"/\" + name, index=False)\n",
    "\n",
    "#Parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--sentence_data\", type=str)\n",
    "parser.add_argument(\"--embedded_data\", type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "embedding_model = hub.Module(module_url)\n",
    "\n",
    "#Read data \n",
    "train = pd.read_csv(args.sentence_data + \"/train.csv\")\n",
    "dev = pd.read_csv(args.sentence_data + \"/dev.csv\")\n",
    "\n",
    "#Get Google USE features\n",
    "training_data, training_scores = feature_engineering(train)\n",
    "validation_data, validation_scores = feature_engineering(dev)\n",
    "\n",
    "#Write out training data to Datastore\n",
    "write_output(training_data, args.embedded_data, \"X_train.csv\")\n",
    "write_output(pd.DataFrame(training_scores, columns=['score']), args.embedded_data, \"y_train.csv\")\n",
    "\n",
    "#Write out validation data to Datastore\n",
    "write_output(validation_data, args.embedded_data, \"X_dev.csv\")\n",
    "write_output(pd.DataFrame(validation_scores, columns=['score']), args.embedded_data, \"y_dev.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Create PipelineData object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PipelineData` objects represent a piece of intermediate data in a pipeline. Generally they are produced by one step (as an output) and then consumed by the next step (as an input), introducing an implicit order between steps in a pipeline. We create a PipelineData object that can represent the data produced by our first pipeline step that will be consumed by our second pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_data = PipelineData(\"embedded_data\", datastore=ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Create PythonScriptStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step defines the `PythonScriptStep`. We give the step a name, tell the step which python script to run (embed.py) and what directory that script is located in (source_directory). Note that the hash_paths parameter will be deprecated but currently is needed to check for any updates to the embed.py file.\n",
    "\n",
    "We also link the compute target and run configuration that we made previously. Our input is the `DataReference` object (input_data) where our raw sentence data was uploaded and our ouput is the `PipelineData` object (embedded_data) where the embedded data produced by this step will be stored. These are also passed in as arguments so that we have access to the correct data paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedStep = PythonScriptStep(\n",
    "    name=\"Embed\",\n",
    "    script_name=\"embed.py\", \n",
    "    arguments=[\"--embedded_data\", embedded_data,\n",
    "               \"--sentence_data\", input_data],\n",
    "    inputs=[input_data],\n",
    "    outputs=[embedded_data],\n",
    "    compute_target=compute_target,\n",
    "    runconfig = conda_run_config,\n",
    "    hash_paths=[\"embed.py\"],\n",
    "    source_directory=project_folder,\n",
    "    allow_reuse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 AutoMLStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AutoMLStep` creates an AutoML step in a pipeline (see [documentation](https://docs.microsoft.com/en-us/python/api/azureml-train-automl/azureml.train.automl.automlstep?view=azure-ml-py) and [basic example](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-with-automated-machine-learning-step.ipynb)). When using AutoML on remote compute, rather than passing our data directly into the `AutoMLConfig` object as we did in the local example, we must define a get_data.py script with a get_data() function to pass as the data_script argument. This workflow can be used for both local and remote executions (see [details](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-auto-train-remote)). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Define get_data script to load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the get_data.py file and get_data() function that the `AutoMLStep` will execute to collect data. Note that we can directly access the path of the intermediate data (called embedded_data) through `os.environ['AZUREML_DATAREFERENCE_embedded_data']`. This is necessary because the AutoMLStep does not accept additional parameters like the PythonScriptStep does with `arguments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./automl-sentence-similarity/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $project_folder/get_data.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_data():\n",
    "    \"\"\"Function needed to load data for use on remote AutoML experiments\"\"\"\n",
    "    X_train  = pd.read_csv(os.environ['AZUREML_DATAREFERENCE_embedded_data'] + \"/X_train.csv\")\n",
    "    y_train  = pd.read_csv(os.environ['AZUREML_DATAREFERENCE_embedded_data'] + \"/y_train.csv\")\n",
    "    X_dev  = pd.read_csv(os.environ['AZUREML_DATAREFERENCE_embedded_data'] + \"/X_dev.csv\")\n",
    "    y_dev  = pd.read_csv(os.environ['AZUREML_DATAREFERENCE_embedded_data'] + \"/y_dev.csv\")\n",
    "    return { \"X\" : X_train.values, \"y\" : y_train.values.flatten(), \"X_valid\": X_dev.values, \"y_valid\": y_dev.values.flatten()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Create AutoMLConfig object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we specify the parameters for the `AutoMLConfig` class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**task**  \n",
    "AutoML supports the following base learners for the regression task: Elastic Net, Light GBM, Gradient Boosting, Decision Tree, K-nearest Neighbors, LARS Lasso, Stochastic Gradient Descent, Random Forest, Extremely Randomized Trees, XGBoost, DNN Regressor, Linear Regression. In addition, AutoML also supports two kinds of ensemble methods: voting (weighted average of the output of multiple base learners) and stacking (training a second \"metalearner\" which uses the base algorithms' predictions to predict the target variable). Specific base learners can be included or excluded in the parameters for the AutoMLConfig class (whitelist_models and blacklist_models) and the voting/stacking ensemble options can be specified as well (enable_voting_ensemble and enable_stack_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**preprocess**  \n",
    "AutoML also has advanced preprocessing methods, eliminating the need for users to perform this manually. Data is automatically scaled and normalized but an additional parameter in the AutoMLConfig class enables the use of more advanced techniques including imputation, generating additional features, transformations, word embeddings, etc. (full list found [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-create-portal-experiments#preprocess)). Note that algorithm-specific preprocessing will be applied even if preprocess=False. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**primary_metric**  \n",
    "The regression metrics available are the following: Spearman Correlation (spearman_correlation), Normalized RMSE (normalized_root_mean_squared_error), Normalized MAE (normalized_mean_absolute_error), and R2 score (r2_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constraints:**  \n",
    "There is a cost_mode parameter to set cost prediction modes (see options [here](https://docs.microsoft.com/en-us/python/api/azureml-train-automl/azureml.train.automl.automlconfig?view=azure-ml-py)). To set constraints on time there are multiple parameters including experiment_exit_score (target score to exit the experiment after acheiving), experiment_timeout_minutes (maximum amount of time for all combined iterations), and iterations (total number of different algorithm and parameter combinations to try)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 5, #How long each iteration can take before moving on\n",
    "    \"iterations\": 5,  #Number of algorithm options to try\n",
    "    \"primary_metric\": 'spearman_correlation', #Metric to optimize\n",
    "    \"preprocess\": True,  #Whether dataset preprocessing should be applied\n",
    "    \"verbosity\": logging.INFO,\n",
    "}\n",
    "automl_config = AutoMLConfig(task = 'regression', #type of task: classification, regression or forecasting\n",
    "                 debug_log = 'automl_errors.log',\n",
    "                 path = project_folder,\n",
    "                 compute_target=compute_target,\n",
    "                 run_configuration=conda_run_config,\n",
    "                 data_script = project_folder + \"/get_data.py\", #local path to script with get_data() function\n",
    "                 **automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Create AutoMLStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create `PipelineData` objects for the model data (our outputs) and then create the `AutoMLStep`. The `AutoMLStep` requires a `AutoMLConfig` object and we pass our intermediate data (embedded_data) in as the inputs. Again, note that the hash_paths parameter will be deprecated but currently is needed to check for any updates to the get_data.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PipelineData objects for tracking AutoML metrics \n",
    "metrics_output_name = 'metrics_output'\n",
    "best_model_output_name = 'best_model_output'\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                           datastore=ds,\n",
    "                           pipeline_output_name=metrics_output_name,\n",
    "                           training_output=TrainingOutput(type='Metrics'))\n",
    "model_data = PipelineData(name='model_data',\n",
    "                           datastore=ds,\n",
    "                           pipeline_output_name=best_model_output_name,\n",
    "                           training_output=TrainingOutput(type='Model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_step = AutoMLStep(\n",
    "    name='AutoML',\n",
    "    automl_config=automl_config, #the AutoMLConfig object created previously\n",
    "    inputs=[embedded_data], #inputs is the PipelineData that was the output of the previous pipeline step\n",
    "    outputs=[metrics_data, model_data], #PipelineData objects to reference metric and model information\n",
    "    hash_paths=[\"get_data.py\"],\n",
    "    allow_reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up our pipeline which requires specifying our `Workspace` and the ordering of the steps that we created (steps parameter). We submit the pipeline and inspect the run details using a RunDetails widget. For remote runs, the execution of iterations is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automl_step.run_after(embedStep)\n",
    "pipeline = Pipeline(\n",
    "    description=\"pipeline_embed_automl\", #give a name for the pipeline\n",
    "    workspace=ws,    \n",
    "    steps=[embedStep, automl_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Embed [ba6c6c5a][d271deed-bd3b-4e41-9814-29fc11e585b4], (This step is eligible to reuse a previous run's output)\n",
      "Created step AutoML [4cc715de][cd685f96-c946-46df-a4c4-87a53b92c90e], (This step will run and generate new outputs)\n",
      "Using data reference stsbenchmark for StepId [0c4ee4ad][e3340790-c54f-4147-8dd0-bcb80a9b7b46], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted pipeline run: 994a7673-8f48-42b9-9cfa-1a47bf70c304\n"
     ]
    }
   ],
   "source": [
    "pipeline_run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the run details using the provided widget\n",
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pipelineWidget.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 994a7673-8f48-42b9-9cfa-1a47bf70c304\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/nlprg/providers/Microsoft.MachineLearningServices/workspaces/MAIDAPTest/experiments/automl-sentence-similarity/runs/994a7673-8f48-42b9-9cfa-1a47bf70c304\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 9f99614d-6bc5-4c10-a121-b09afdc02c74\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/nlprg/providers/Microsoft.MachineLearningServices/workspaces/MAIDAPTest/experiments/automl-sentence-similarity/runs/9f99614d-6bc5-4c10-a121-b09afdc02c74\n",
      "\n",
      "StepRun(Embed) Execution Summary\n",
      "=================================\n",
      "StepRun( Embed ) Status: Finished\n",
      "{'runId': '9f99614d-6bc5-4c10-a121-b09afdc02c74', 'target': 'gpucluster', 'status': 'Completed', 'startTimeUtc': '2019-06-19T17:11:05.931189Z', 'endTimeUtc': '2019-06-19T17:11:06.005469Z', 'properties': {'azureml.reusedrunid': 'f78cb325-802a-4779-ada8-05db82c97835', 'azureml.reusednodeid': '70352e68', 'azureml.reusedpipeline': '50a80cb2-8adb-4cd5-a337-c493404b7549', 'azureml.reusedpipelinerunid': '50a80cb2-8adb-4cd5-a337-c493404b7549', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'ba6c6c5a', 'ContentSnapshotId': '8979e52a-3c38-432c-b9e3-a235b33b7d1e', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': '994a7673-8f48-42b9-9cfa-1a47bf70c304', 'AzureML.DerivedImageName': 'azureml/azureml_b2a8349416887710026a15e07f74a6a3'}, 'runDefinition': {'script': 'embed.py', 'arguments': ['--embedded_data', '$AZUREML_DATAREFERENCE_embedded_data', '--sentence_data', '$AZUREML_DATAREFERENCE_stsbenchmark'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'gpucluster', 'dataReferences': {'stsbenchmark': {'dataStoreName': 'workspacefilestore', 'mode': 'Mount', 'pathOnDataStore': 'stsbenchmark_data/', 'pathOnCompute': None, 'overwrite': False}, 'embedded_data': {'dataStoreName': 'workspacefilestore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/f78cb325-802a-4779-ada8-05db82c97835/embedded_data', 'pathOnCompute': None, 'overwrite': False}}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment automl-sentence-similarity Environment', 'version': 'Autosave_2019-06-18T20:46:30Z_9b3f4178', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk', 'azureml-dataprep', 'azureml-train-automl==1.0.33']}, 'numpy', 'py-xgboost', 'pandas', 'tensorflow', 'tensorflow-hub', 'scikit-learn'], 'channels': ['conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'enabled': True, 'sharedVolumes': True, 'gpuSupport': False, 'shmSize': '1g', 'arguments': [], 'baseImageRegistry': {'address': None, 'username': None, 'password': None}}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'vmPriority': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/20_image_build_log.txt?sv=2018-03-28&sr=b&sig=IuiLro7VKrTsmPEJbfhRGYus2BolDMlvECS3bZ3BFvo%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/70_driver_log.txt?sv=2018-03-28&sr=b&sig=sE6YQBEIcxO1nlrQ6DrJsxEmG2CNm8LT20qK2RohIkM%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r', 'azureml-logs/driver_log.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/driver_log.txt?sv=2018-03-28&sr=b&sig=N4Ygz1QllDgRPhcRMZVs3zK%2BYYOh738B3kzpgdw60j4%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r', 'azureml-logs/55_batchai_stdout-job_post.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/55_batchai_stdout-job_post.txt?sv=2018-03-28&sr=b&sig=8IEjHjHLfGsriil0ZaaHkMizZyhGyVl1VzBD5gwwTvw%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r', 'azureml-logs/55_batchai_execution.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/55_batchai_execution.txt?sv=2018-03-28&sr=b&sig=CC4n2r9mjciD7h%2FMA2Y9NF2exyW4V%2BteCp9q1QBhsTw%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r', 'azureml-logs/56_batchai_stderr.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/56_batchai_stderr.txt?sv=2018-03-28&sr=b&sig=70mUUIdwHi1SJ0s7XyOBviDk%2F9cBh%2BH%2FwV%2FO84%2FQ5xk%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r', 'azureml-logs/55_batchai_stdout.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/55_batchai_stdout.txt?sv=2018-03-28&sr=b&sig=JHPzCDmads8HeyP5HovD6eZa8mSFDfl7l8IwhQXb0d0%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r', 'azureml-logs/55_batchai_stdout-job_prep.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/azureml-logs/55_batchai_stdout-job_prep.txt?sv=2018-03-28&sr=b&sig=W8EnL2oERfRojlbZ%2Fk7KutncWvF6IVSQInSuvUPbdvU%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/logs/azureml/stdoutlogs.txt?sv=2018-03-28&sr=b&sig=b%2ByKyJj1%2Bt8XLmJYOOkvEKSu5glJeyp7lbRaruwGmgo%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/logs/azureml/stderrlogs.txt?sv=2018-03-28&sr=b&sig=9nwwElqLPKA10YapK0r4t3DP1b0T4BM293%2FKkc3u0%2BQ%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/logs/azureml/executionlogs.txt?sv=2018-03-28&sr=b&sig=OUVWL%2FjXqUFM9ymDdIeRMUSxUOQzlU%2BMFRT90qqJflw%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r', 'logs/azureml/138_azureml.log': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/logs/azureml/138_azureml.log?sv=2018-03-28&sr=b&sig=GgFEfWuyG9Q3VjDZI8Mr%2FxkwJ6XW2%2FSPwtHurNrpX54%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r', 'logs/azureml/azureml.log': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.f78cb325-802a-4779-ada8-05db82c97835/logs/azureml/azureml.log?sv=2018-03-28&sr=b&sig=a%2BKsFAoMIlVigIYCutZSa%2FmlqqeLFTCiI3VzFg9GPSo%3D&st=2019-06-19T17%3A01%3A07Z&se=2019-06-20T01%3A11%3A07Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: a3a6fa4b-d2dc-479d-be93-eea52e5c597c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/nlprg/providers/Microsoft.MachineLearningServices/workspaces/MAIDAPTest/experiments/automl-sentence-similarity/runs/a3a6fa4b-d2dc-479d-be93-eea52e5c597c\n",
      "StepRun( AutoML ) Status: NotStarted\n",
      "StepRun( AutoML ) Status: Running\n",
      "\n",
      "StepRun(AutoML) Execution Summary\n",
      "==================================\n",
      "StepRun( AutoML ) Status: Finished\n",
      "{'runId': 'a3a6fa4b-d2dc-479d-be93-eea52e5c597c', 'target': 'gpucluster', 'status': 'Completed', 'startTimeUtc': '2019-06-19T17:17:00.446785Z', 'endTimeUtc': '2019-06-19T17:25:31.355471Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'bac07baf-2af3-4a06-aadf-aef17548794d', 'StepType': 'AutoMLStep', 'azureml.pipelinerunid': '994a7673-8f48-42b9-9cfa-1a47bf70c304', 'num_iterations': '5', 'training_type': 'TrainFull', 'acquisition_function': 'EI', 'metrics': 'accuracy', 'primary_metric': 'spearman_correlation', 'train_split': '0', 'MaxTimeSeconds': '300', 'acquisition_parameter': '0', 'num_cross_validation': None, 'target': 'gpucluster', 'RawAMLSettingsString': \"{'name':'automl-sentence-similarity','subscription_id':'15ae9cb6-95c1-483d-a0e3-b1a1a3b06324','resource_group':'nlprg','workspace_name':'MAIDAPTest','path':'./automl-sentence-similarity','iterations':5,'data_script':'./automl-sentence-similarity/get_data.py','primary_metric':'spearman_correlation','task_type':'regression','compute_target':'gpucluster','spark_context':None,'validation_size':0.0,'n_cross_validations':None,'y_min':None,'y_max':None,'num_classes':None,'preprocess':True,'lag_length':0,'max_cores_per_iteration':1,'max_concurrent_iterations':1,'iteration_timeout_minutes':5,'mem_in_mb':None,'enforce_time_on_windows':True,'experiment_timeout_minutes':None,'experiment_exit_score':None,'blacklist_models':None,'whitelist_models':None,'auto_blacklist':True,'exclude_nan_labels':True,'verbosity':20,'debug_log':'automl_errors.log','debug_flag':None,'enable_ensembling':True,'ensemble_iterations':5,'model_explainability':False,'enable_tf':False,'enable_cache':True,'enable_subsampling':False,'subsample_seed':None,'cost_mode':0,'is_timeseries':False,'metric_operation':'maximize'}\", 'AMLSettingsJsonString': '{\"name\":\"automl-sentence-similarity\",\"subscription_id\":\"15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\",\"resource_group\":\"nlprg\",\"workspace_name\":\"MAIDAPTest\",\"path\":\"./automl-sentence-similarity\",\"iterations\":5,\"data_script\":\"./automl-sentence-similarity/get_data.py\",\"primary_metric\":\"spearman_correlation\",\"task_type\":\"regression\",\"compute_target\":\"gpucluster\",\"spark_context\":null,\"validation_size\":0.0,\"n_cross_validations\":null,\"y_min\":null,\"y_max\":null,\"num_classes\":null,\"preprocess\":true,\"lag_length\":0,\"max_cores_per_iteration\":1,\"max_concurrent_iterations\":1,\"iteration_timeout_minutes\":5,\"mem_in_mb\":null,\"enforce_time_on_windows\":true,\"experiment_timeout_minutes\":null,\"experiment_exit_score\":null,\"blacklist_models\":null,\"whitelist_models\":null,\"auto_blacklist\":true,\"exclude_nan_labels\":true,\"verbosity\":20,\"debug_log\":\"automl_errors.log\",\"debug_flag\":null,\"enable_ensembling\":true,\"ensemble_iterations\":5,\"model_explainability\":false,\"enable_tf\":false,\"enable_cache\":true,\"enable_subsampling\":false,\"subsample_seed\":null,\"cost_mode\":0,\"is_timeseries\":false,\"metric_operation\":\"maximize\"}', 'DataPrepJsonString': None, 'EnableSubsampling': 'False', 'runTemplate': 'AutoML', 'snapshotId': 'bac07baf-2af3-4a06-aadf-aef17548794d', 'SetupRunId': 'a3a6fa4b-d2dc-479d-be93-eea52e5c597c_setup', 'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"dataset_classes\": 140, \"dataset_features\": 1024, \"dataset_samples\": 5749, \"is_sparse\": false, \"subsampling\": false}'}, 'logFiles': {'logs/azureml/stderrlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.a3a6fa4b-d2dc-479d-be93-eea52e5c597c/logs/azureml/stderrlogs.txt?sv=2018-03-28&sr=b&sig=acaxB1G7%2BLXjlhmZ7re%2BwzFYKUIS4pLZSqX%2F7Wx5yHk%3D&st=2019-06-19T17%3A17%3A40Z&se=2019-06-20T01%3A27%3A40Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.a3a6fa4b-d2dc-479d-be93-eea52e5c597c/logs/azureml/executionlogs.txt?sv=2018-03-28&sr=b&sig=wYI6C3wu4V8nM6jJLrp6dI1m5G4lU9ELOuoIiucV27g%3D&st=2019-06-19T17%3A17%3A40Z&se=2019-06-20T01%3A27%3A40Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.a3a6fa4b-d2dc-479d-be93-eea52e5c597c/logs/azureml/stdoutlogs.txt?sv=2018-03-28&sr=b&sig=wPHCRzEYZ1GQ3UbXpsfSk7xFu5SMDzJTsLYkt%2FRHWpM%3D&st=2019-06-19T17%3A17%3A40Z&se=2019-06-20T01%3A27%3A40Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '994a7673-8f48-42b9-9cfa-1a47bf70c304', 'status': 'Completed', 'startTimeUtc': '2019-06-19T17:11:01.903161Z', 'endTimeUtc': '2019-06-19T17:27:39.802989Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': None, 'runType': 'HTTP', 'azureml.parameters': '{}'}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.994a7673-8f48-42b9-9cfa-1a47bf70c304/logs/azureml/executionlogs.txt?sv=2018-03-28&sr=b&sig=YB7H6UmXpGnLZ0ir%2FK2eQuYfwb4pQ5CKXlJhcRnPTqE%3D&st=2019-06-19T17%3A17%3A42Z&se=2019-06-20T01%3A27%3A42Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.994a7673-8f48-42b9-9cfa-1a47bf70c304/logs/azureml/stdoutlogs.txt?sv=2018-03-28&sr=b&sig=PPsWsEXEsUhc%2F8BPXh5KnX6Ze5fUbSohjcqgeghWaIk%3D&st=2019-06-19T17%3A17%3A42Z&se=2019-06-20T01%3A27%3A42Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.994a7673-8f48-42b9-9cfa-1a47bf70c304/logs/azureml/stderrlogs.txt?sv=2018-03-28&sr=b&sig=UQ7xiAJdha6PiJENVKM0OiuduPNfgQbSNrZdEHddO7c%3D&st=2019-06-19T17%3A17%3A42Z&se=2019-06-20T01%3A27%3A42Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_run.wait_for_completion(show_output=True) #show console output while run is in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Publish the pipeline\n",
    "published_pipeline = pipeline.publish(\n",
    "    name=\"Sentence_Similarity_Pipeline\", \n",
    "    description=\"Sentence Similarity with Google USE Features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
