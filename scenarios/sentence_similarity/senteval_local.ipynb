{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentEval on Local\n",
    "\n",
    "SentEval is a widely used benchmarking tool for evaluating general-purpose sentence embeddings. It provides a simple interface for evaluating your embeddings on up to 17 supported downstream tasks (such as sentiment classification, natural language inference, semantic similarity, etc.)\n",
    "\n",
    "Running SentEval locally is simple. Clone the [repository](https://github.com/facebookresearch/SentEval), follow their setup instructions to get the data for the transfer tasks, and implement two functions `prepare(params, samples)` and `batcher(params, batch)` specific to your model. The authors provide some guidance on how to do this in the [examples](https://github.com/facebookresearch/SentEval/tree/master/examples) directory of their repository. In this notebook we show an example for evaluating the GenSen model on the available STS downstream tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00 Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from utils_nlp.eval.senteval import SentEvalRunner\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Torch version: {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 SentEval Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SENTEVAL = (\n",
    "    \"../../../../SentEval\"\n",
    ")  # Set this path to where you have cloned the senteval source code\n",
    "sys.path.insert(0, PATH_TO_SENTEVAL)\n",
    "import senteval\n",
    "\n",
    "transfer_tasks = [\"STSBenchmark\", \"STS12\", \"STS13\", \"STS14\", \"STS15\", \"STS16\"]\n",
    "\n",
    "params_senteval = {\n",
    "    \"task_path\": os.path.join(PATH_TO_SENTEVAL, \"data\"),\n",
    "    \"usepytorch\": True,\n",
    "    \"kfold\": 10,\n",
    "}\n",
    "params_senteval[\"classifier\"] = {\n",
    "    \"nhid\": 0,\n",
    "    \"optim\": \"adam\",\n",
    "    \"batch_size\": 64,\n",
    "    \"tenacity\": 5,\n",
    "    \"epoch_size\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 GenSen Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_GENSEN = (\n",
    "    \"../../../../gensen\"\n",
    ")  # Set this path to where you have cloned the gensen source code\n",
    "sys.path.append(PATH_TO_GENSEN)\n",
    "from gensen import GenSen, GenSenSingle\n",
    "\n",
    "model_params = {}\n",
    "model_params[\"folder_path\"] = os.path.join(PATH_TO_GENSEN, \"data/models\")\n",
    "model_params[\"prefix_1\"] = \"nli_large_bothskip_parse\"\n",
    "model_params[\"prefix_2\"] = \"nli_large_bothskip\"\n",
    "model_params[\"pretrain\"] = os.path.join(\n",
    "    PATH_TO_GENSEN, \"data/embedding/glove.840B.300d.h5\"\n",
    ")\n",
    "model_params[\"cuda\"] = torch.cuda.is_available()\n",
    "\n",
    "print(\"model params: {}\".format(json.dumps(model_params, indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 SentEval Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As specified in the SentEval [repo](https://github.com/facebookresearch/SentEval#how-to-use-senteval), we implement 2 functions:\n",
    "\n",
    "<b>prepare</b> (sees the whole dataset of each task and can thus construct the word vocabulary, the dictionary of word vectors etc)         \n",
    "<b>batcher</b> (transforms a batch of text sentences into sentence embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(params, samples):\n",
    "    vocab = set()\n",
    "    for sample in samples:\n",
    "        if params.current_task != \"TREC\":\n",
    "            sample = \" \".join(sample).lower().split()\n",
    "        else:\n",
    "            sample = \" \".join(sample).split()\n",
    "        for word in sample:\n",
    "            if word not in vocab:\n",
    "                vocab.add(word)\n",
    "\n",
    "    vocab.add(\"<s>\")\n",
    "    vocab.add(\"<pad>\")\n",
    "    vocab.add(\"<unk>\")\n",
    "    vocab.add(\"</s>\")\n",
    "    # Optional vocab expansion\n",
    "    # params[\"model\"].vocab_expansion(vocab)\n",
    "\n",
    "\n",
    "def batcher(params, batch):\n",
    "    # batch contains list of words\n",
    "    max_tasks = [\"MR\", \"CR\", \"SUBJ\", \"MPQA\", \"ImageCaptionRetrieval\"]\n",
    "    if params.current_task in max_tasks:\n",
    "        strategy = \"max\"\n",
    "    else:\n",
    "        strategy = \"last\"\n",
    "\n",
    "    sentences = [\" \".join(s).lower() for s in batch]\n",
    "    _, embeddings = params[\"model\"].get_representation(\n",
    "        sentences, pool=strategy, return_numpy=True\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 Run SentEval on GenSen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensen_1 = GenSenSingle(\n",
    "    model_folder=model_params[\"folder_path\"],\n",
    "    filename_prefix=model_params[\"prefix_1\"],\n",
    "    pretrained_emb=model_params[\"pretrain\"],\n",
    "    cuda=model_params[\"cuda\"],\n",
    ")\n",
    "gensen_2 = GenSenSingle(\n",
    "    model_folder=model_params[\"folder_path\"],\n",
    "    filename_prefix=model_params[\"prefix_2\"],\n",
    "    pretrained_emb=model_params[\"pretrain\"],\n",
    "    cuda=model_params[\"cuda\"],\n",
    ")\n",
    "gensen = GenSen(gensen_1, gensen_2)\n",
    "\n",
    "ser = SentEvalRunner(path_to_senteval=PATH_TO_SENTEVAL, use_azureml=False)\n",
    "ser.set_transfer_data_path(os.path.join(PATH_TO_SENTEVAL, \"data\"))\n",
    "ser.set_transfer_tasks(transfer_tasks)\n",
    "ser.set_model(gensen)\n",
    "ser.set_params_senteval()\n",
    "results = ser.run(batcher, prepare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print selected metrics from the model's results on the transfer tasks as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = ser.print_mean(results, selected_metrics=[\"pearson\", \"spearman\"])\n",
    "print(eval_metrics.head(eval_metrics.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
