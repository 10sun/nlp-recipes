{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentEval on Local\n",
    "\n",
    "SentEval is a widely used benchmarking tool for evaluating general-purpose sentence embeddings. It provides a simple interface for evaluating your embeddings on up to 17 supported downstream tasks (such as sentiment classification, natural language inference, semantic similarity, etc.)\n",
    "\n",
    "Running SentEval locally is simple. Clone the [repository](https://github.com/facebookresearch/SentEval), follow their setup instructions to get the data for the transfer tasks, and implement two functions `prepare(params, samples)` and `batcher(params, batch)` specific to your model. The authors provide some guidance on how to do this in the [examples](https://github.com/facebookresearch/SentEval/tree/master/examples) directory of their repository. In this notebook we show an example for evaluating the GenSen model on the available STS downstream tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00 Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n",
      "Torch version: 1.0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from utils_nlp.models.gensen.gensen import GenSen, GenSenSingle\n",
    "from utils_nlp.eval.senteval import SentEvalRunner\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Torch version: {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PATH_TO_SENTEVAL = (\n",
    "    \"../../../SentEval\"\n",
    ")  # Set this path to where you have cloned the senteval source code\n",
    "PATH_TO_GENSEN = (\n",
    "    \"../../../gensen\"\n",
    ")  # Set this path to where you have cloned the gensen source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 SentEval Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.insert(0, PATH_TO_SENTEVAL)\n",
    "#import senteval\n",
    "\n",
    "transfer_tasks = [\"STSBenchmark\", \"STS12\", \"STS13\", \"STS14\", \"STS15\", \"STS16\"]\n",
    "params_senteval = {\n",
    "    \"usepytorch\": True,\n",
    "    \"kfold\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 GenSen Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: {\n",
      "    \"folder_path\": \"../../../gensen/data/models\",\n",
      "    \"prefix\": \"nli_large_bothskip\",\n",
      "    \"pretrain\": \"../../../gensen/data/embedding/glove.840B.300d.h5\",\n",
      "    \"cuda\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(PATH_TO_GENSEN)\n",
    "\n",
    "model_params = {}\n",
    "model_params[\"folder_path\"] = os.path.join(PATH_TO_GENSEN, \"data/models\")\n",
    "model_params[\"prefix\"] = \"nli_large_bothskip\"\n",
    "model_params[\"pretrain\"] = os.path.join(\n",
    "    PATH_TO_GENSEN, \"data/embedding/glove.840B.300d.h5\"\n",
    ")\n",
    "model_params[\"cuda\"] = torch.cuda.is_available()\n",
    "\n",
    "print(\"model params: {}\".format(json.dumps(model_params, indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 SentEval Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As specified in the SentEval [repo](https://github.com/facebookresearch/SentEval#how-to-use-senteval), we implement 2 functions:\n",
    "\n",
    "<b>prepare</b> (sees the whole dataset of each task and can thus construct the word vocabulary, the dictionary of word vectors etc)         \n",
    "<b>batcher</b> (transforms a batch of text sentences into sentence embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(params, samples):\n",
    "    vocab = set()\n",
    "    for sample in samples:\n",
    "        if params.current_task != \"TREC\":\n",
    "            sample = \" \".join(sample).lower().split()\n",
    "        else:\n",
    "            sample = \" \".join(sample).split()\n",
    "        for word in sample:\n",
    "            if word not in vocab:\n",
    "                vocab.add(word)\n",
    "\n",
    "    vocab.add(\"<s>\")\n",
    "    vocab.add(\"<pad>\")\n",
    "    vocab.add(\"<unk>\")\n",
    "    vocab.add(\"</s>\")\n",
    "    # Optional vocab expansion\n",
    "    # params[\"model\"].vocab_expansion(vocab)\n",
    "\n",
    "\n",
    "def batcher(params, batch):\n",
    "    # batch contains list of words\n",
    "    max_tasks = [\"MR\", \"CR\", \"SUBJ\", \"MPQA\", \"ImageCaptionRetrieval\"]\n",
    "    if params.current_task in max_tasks:\n",
    "        strategy = \"max\"\n",
    "    else:\n",
    "        strategy = \"last\"\n",
    "\n",
    "    sentences = [\" \".join(s).lower() for s in batch]\n",
    "    _, embeddings = params[\"model\"].get_representation(\n",
    "        sentences, pool=strategy, return_numpy=True\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 Run SentEval on GenSen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensen = GenSenSingle(\n",
    "    model_folder=model_params[\"folder_path\"],\n",
    "    filename_prefix=model_params[\"prefix\"],\n",
    "    pretrained_emb=model_params[\"pretrain\"],\n",
    "    cuda=model_params[\"cuda\"],\n",
    ")\n",
    "\n",
    "ser = SentEvalRunner(path_to_senteval=PATH_TO_SENTEVAL)\n",
    "ser.set_transfer_data_path(\"data\")\n",
    "ser.set_transfer_tasks(transfer_tasks)\n",
    "ser.set_model(gensen)\n",
    "ser.set_params(params_senteval)\n",
    "results = ser.run(batcher, prepare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print selected metrics from the model's results on the transfer tasks as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pearson</th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STSBenchmark</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STS12</th>\n",
       "      <td>0.598</td>\n",
       "      <td>0.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STS13</th>\n",
       "      <td>0.542</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STS14</th>\n",
       "      <td>0.639</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STS15</th>\n",
       "      <td>0.727</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STS16</th>\n",
       "      <td>0.659</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pearson  spearman\n",
       "STSBenchmark    0.778     0.780\n",
       "STS12           0.598     0.603\n",
       "STS13           0.542     0.556\n",
       "STS14           0.639     0.625\n",
       "STS15           0.727     0.729\n",
       "STS16           0.659     0.663"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics = ser.log_mean(results, selected_metrics=[\"pearson\", \"spearman\"])\n",
    "eval_metrics.head(eval_metrics.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": {
        "pearson": {
         "STS12": 0.598,
         "STS13": 0.542,
         "STS14": 0.639,
         "STS15": 0.727,
         "STS16": 0.659,
         "STSBenchmark": 0.778
        },
        "spearman": {
         "STS12": 0.603,
         "STS13": 0.556,
         "STS14": 0.625,
         "STS15": 0.729,
         "STS16": 0.663,
         "STSBenchmark": 0.78
        }
       },
       "encoder": "json",
       "name": "results",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "results"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Persist output to scrapbook\n",
    "sb.glue(\"results\", eval_metrics.to_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_gpu)",
   "language": "python",
   "name": "nlp_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
