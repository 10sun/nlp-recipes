{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenSen Deep Dive on AzureML\n",
    "**Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning** [\\[1\\]](#References)\n",
    "\n",
    "## What is sentence similarity?\n",
    "\n",
    "Sentence similarity or semantic textual similarity deals with determining how similar two pieces of texts are. This can take the form of assigning a score from 1 to 5. Related tasks are parahrase or duplicate identification.\n",
    "\n",
    "## How to evaluate?\n",
    "\n",
    "[SentEval](https://arxiv.org/abs/1803.05449) [\\[2\\]](#References) is an evaluation toolkit for evaluating sentence representations. It includes 17 downstream tasks, including common semantic textual similarity tasks. The semantic textual similarity (**STS**) benchmark tasks from 2012-2016 (STS12, STS13, STS14, STS15, STS16, STSB) measure the relatedness of two sentences based on the cosine similarity of the two representations. The evaluation criterion is Pearson correlation.\n",
    "\n",
    "The SICK relatedness (**SICK-R**) task trains a linear model to output a score from 1 to 5 indicating the relatedness of two sentences. For the same dataset (**SICK-E**) can be treated as a three-class classification problem using the entailment labels (classes are ‘entailment’, ‘contradiction’, and ‘neutral’). The evaluation metric for SICK-R is Pearson correlation and classification accuracy for SICK-E.\n",
    "\n",
    "The Microsoft Research Paraphrase Corpus [(**MRPC**)](https://www.microsoft.com/en-us/download/details.aspx?id=52398) corpus is a paraphrase identification dataset, where systems aim to identify if two sentences are paraphrases of each other. The evaluation metric is classification accuracy and F1.\n",
    "\n",
    "## What is GenSen?\n",
    "\n",
    "GenSen is a technique to learn general purpose, fixed-length representations of sentences via multi-task training. GenSen model is to combine the benefits of diverse sentence-representation learning objectives into a single multi-task framework. This is the first large-scale reusable sentence representation model obtained by combining a set of training objectives with the level of diversity explored here, i.e. multi-lingual NMT, natural language inference, constituency parsing and skip-thought vectors. These representations are useful for transfer and low-resource learning. GenSen is trained on several data sources with multiple training objectives on over 100 milion sentences.\n",
    "\n",
    "The GenSen model is most similar to that of Luong et al. (2015) [\\[4\\]](#References), who train a many-to-many **sequence-to-sequence** model on a diverse set of weakly ralated tasks that includes machine translation, constituency parsing, image captioning, sequence autoencoding, and intra-sentence skip-thoughts. However, there are two key differences. GenSen uses an attention mechanism preventing learning a fixed-length vector representation for a sentence and it aims for learning re-usable sentence representations that transfers elsewhere, as opposed to Luong's work aims for improvements on the same tasks on which the model is trained.\n",
    "\n",
    "### Sequence to Sequence Learning\n",
    "\n",
    "![Sequence to sequence learning examples - (left) machine translation and (right) constituent parsing](https://nlpbp.blob.core.windows.net/images/seq2seq.png)**Sequence to sequence learning examples - (left) machine translation and (right) constituent parsing**\n",
    "\n",
    "Sequence to sequence learning (*seq2seq*) aims to directly model the conditional probability $p(x|y)$ of mapping an input sequence, $x_1,...,x_n$, into an output sequence, $y_1,...,y_m$. It accomplishes such goal through the *encoder-decoder* framework. As illustrated in the above figure, the encoder computes a representation $s$ for each input sequence. Based on that input representation, the *decoder* generates an ouput sequence, one unit at a time, and hence, decomposes the conditional probability as:\n",
    "\n",
    "$$\n",
    "\\log p(y|x)=\\sum_{j=1}^{m} \\log p(y_i|y_{<j}, x, s)\n",
    "$$\n",
    "\n",
    "## Why GenSen?\n",
    "\n",
    "GenSen model performs the state-of-the-art results on multiple datasets, such as MRPC, SICK-R, SICK-E and STS, for sentence similarity. The reported results are as follows compared with other models [\\[3\\]](#References):\n",
    "\n",
    "| Model | MRPC | SICK-R | SICK-E | STS |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| GenSen (Subramanian et al., 2018) | 78.6/84.4 | 0.888 | 87.8 | 78.9/78.6 |\n",
    "| [InferSent](https://arxiv.org/abs/1705.02364) (Conneau et al., 2017) | 76.2/83.1 | 0.884 | 86.3 | 75.8/75.5 |\n",
    "| [TF-KLD](https://www.aclweb.org/anthology/D13-1090) (Ji and Eisenstein, 2013) | 80.4/85.9 | - | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as an introduction to an end-to-end NLP solution for sentence similarity building one of the advanced models - GenSen on AzureML platform. We show the advantages of AzureML when training large NLP models with GPU.\n",
    "\n",
    "Regarding **AzureML**, please refer to:\n",
    "* [Quickstart notebook](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python)\n",
    "* [Hyperdrive](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "0. [Global Settings](#0-Global-Settings)\n",
    "1. [Data Loading and Preprocessing](#1-Data-Loading-and-Preprocessing)    \n",
    "    * 1.1. [Load SNLI Dataset](#1.1-Load-SNLI-Dataset)  \n",
    "    * 1.2. [Tokenize](#1.2-Tokenize)  \n",
    "    * 1.3. [Preprocess for GenSen Model](#1.3-Preprocess-for-GenSen-Model)  \n",
    "    * 1.4. [Upload to Azure Blob Storage](#1.4-Upload-to-Azure-Blob-Storage)  \n",
    "2. [Train GenSen Model with Distributed Pytorch with Horovod on AzureML](#2-Train-GenSen-Model-with-Distributed-Pytorch-with-Horovod-on-AzureML)  \n",
    "    * 2.1. [Initialization](#2.1-Initialization) \n",
    "        * 2.1.1 [Initialize Workspace](#2.1.1-Initialize-Workspace)  \n",
    "        * 2.1.2 [Create or Attach Existing AmlCompute](#2.1.2-Create-or-Attach-Existing-AmlCompute)  \n",
    "    * 2.2. [Settings for GenSen](#2.2-Settings-for-GenSen)  \n",
    "        * 2.2.1 [Access to a Project Directory](#2.2.1-Access-to-a-Project-Directory)  \n",
    "        * 2.2.2 [Access to Datastore](#2.2.2-Access-to-Datastore)  \n",
    "    * 2.3. [Train Model on the Remote Compute](#2.3-Train-Model-on-the-Remote-Compute)  \n",
    "        * 2.3.1 [Prepare Training Script](#2.3.1-Prepare-Training-Script)  \n",
    "        * 2.3.2 [Create an Experiment](#2.3.2-Create-an-Experiment)\n",
    "        * 2.3.3 [Create a PyTorch Estimator](#2.3.3-Create-a-PyTorch-Estimator)\n",
    "        * 2.3.4 [Submit or Cancel a job](#2.3.4-Submit-or-Cancel-a-job)\n",
    "        * 2.3.5 [Monitor your run](#2.3.5-Monitor-your-run)\n",
    "3. [Tune Model Hyperparameters](#3-Tune-Model-Hyperparameters)\n",
    "    * 3.1 [Start a Hyperparameter Sweep](#3.1-Start-a-Hyperparameter-Sweep)\n",
    "    * 3.2 [Monitor HyperDrive runs](#3.2-Monitor-HyperDrive-runs)\n",
    "- [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Global Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Go through the [Configuration](../../../configuration.ipynb) notebook to install the Azure Machine Learning Python SDK and create an Azure ML `Workspace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]\n",
      "Azure ML SDK Version: 1.0.33\n",
      "Pandas version: 0.24.2\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find NLP\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "import os\n",
    "# import papermill as pm\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import azureml as aml\n",
    "import azureml.train.hyperdrive as hd\n",
    "\n",
    "from azureml.telemetry import set_diagnostics_collection\n",
    "from utils_nlp.dataset.preprocess import to_lowercase, to_nltk_tokens\n",
    "from utils_nlp.dataset import snli\n",
    "from utils_nlp.azureml import azureml_utils\n",
    "from utils_nlp.model.gensen.gensen_utils import gensen_preprocess\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Azure ML SDK Version:\", aml.core.VERSION)\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opt-in diagnostics for better experience, quality, and security of future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will\n",
    "1. Download the dataset and load the dataset.\n",
    "2. Tokenize and reshape the dataset for Gensen.\n",
    "3. Upload the training set to the default blob storage of the workspace.\n",
    "\n",
    "We use the [SNLI](https://nlp.stanford.edu/projects/snli/) dataset in this example. For a more detailed walkthrough about data processing jump to [SNLI Data Prep](../data-prep/snli.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the data folder path.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_PATH = '../../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load SNLI Dataset\n",
    "We provide a function `load_pandas_df` which\n",
    "* Downloads the SNLI zipfile at the specified directory location\n",
    "* Extracts the file based on the specified split\n",
    "* Loads the split as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1_binary_parse</th>\n",
       "      <th>sentence2_binary_parse</th>\n",
       "      <th>sentence1_parse</th>\n",
       "      <th>sentence2_parse</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>captionID</th>\n",
       "      <th>pairID</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>label4</th>\n",
       "      <th>label5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
       "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "      <td>3416050480.jpg#4</td>\n",
       "      <td>3416050480.jpg#4r1n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
       "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>3416050480.jpg#4</td>\n",
       "      <td>3416050480.jpg#4r1c</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entailment</td>\n",
       "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
       "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>3416050480.jpg#4</td>\n",
       "      <td>3416050480.jpg#4r1e</td>\n",
       "      <td>entailment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
       "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
       "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
       "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>They are smiling at their parents</td>\n",
       "      <td>2267923837.jpg#2</td>\n",
       "      <td>2267923837.jpg#2r1n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entailment</td>\n",
       "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
       "      <td>( There ( ( are children ) present ) )</td>\n",
       "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
       "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>2267923837.jpg#2</td>\n",
       "      <td>2267923837.jpg#2r1e</td>\n",
       "      <td>entailment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                             sentence1_binary_parse  \\\n",
       "0        neutral  ( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...   \n",
       "1  contradiction  ( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...   \n",
       "2     entailment  ( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...   \n",
       "3        neutral  ( Children ( ( ( smiling and ) waving ) ( at c...   \n",
       "4     entailment  ( Children ( ( ( smiling and ) waving ) ( at c...   \n",
       "\n",
       "                              sentence2_binary_parse  \\\n",
       "0  ( ( A person ) ( ( is ( ( training ( his horse...   \n",
       "1  ( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...   \n",
       "2  ( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...   \n",
       "3  ( They ( are ( smiling ( at ( their parents ) ...   \n",
       "4             ( There ( ( are children ) present ) )   \n",
       "\n",
       "                                     sentence1_parse  \\\n",
       "0  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...   \n",
       "1  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...   \n",
       "2  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...   \n",
       "3  (ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...   \n",
       "4  (ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...   \n",
       "\n",
       "                                     sentence2_parse  \\\n",
       "0  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...   \n",
       "1  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...   \n",
       "2  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...   \n",
       "3  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...   \n",
       "4  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...   \n",
       "\n",
       "                                           sentence1  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "1  A person on a horse jumps over a broken down a...   \n",
       "2  A person on a horse jumps over a broken down a...   \n",
       "3              Children smiling and waving at camera   \n",
       "4              Children smiling and waving at camera   \n",
       "\n",
       "                                           sentence2         captionID  \\\n",
       "0  A person is training his horse for a competition.  3416050480.jpg#4   \n",
       "1      A person is at a diner, ordering an omelette.  3416050480.jpg#4   \n",
       "2                  A person is outdoors, on a horse.  3416050480.jpg#4   \n",
       "3                  They are smiling at their parents  2267923837.jpg#2   \n",
       "4                         There are children present  2267923837.jpg#2   \n",
       "\n",
       "                pairID         label1 label2 label3 label4 label5  \n",
       "0  3416050480.jpg#4r1n        neutral    NaN    NaN    NaN    NaN  \n",
       "1  3416050480.jpg#4r1c  contradiction    NaN    NaN    NaN    NaN  \n",
       "2  3416050480.jpg#4r1e     entailment    NaN    NaN    NaN    NaN  \n",
       "3  2267923837.jpg#2r1n        neutral    NaN    NaN    NaN    NaN  \n",
       "4  2267923837.jpg#2r1e     entailment    NaN    NaN    NaN    NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defaults to txt\n",
    "train = snli.load_pandas_df(BASE_DATA_PATH, file_split=\"train\")\n",
    "\n",
    "#load dataframe from jsonl file format\n",
    "dev = snli.load_pandas_df(BASE_DATA_PATH, file_split=\"dev\")\n",
    "\n",
    "#specify txt format \n",
    "test = snli.load_pandas_df(BASE_DATA_PATH, file_split=\"test\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Tokenize\n",
    "Now that we've loaded the data into a pandas.DataFrame, we can tokenize the sentences.\n",
    "We also clean the data before tokenizing. This includes dropping unneccessary columns and renaming the relevant columns as score, sentence_1, and sentence_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df, file_split):\n",
    "    src_file_path = os.path.join(BASE_DATA_PATH, \"raw/snli_1.0/snli_1.0_{}.txt\".format(file_split))\n",
    "    if not os.path.exists(os.path.join(BASE_DATA_PATH, \"clean/snli_1.0\")):\n",
    "        os.makedirs(os.path.join(BASE_DATA_PATH, \"clean/snli_1.0\"))\n",
    "    dest_file_path = os.path.join(BASE_DATA_PATH, \"clean/snli_1.0/snli_1.0_{}.txt\".format(file_split))\n",
    "    clean_df = snli.clean_snli(src_file_path).dropna() # drop rows with any NaN vals\n",
    "    clean_df.to_csv(dest_file_path)\n",
    "    return clean_df\n",
    "\n",
    "train = clean(train, 'train')\n",
    "dev = clean(dev, 'dev')\n",
    "test = clean(test, 'test')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the clean pandas dataframes, we do lowercase standardization and tokenization. We use the [NLTK](https://www.nltk.org/) library for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lishao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lishao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lishao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "train_tok = to_nltk_tokens(to_lowercase(train))\n",
    "dev_tok = to_nltk_tokens(to_lowercase(dev))\n",
    "test_tok = to_nltk_tokens(to_lowercase(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Preprocess for GenSen Model\n",
    "We need to prepare our data in a specific way in order for the Gensen model to be able to ingest it. We do this by\n",
    "* Saving the tokens for each split in a `snli_1.0_{split}.txt.clean` file, with the sentence pairs and scores tab-separated and the tokens separated by a single space. Since some of the samples have invalid scores (\"-\"), we filter those out and save them separately in a `snli_1.0_{split}.txt.clean.noblank` file.\n",
    "* Saving the tokenized sentence and labels separately, in the form `snli_1.0_{split}.txt.s1.tok` or `snli_1.0_{split}.txt.s2.tok` or `snli_1.0_{split}.txt.lab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lishao\\Project\\Rotation2\\NLP\\data\\clean/snli_1.0/snli_1.0_train.txt\n",
      "C:\\Users\\lishao\\Project\\Rotation2\\NLP\\data\\clean/snli_1.0/snli_1.0_dev.txt\n",
      "C:\\Users\\lishao\\Project\\Rotation2\\NLP\\data\\clean/snli_1.0/snli_1.0_test.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lishao\\\\Project\\\\Rotation2\\\\NLP\\\\data\\\\clean/snli_1.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensen_preprocess(train_tok, dev_tok, test_tok, os.path.abspath(BASE_DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Upload to Azure Blob Storage\n",
    "We make the data accessible remotely by uploading that data from your local machine into Azure. Then it can be accessed for remote training. The datastore is a convenient construct associated with your workspace for you to upload or download data. You can also interact with it from your remote compute targets. It's backed by an Azure Blob storage account.\n",
    "\n",
    "**Note: If you already has all the files under `clean/snli_1.0/` in your default datastorage, you DO NOT need to redo this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(BASE_DATA_PATH, \"clean/snli_1.0/\")\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name, data_folder)\n",
    "\n",
    "ds.upload(src_dir=data_folder, target_path='data/preprocessed', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Train GenSen Model with Distributed Pytorch with Horovod on AzureML\n",
    "In this tutorial, you will train a GenSen model with PyTorch on AML using distributed training across a GPU cluster. This could also be a generic guideline to train models using GPU cluster.\n",
    "\n",
    "Once you've created your workspace and set up your development environment, training a model in Azure Machine Learning involves the following steps:\n",
    "1. Create a remote compute target (note you can also use local computer as compute target)\n",
    "2. Prepare your training data and upload it to datastore\n",
    "3. Create your training script\n",
    "4. Create an Estimator object\n",
    "5. Submit the estimator to an experiment object under the workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Initialization\n",
    "In this section, we will initialize workspace and create a AmlCompute for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Initialize Workspace\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. For instructions on how to do this, see [here](README.md). `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Note, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\n",
      "WARNING - You have logged in. Now let us find all the subscriptions to which you have access...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n",
      "Workspace name: MAIDAPTest\n",
      "Azure region: eastus2\n",
      "Subscription id: 15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\n",
      "Resource group: nlprg\n"
     ]
    }
   ],
   "source": [
    "ws = azureml_utils.get_or_create_workspace(\n",
    "    subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "    resource_group=\"<RESOURCE_GROUP>\",\n",
    "    workspace_name=\"<WORKSPACE_NAME>\",\n",
    "    workspace_region=\"<WORKSPACE_REGION>\"\n",
    ")\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Create or Attach Existing AmlCompute\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, we use Azure ML managed compute ([AmlCompute](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute)) for our remote training compute resource. Specifically, the below code creates an `STANDARD_NC6` GPU cluster that autoscales from `0` to `4` nodes.\n",
    "\n",
    "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace, this code will skip the creation process.\n",
    "\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota.\n",
    "\n",
    "**Use Standard_NC6 for now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'currentNodeCount': 4, 'targetNodeCount': 4, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 4, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-05-31T21:24:32.828000+00:00', 'errors': None, 'creationTime': '2019-05-20T22:09:40.142683+00:00', 'modifiedTime': '2019-05-20T22:10:11.888950+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current AmlCompute. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Settings for GenSen\n",
    "In this section, we set the GenSen code folder and data folder for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Access to a Project Directory\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on.\n",
    "\n",
    "`project_folder` contains all the code you want to submit to AmlCompute to run. The size of the folder can not exceed 300Mb. In GenSen model, it loads large pre-trained embedding files to the model. Thus, we need to save large files in datastore and only uploads code to `project_folder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change the path to where your model code locates.\n",
    "\n",
    "project_folder = '../../utils_nlp/model/gensen/'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Access to Datastore\n",
    "To download some of the data required to train a GenSen model, run the bash file [here](https://github.com/Maluuba/gensen/blob/master/get_data.sh). Make sure to upload all the large files to azure file share. You can access to datastore by using `ds.as_mount()`.\n",
    "\n",
    "**Note: To download data required to train a GenSen model in the original paper, run code [here](https://github.com/Maluuba/gensen/blob/master/get_data.sh). By training on the original datasets (training time around 20 hours), it will reproduce the results in the [paper](https://arxiv.org/abs/1804.00079). For simplicity, we will train on a smaller dataset, which is SNLI preprocessed in [1 Data Loading and Preprocessing](#1-Data-Loading-and-Preprocessing) for showcasing the example.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "ds = Datastore.register_azure_file_share(workspace=ws,\n",
    "                                        datastore_name= 'GenSen',\n",
    "                                        file_share_name='azureml-filestore-792de9d4-7d0a-464c-b40a-58584f23f5ec',\n",
    "                                        account_name='maidaptest3334372853',\n",
    "                                        account_key='p0qz3rO4YWDeRRyhU+aQycW8kD2vvF061OyURSLwwQxkfQmhfch48tC+kFzBdZlJPDR/Jk8JoFxSLxKbUaZ1lQ==')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisites:**\n",
    "\n",
    "Upload the all the files under `data_folder` in [1.4 Upload to Azure Blob Storage](#1.4-Upload-to-Azure-Blob-Storage) to the path `./data/processed/` on the above datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_gensen"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.as_mount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Train model on the Remote Compute\n",
    "Now that we have the AmlCompute ready to go, let's run our distributed training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Prepare Training Script\n",
    "Now you will need to create your training script. In this tutorial, the script for distributed training of GENSEN is already provided for you at `train.py`. In practice, you should be able to take any custom PyTorch training script as is and run it with Azure ML without having to modify your code.\n",
    "\n",
    "However, if you would like to use Azure ML's [metric logging](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#logging) capabilities, you will have to add a small amount of Azure ML logic inside your training script. In this example, at each logging interval, we will log the loss for that minibatch to our Azure ML run.\n",
    "\n",
    "To do so, in `train.py`, we will first access the Azure ML `Run` object within the script:\n",
    "```Python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "Later within the script, we log the loss metric to our run:\n",
    "```Python\n",
    "run.log('loss', loss.item())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Create an Experiment\n",
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this distributed PyTorch tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, get_run\n",
    "\n",
    "experiment_name = 'pytorch-gensen'\n",
    "experiment = Experiment(ws, name=experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Create a PyTorch Estimator\n",
    "The Azure ML SDK's PyTorch estimator enables you to easily submit PyTorch training jobs for both single-node and distributed runs. For more information on the PyTorch estimator, refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-train-pytorch).\n",
    "\n",
    "`sample_config.json` defines all the hyper parameters and paths when training GenSen model. The trained model will be saved in `data/models/example` to Azure Blob Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--config': 'sample_config.json',\n",
    "    '--data_folder': ds.as_mount()}\n",
    "\n",
    "estimator = PyTorch(source_directory=project_folder,\n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='train.py',\n",
    "                    node_count=4,\n",
    "                    process_count_per_node=1,\n",
    "                    distributed_backend='mpi',\n",
    "                    use_gpu=True,\n",
    "                    conda_packages=['scikit-learn=0.20.3']\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code specifies that we will run our training script on `4` nodes, with one worker per node. In order to execute a distributed run using GPU, you must provide the argument `use_gpu=True`. To execute a distributed run using MPI/Horovod, you must provide the argument `distributed_backend='mpi'`. Using this estimator with these settings, PyTorch, Horovod and their dependencies will be installed for you. If you are the first time to create a experiment, it may take longer to set up conda environments under `.azureml/conda_dependencies.yml`. After the first run, it will use the existing conda environments and directly run the code. However, if your script also uses other packages, make sure to install them via the `PyTorch` constructor's `pip_packages` or `conda_packages` parameters. The more required packages are stored in `.azureml/conda_dependencies.yml` file.\n",
    "\n",
    "**Requirements:**\n",
    "- python=3.6.2\n",
    "- numpy=1.15.1\n",
    "- numpy-base=1.15.1\n",
    "- pip=10.0.1\n",
    "- python=3.6.6\n",
    "- python-dateutil=2.7.3\n",
    "- scikit-learn=0.20.3\n",
    "- azureml-defaults\n",
    "- h5py\n",
    "- nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Submit or Cancel a job\n",
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: pytorch-gensen,\n",
      "Id: pytorch-gensen_1559577451_8b3c6f42,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Queued)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cancel the job**\n",
    "\n",
    "It's better to cancel the job manually to make sure you does not waste resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel the job with id.\n",
    "# job_id = \"pytorch-gensen_1555533596_d9cc75fe\"\n",
    "# run = get_run(experiment, job_id)\n",
    "\n",
    "# Cancel jobs.\n",
    "run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Monitor your run\n",
    "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes. You can see that the widget automatically plots and visualizes the loss metric that we logged to the Azure ML run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debca7cb57da4fc0b97c05b973fa0412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can block until the script has completed training before running more code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: pytorch-gensen_1559153095_0e7f4645\n",
      "\n",
      "Streaming azureml-logs/80_driver_log_rank_0.txt\n",
      "===============================================\n",
      "\n",
      "Building vocabulary ...\n",
      "Building common source vocab ...\n",
      "Found existing vocab file. Reloading ...\n",
      "Building target vocabs ...\n",
      "Found existing vocab file. Reloading ...\n",
      "Reloading vocab for snli \n",
      "Fetching sentences ...\n",
      "Processing corpus : 0 task snli \n",
      "Reached end of dataset, reseting file pointer ...\n",
      "Fetching sentences ...\n",
      "Processing corpus : 0 task snli \n",
      "Fetched 1000000 sentences\n",
      "Fetched 1000000 sentences\n",
      "2019-05-29 18:05:35,740 - INFO - Finished creating iterator ...\n",
      "2019-05-29 18:05:35,747 - INFO - Found 19966 words in source : \n",
      "2019-05-29 18:05:35,753 - INFO - Found 30004 target words in task snli \n",
      "2019-05-29 18:05:35,758 - INFO - Model Parameters : \n",
      "2019-05-29 18:05:35,763 - INFO - Task : multi-seq2seq-nli \n",
      "2019-05-29 18:05:35,768 - INFO - Source Word Embedding Dim  : 512\n",
      "2019-05-29 18:05:35,772 - INFO - Target Word Embedding Dim  : 512\n",
      "2019-05-29 18:05:35,777 - INFO - Source RNN Hidden Dim  : 2048\n",
      "2019-05-29 18:05:35,781 - INFO - Target RNN Hidden Dim  : 2048\n",
      "2019-05-29 18:05:35,788 - INFO - Source RNN Bidirectional  : True\n",
      "2019-05-29 18:05:35,792 - INFO - Batch Size : 48 \n",
      "2019-05-29 18:05:35,806 - INFO - Optimizer : adam \n",
      "2019-05-29 18:05:35,844 - INFO - Learning Rate : 0.000100 \n",
      "2019-05-29 18:05:35,849 - INFO - Found 19966 words in src \n",
      "2019-05-29 18:05:35,854 - INFO - Found 30004 words in trg \n",
      "/azureml-envs/azureml_4737f522821717a6daa7464dfd956f84/lib/python3.6/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "2019-05-29 18:05:40,676 - INFO - MultitaskModel(\n",
      "  (src_embedding): Embedding(19966, 512, padding_idx=1)\n",
      "  (encoder): GRU(512, 1024, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (enc_drp): Dropout(p=0.3)\n",
      "  (trg_embedding): ModuleList(\n",
      "    (0): Embedding(30004, 512, padding_idx=1)\n",
      "  )\n",
      "  (decoders): ModuleList(\n",
      "    (0): ConditionalGRU(\n",
      "      (input_weights): Linear(in_features=512, out_features=6144, bias=True)\n",
      "      (hidden_weights): Linear(in_features=2048, out_features=6144, bias=True)\n",
      "      (peep_weights): Linear(in_features=2048, out_features=6144, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder2vocab): ModuleList(\n",
      "    (0): Linear(in_features=2048, out_features=30004, bias=True)\n",
      "  )\n",
      "  (nli_decoder): Sequential(\n",
      "    (0): Dropout(p=0.3)\n",
      "    (1): Linear(in_features=8192, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "2019-05-29 18:05:40,715 - INFO - Could not find model checkpoint, starting afresh\n",
      "2019-05-29 18:05:40,720 - INFO - Commencing Training ...\n",
      "train.py:245: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.)\n",
      "2019-05-29 18:05:40,930 - INFO - ############################\n",
      "2019-05-29 18:05:40,960 - INFO - ##### Evaluating model #####\n",
      "2019-05-29 18:05:40,968 - INFO - ############################\n",
      "/azureml-envs/azureml_4737f522821717a6daa7464dfd956f84/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/azureml-envs/azureml_4737f522821717a6daa7464dfd956f84/lib/python3.6/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "2019-05-29 18:06:57,575 - INFO - snli Validation Loss : 10.312\n",
      "2019-05-29 18:06:57,602 - INFO - Evaluating on NLI\n",
      "train.py:390: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  class_preds = F.softmax(class_logits).data.cpu().numpy().argmax(\n",
      "2019-05-29 18:07:04,824 - INFO - NLI Dev Acc : 0.32930\n",
      "train.py:412: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  class_preds = F.softmax(class_logits).data.cpu().numpy().argmax(\n",
      "2019-05-29 18:07:11,986 - INFO - NLI Test Acc : 0.32736\n",
      "2019-05-29 18:07:12,004 - INFO - ******************************************************\n",
      "/mnt/batch/tasks/shared/LS_root/jobs/maidaptest/azureml/pytorch-gensen_1559153095_0e7f4645/mounts/workspaceblobstore/azureml/pytorch-gensen_1559153095_0e7f4645/utils.py:310: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  torch.LongTensor(sorted_src_lens), volatile=True\n",
      "train.py:316: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.)\n",
      "2019-05-29 18:09:30,890 - INFO - Seq2Seq Examples Processed : 9600 snli Loss : 5.71808 Num snli minibatches : 180\n",
      "2019-05-29 18:09:30,946 - INFO - Round: 200 NLI Epoch : 0 NLI Examples Processed : 1008 NLI Loss : 1.12384\n",
      "2019-05-29 18:09:30,996 - INFO - Average time per mininbatch : 0.69195\n",
      "2019-05-29 18:09:31,032 - INFO - ******************************************************\n",
      "2019-05-29 18:11:39,438 - INFO - Seq2Seq Examples Processed : 19200 snli Loss : 4.66382 Num snli minibatches : 180\n",
      "2019-05-29 18:11:39,514 - INFO - Round: 400 NLI Epoch : 0 NLI Examples Processed : 1968 NLI Loss : 1.08484\n",
      "2019-05-29 18:11:39,521 - INFO - Average time per mininbatch : 0.64192\n",
      "2019-05-29 18:11:39,532 - INFO - ******************************************************\n",
      "2019-05-29 18:13:46,059 - INFO - Seq2Seq Examples Processed : 28800 snli Loss : 4.33601 Num snli minibatches : 180\n",
      "2019-05-29 18:13:46,068 - INFO - Round: 600 NLI Epoch : 0 NLI Examples Processed : 2928 NLI Loss : 1.08472\n",
      "2019-05-29 18:13:46,073 - INFO - Average time per mininbatch : 0.63259\n",
      "2019-05-29 18:13:46,079 - INFO - ******************************************************\n",
      "2019-05-29 18:15:46,846 - INFO - Seq2Seq Examples Processed : 38400 snli Loss : 4.09014 Num snli minibatches : 180\n",
      "2019-05-29 18:15:46,914 - INFO - Round: 800 NLI Epoch : 0 NLI Examples Processed : 3888 NLI Loss : 1.04902\n",
      "2019-05-29 18:15:46,921 - INFO - Average time per mininbatch : 0.60379\n",
      "2019-05-29 18:15:46,928 - INFO - ******************************************************\n",
      "2019-05-29 18:17:46,728 - INFO - Seq2Seq Examples Processed : 48000 snli Loss : 3.93451 Num snli minibatches : 180\n",
      "2019-05-29 18:17:46,761 - INFO - Round: 1000 NLI Epoch : 0 NLI Examples Processed : 4848 NLI Loss : 1.04646\n",
      "2019-05-29 18:17:46,797 - INFO - Average time per mininbatch : 0.59882\n",
      "2019-05-29 18:17:46,806 - INFO - ******************************************************\n",
      "2019-05-29 18:19:45,026 - INFO - Seq2Seq Examples Processed : 57600 snli Loss : 3.80465 Num snli minibatches : 180\n",
      "2019-05-29 18:19:45,059 - INFO - Round: 1200 NLI Epoch : 0 NLI Examples Processed : 5808 NLI Loss : 1.03508\n",
      "2019-05-29 18:19:45,066 - INFO - Average time per mininbatch : 0.59106\n",
      "2019-05-29 18:19:45,101 - INFO - ******************************************************\n",
      "2019-05-29 18:21:41,592 - INFO - Seq2Seq Examples Processed : 67200 snli Loss : 3.69689 Num snli minibatches : 180\n",
      "2019-05-29 18:21:41,609 - INFO - Round: 1400 NLI Epoch : 0 NLI Examples Processed : 6768 NLI Loss : 1.01259\n",
      "2019-05-29 18:21:41,615 - INFO - Average time per mininbatch : 0.58242\n",
      "2019-05-29 18:21:41,621 - INFO - ******************************************************\n",
      "2019-05-29 18:23:37,792 - INFO - Seq2Seq Examples Processed : 76800 snli Loss : 3.63456 Num snli minibatches : 180\n",
      "2019-05-29 18:23:37,801 - INFO - Round: 1600 NLI Epoch : 0 NLI Examples Processed : 7728 NLI Loss : 1.01536\n",
      "2019-05-29 18:23:37,807 - INFO - Average time per mininbatch : 0.58082\n",
      "2019-05-29 18:23:37,813 - INFO - ******************************************************\n",
      "2019-05-29 18:25:31,047 - INFO - Seq2Seq Examples Processed : 86400 snli Loss : 3.66306 Num snli minibatches : 180\n",
      "2019-05-29 18:25:31,251 - INFO - Round: 1800 NLI Epoch : 0 NLI Examples Processed : 8688 NLI Loss : 0.98221\n",
      "2019-05-29 18:25:31,264 - INFO - Average time per mininbatch : 0.56610\n",
      "2019-05-29 18:25:31,270 - INFO - ******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29 18:27:25,602 - INFO - Seq2Seq Examples Processed : 96000 snli Loss : 3.44516 Num snli minibatches : 180\n",
      "2019-05-29 18:27:25,708 - INFO - Round: 2000 NLI Epoch : 0 NLI Examples Processed : 9648 NLI Loss : 0.99616\n",
      "2019-05-29 18:27:25,714 - INFO - Average time per mininbatch : 0.57163\n",
      "2019-05-29 18:27:25,728 - INFO - ******************************************************\n",
      "2019-05-29 18:29:17,873 - INFO - Seq2Seq Examples Processed : 105600 snli Loss : 3.59119 Num snli minibatches : 180\n",
      "2019-05-29 18:29:17,894 - INFO - Round: 2200 NLI Epoch : 0 NLI Examples Processed : 10608 NLI Loss : 0.99196\n",
      "2019-05-29 18:29:17,899 - INFO - Average time per mininbatch : 0.56068\n",
      "2019-05-29 18:29:17,951 - INFO - ******************************************************\n",
      "2019-05-29 18:31:09,519 - INFO - Seq2Seq Examples Processed : 115200 snli Loss : 3.35993 Num snli minibatches : 180\n",
      "2019-05-29 18:31:09,529 - INFO - Round: 2400 NLI Epoch : 0 NLI Examples Processed : 11568 NLI Loss : 0.98847\n",
      "2019-05-29 18:31:09,538 - INFO - Average time per mininbatch : 0.55776\n",
      "2019-05-29 18:31:09,554 - INFO - ******************************************************\n",
      "2019-05-29 18:33:01,925 - INFO - Seq2Seq Examples Processed : 124800 snli Loss : 3.48944 Num snli minibatches : 180\n",
      "2019-05-29 18:33:01,960 - INFO - Round: 2600 NLI Epoch : 0 NLI Examples Processed : 12528 NLI Loss : 0.98408\n",
      "2019-05-29 18:33:01,966 - INFO - Average time per mininbatch : 0.56180\n",
      "2019-05-29 18:33:01,973 - INFO - ******************************************************\n",
      "2019-05-29 18:34:50,796 - INFO - Seq2Seq Examples Processed : 134400 snli Loss : 3.44262 Num snli minibatches : 180\n",
      "2019-05-29 18:34:50,847 - INFO - Round: 2800 NLI Epoch : 0 NLI Examples Processed : 13488 NLI Loss : 0.91956\n",
      "2019-05-29 18:34:50,852 - INFO - Average time per mininbatch : 0.54408\n",
      "2019-05-29 18:34:50,858 - INFO - ******************************************************\n",
      "2019-05-29 18:36:42,178 - INFO - Seq2Seq Examples Processed : 144000 snli Loss : 3.24111 Num snli minibatches : 180\n",
      "2019-05-29 18:36:42,187 - INFO - Round: 3000 NLI Epoch : 0 NLI Examples Processed : 14448 NLI Loss : 0.94733\n",
      "2019-05-29 18:36:42,193 - INFO - Average time per mininbatch : 0.55657\n",
      "2019-05-29 18:36:42,201 - INFO - ******************************************************\n",
      "2019-05-29 18:38:31,432 - INFO - Seq2Seq Examples Processed : 153600 snli Loss : 3.39076 Num snli minibatches : 180\n",
      "2019-05-29 18:38:31,441 - INFO - Round: 3200 NLI Epoch : 0 NLI Examples Processed : 15408 NLI Loss : 0.96010\n",
      "2019-05-29 18:38:31,447 - INFO - Average time per mininbatch : 0.54612\n",
      "2019-05-29 18:38:31,453 - INFO - ******************************************************\n",
      "2019-05-29 18:40:20,337 - INFO - Seq2Seq Examples Processed : 163200 snli Loss : 3.34304 Num snli minibatches : 180\n",
      "2019-05-29 18:40:20,352 - INFO - Round: 3400 NLI Epoch : 0 NLI Examples Processed : 16368 NLI Loss : 0.90768\n",
      "2019-05-29 18:40:20,359 - INFO - Average time per mininbatch : 0.54439\n",
      "2019-05-29 18:40:20,365 - INFO - ******************************************************\n",
      "2019-05-29 18:42:09,816 - INFO - Seq2Seq Examples Processed : 172800 snli Loss : 3.15766 Num snli minibatches : 180\n",
      "2019-05-29 18:42:09,828 - INFO - Round: 3600 NLI Epoch : 0 NLI Examples Processed : 17328 NLI Loss : 0.90791\n",
      "2019-05-29 18:42:09,834 - INFO - Average time per mininbatch : 0.54722\n",
      "2019-05-29 18:42:09,840 - INFO - ******************************************************\n",
      "2019-05-29 18:43:56,758 - INFO - Seq2Seq Examples Processed : 182400 snli Loss : 3.26524 Num snli minibatches : 180\n",
      "2019-05-29 18:43:56,786 - INFO - Round: 3800 NLI Epoch : 0 NLI Examples Processed : 18288 NLI Loss : 0.92823\n",
      "2019-05-29 18:43:56,795 - INFO - Average time per mininbatch : 0.53455\n",
      "2019-05-29 18:43:56,802 - INFO - ******************************************************\n",
      "2019-05-29 18:45:44,253 - INFO - Seq2Seq Examples Processed : 192000 snli Loss : 3.32298 Num snli minibatches : 180\n",
      "2019-05-29 18:45:44,336 - INFO - Round: 4000 NLI Epoch : 0 NLI Examples Processed : 19248 NLI Loss : 0.85748\n",
      "2019-05-29 18:45:44,343 - INFO - Average time per mininbatch : 0.53723\n",
      "2019-05-29 18:45:44,349 - INFO - ******************************************************\n",
      "2019-05-29 18:47:30,880 - INFO - Seq2Seq Examples Processed : 201600 snli Loss : 3.16485 Num snli minibatches : 180\n",
      "2019-05-29 18:47:30,896 - INFO - Round: 4200 NLI Epoch : 0 NLI Examples Processed : 20208 NLI Loss : 0.90056\n",
      "2019-05-29 18:47:30,901 - INFO - Average time per mininbatch : 0.53256\n",
      "2019-05-29 18:47:30,907 - INFO - ******************************************************\n",
      "2019-05-29 18:49:18,536 - INFO - Seq2Seq Examples Processed : 211200 snli Loss : 3.05513 Num snli minibatches : 180\n",
      "2019-05-29 18:49:18,567 - INFO - Round: 4400 NLI Epoch : 0 NLI Examples Processed : 21168 NLI Loss : 0.86934\n",
      "2019-05-29 18:49:18,579 - INFO - Average time per mininbatch : 0.53807\n",
      "2019-05-29 18:49:18,584 - INFO - ******************************************************\n",
      "2019-05-29 18:51:04,240 - INFO - Seq2Seq Examples Processed : 220800 snli Loss : 3.24391 Num snli minibatches : 180\n",
      "2019-05-29 18:51:04,358 - INFO - Round: 4600 NLI Epoch : 0 NLI Examples Processed : 22128 NLI Loss : 0.84865\n",
      "2019-05-29 18:51:04,365 - INFO - Average time per mininbatch : 0.52824\n",
      "2019-05-29 18:51:04,414 - INFO - ******************************************************\n",
      "2019-05-29 18:52:50,226 - INFO - Seq2Seq Examples Processed : 230400 snli Loss : 3.25106 Num snli minibatches : 180\n",
      "2019-05-29 18:52:50,268 - INFO - Round: 4800 NLI Epoch : 0 NLI Examples Processed : 23088 NLI Loss : 0.87072\n",
      "2019-05-29 18:52:50,276 - INFO - Average time per mininbatch : 0.52897\n",
      "2019-05-29 18:52:50,292 - INFO - ******************************************************\n",
      "2019-05-29 18:54:35,638 - INFO - Seq2Seq Examples Processed : 240000 snli Loss : 3.06245 Num snli minibatches : 180\n",
      "2019-05-29 18:54:35,664 - INFO - Round: 5000 NLI Epoch : 0 NLI Examples Processed : 24048 NLI Loss : 0.84427\n",
      "2019-05-29 18:54:35,670 - INFO - Average time per mininbatch : 0.52669\n",
      "2019-05-29 18:54:35,677 - INFO - ******************************************************\n",
      "2019-05-29 18:56:21,116 - INFO - Seq2Seq Examples Processed : 249600 snli Loss : 2.99545 Num snli minibatches : 180\n",
      "2019-05-29 18:56:21,167 - INFO - Round: 5200 NLI Epoch : 0 NLI Examples Processed : 25008 NLI Loss : 0.89375\n",
      "2019-05-29 18:56:21,172 - INFO - Average time per mininbatch : 0.52716\n",
      "2019-05-29 18:56:21,178 - INFO - ******************************************************\n",
      "2019-05-29 18:58:03,355 - INFO - Seq2Seq Examples Processed : 259200 snli Loss : 3.12514 Num snli minibatches : 180\n",
      "2019-05-29 18:58:03,377 - INFO - Round: 5400 NLI Epoch : 0 NLI Examples Processed : 25968 NLI Loss : 0.84170\n",
      "2019-05-29 18:58:03,383 - INFO - Average time per mininbatch : 0.51073\n",
      "2019-05-29 18:58:03,389 - INFO - ******************************************************\n",
      "2019-05-29 18:59:45,907 - INFO - Seq2Seq Examples Processed : 268800 snli Loss : 3.13727 Num snli minibatches : 180\n",
      "2019-05-29 18:59:45,929 - INFO - Round: 5600 NLI Epoch : 0 NLI Examples Processed : 26928 NLI Loss : 0.85129\n",
      "2019-05-29 18:59:45,947 - INFO - Average time per mininbatch : 0.51247\n",
      "2019-05-29 18:59:45,953 - INFO - ******************************************************\n",
      "2019-05-29 19:01:28,814 - INFO - Seq2Seq Examples Processed : 278400 snli Loss : 3.08039 Num snli minibatches : 180\n",
      "2019-05-29 19:01:28,851 - INFO - Round: 5800 NLI Epoch : 0 NLI Examples Processed : 27888 NLI Loss : 0.86816\n",
      "2019-05-29 19:01:28,857 - INFO - Average time per mininbatch : 0.51426\n",
      "2019-05-29 19:01:28,863 - INFO - ******************************************************\n",
      "2019-05-29 19:03:09,420 - INFO - Seq2Seq Examples Processed : 288000 snli Loss : 2.87723 Num snli minibatches : 180\n",
      "2019-05-29 19:03:09,452 - INFO - Round: 6000 NLI Epoch : 0 NLI Examples Processed : 28848 NLI Loss : 0.84560\n",
      "2019-05-29 19:03:09,458 - INFO - Average time per mininbatch : 0.50258\n",
      "2019-05-29 19:03:09,464 - INFO - ******************************************************\n",
      "2019-05-29 19:04:52,208 - INFO - Seq2Seq Examples Processed : 297600 snli Loss : 2.91778 Num snli minibatches : 180\n",
      "2019-05-29 19:04:52,251 - INFO - Round: 6200 NLI Epoch : 0 NLI Examples Processed : 29808 NLI Loss : 0.81515\n",
      "2019-05-29 19:04:52,257 - INFO - Average time per mininbatch : 0.51368\n",
      "2019-05-29 19:04:52,264 - INFO - ******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29 19:06:32,652 - INFO - Seq2Seq Examples Processed : 307200 snli Loss : 3.07575 Num snli minibatches : 180\n",
      "2019-05-29 19:06:32,708 - INFO - Round: 6400 NLI Epoch : 0 NLI Examples Processed : 30768 NLI Loss : 0.78086\n",
      "2019-05-29 19:06:32,715 - INFO - Average time per mininbatch : 0.50191\n",
      "2019-05-29 19:06:32,722 - INFO - ******************************************************\n",
      "2019-05-29 19:08:12,195 - INFO - Seq2Seq Examples Processed : 316800 snli Loss : 3.01557 Num snli minibatches : 180\n",
      "2019-05-29 19:08:12,203 - INFO - Round: 6600 NLI Epoch : 0 NLI Examples Processed : 31728 NLI Loss : 0.85198\n",
      "2019-05-29 19:08:12,225 - INFO - Average time per mininbatch : 0.49733\n",
      "2019-05-29 19:08:12,255 - INFO - ******************************************************\n",
      "2019-05-29 19:09:50,561 - INFO - Seq2Seq Examples Processed : 326400 snli Loss : 3.01893 Num snli minibatches : 180\n",
      "2019-05-29 19:09:50,631 - INFO - Round: 6800 NLI Epoch : 0 NLI Examples Processed : 32688 NLI Loss : 0.79130\n",
      "2019-05-29 19:09:50,637 - INFO - Average time per mininbatch : 0.49149\n",
      "2019-05-29 19:09:50,642 - INFO - ******************************************************\n",
      "2019-05-29 19:11:31,019 - INFO - Seq2Seq Examples Processed : 336000 snli Loss : 2.80379 Num snli minibatches : 180\n",
      "2019-05-29 19:11:31,070 - INFO - Round: 7000 NLI Epoch : 0 NLI Examples Processed : 33648 NLI Loss : 0.84067\n",
      "2019-05-29 19:11:31,077 - INFO - Average time per mininbatch : 0.50185\n",
      "2019-05-29 19:11:31,085 - INFO - ******************************************************\n",
      "2019-05-29 19:13:10,680 - INFO - Seq2Seq Examples Processed : 345600 snli Loss : 2.75945 Num snli minibatches : 180\n",
      "2019-05-29 19:13:10,708 - INFO - Round: 7200 NLI Epoch : 0 NLI Examples Processed : 34608 NLI Loss : 0.81463\n",
      "2019-05-29 19:13:10,714 - INFO - Average time per mininbatch : 0.49794\n",
      "2019-05-29 19:13:10,719 - INFO - ******************************************************\n",
      "2019-05-29 19:14:48,873 - INFO - Seq2Seq Examples Processed : 355200 snli Loss : 2.88910 Num snli minibatches : 180\n",
      "2019-05-29 19:14:49,171 - INFO - Round: 7400 NLI Epoch : 0 NLI Examples Processed : 35568 NLI Loss : 0.82873\n",
      "2019-05-29 19:14:49,181 - INFO - Average time per mininbatch : 0.49074\n",
      "2019-05-29 19:14:49,186 - INFO - ******************************************************\n",
      "2019-05-29 19:16:26,470 - INFO - Seq2Seq Examples Processed : 364800 snli Loss : 3.01164 Num snli minibatches : 180\n",
      "2019-05-29 19:16:26,532 - INFO - Round: 7600 NLI Epoch : 0 NLI Examples Processed : 36528 NLI Loss : 0.79707\n",
      "2019-05-29 19:16:26,538 - INFO - Average time per mininbatch : 0.48639\n",
      "2019-05-29 19:16:26,547 - INFO - ******************************************************\n",
      "2019-05-29 19:18:04,600 - INFO - Seq2Seq Examples Processed : 374400 snli Loss : 2.97503 Num snli minibatches : 180\n",
      "2019-05-29 19:18:04,627 - INFO - Round: 7800 NLI Epoch : 0 NLI Examples Processed : 37488 NLI Loss : 0.81165\n",
      "2019-05-29 19:18:04,633 - INFO - Average time per mininbatch : 0.49024\n",
      "2019-05-29 19:18:04,638 - INFO - ******************************************************\n",
      "2019-05-29 19:19:42,343 - INFO - Seq2Seq Examples Processed : 384000 snli Loss : 2.95044 Num snli minibatches : 180\n",
      "2019-05-29 19:19:42,383 - INFO - Round: 8000 NLI Epoch : 0 NLI Examples Processed : 38448 NLI Loss : 0.77696\n",
      "2019-05-29 19:19:42,388 - INFO - Average time per mininbatch : 0.48847\n",
      "2019-05-29 19:19:42,393 - INFO - ******************************************************\n",
      "2019-05-29 19:21:20,043 - INFO - Seq2Seq Examples Processed : 393600 snli Loss : 2.77445 Num snli minibatches : 180\n",
      "2019-05-29 19:21:20,059 - INFO - Round: 8200 NLI Epoch : 0 NLI Examples Processed : 39408 NLI Loss : 0.83046\n",
      "2019-05-29 19:21:20,094 - INFO - Average time per mininbatch : 0.48821\n",
      "2019-05-29 19:21:20,099 - INFO - ******************************************************\n",
      "2019-05-29 19:22:57,666 - INFO - Seq2Seq Examples Processed : 403200 snli Loss : 2.74390 Num snli minibatches : 180\n",
      "2019-05-29 19:22:57,687 - INFO - Round: 8400 NLI Epoch : 0 NLI Examples Processed : 40368 NLI Loss : 0.79176\n",
      "2019-05-29 19:22:57,694 - INFO - Average time per mininbatch : 0.48760\n",
      "2019-05-29 19:22:57,700 - INFO - ******************************************************\n",
      "2019-05-29 19:24:36,064 - INFO - Seq2Seq Examples Processed : 412800 snli Loss : 2.70470 Num snli minibatches : 180\n",
      "2019-05-29 19:24:36,084 - INFO - Round: 8600 NLI Epoch : 0 NLI Examples Processed : 41328 NLI Loss : 0.78364\n",
      "2019-05-29 19:24:36,104 - INFO - Average time per mininbatch : 0.49178\n",
      "2019-05-29 19:24:36,110 - INFO - ******************************************************\n",
      "2019-05-29 19:26:12,557 - INFO - Seq2Seq Examples Processed : 422400 snli Loss : 2.89966 Num snli minibatches : 180\n",
      "2019-05-29 19:26:12,568 - INFO - Round: 8800 NLI Epoch : 0 NLI Examples Processed : 42288 NLI Loss : 0.79969\n",
      "2019-05-29 19:26:12,573 - INFO - Average time per mininbatch : 0.48220\n",
      "2019-05-29 19:26:12,578 - INFO - ******************************************************\n",
      "2019-05-29 19:27:48,184 - INFO - Seq2Seq Examples Processed : 432000 snli Loss : 2.89469 Num snli minibatches : 180\n",
      "2019-05-29 19:27:48,205 - INFO - Round: 9000 NLI Epoch : 0 NLI Examples Processed : 43248 NLI Loss : 0.81662\n",
      "2019-05-29 19:27:48,211 - INFO - Average time per mininbatch : 0.47799\n",
      "2019-05-29 19:27:48,216 - INFO - ******************************************************\n",
      "2019-05-29 19:29:24,910 - INFO - Seq2Seq Examples Processed : 441600 snli Loss : 2.87607 Num snli minibatches : 180\n",
      "2019-05-29 19:29:25,067 - INFO - Round: 9200 NLI Epoch : 0 NLI Examples Processed : 44208 NLI Loss : 0.77653\n",
      "2019-05-29 19:29:25,079 - INFO - Average time per mininbatch : 0.48344\n",
      "2019-05-29 19:29:25,085 - INFO - ******************************************************\n",
      "2019-05-29 19:31:00,670 - INFO - Seq2Seq Examples Processed : 451200 snli Loss : 2.85335 Num snli minibatches : 180\n",
      "2019-05-29 19:31:00,678 - INFO - Round: 9400 NLI Epoch : 0 NLI Examples Processed : 45168 NLI Loss : 0.75379\n",
      "2019-05-29 19:31:00,686 - INFO - Average time per mininbatch : 0.47779\n",
      "2019-05-29 19:31:00,693 - INFO - ******************************************************\n",
      "2019-05-29 19:32:37,261 - INFO - Seq2Seq Examples Processed : 460800 snli Loss : 2.80405 Num snli minibatches : 180\n",
      "2019-05-29 19:32:37,285 - INFO - Round: 9600 NLI Epoch : 0 NLI Examples Processed : 46128 NLI Loss : 0.77045\n",
      "2019-05-29 19:32:37,291 - INFO - Average time per mininbatch : 0.48279\n",
      "2019-05-29 19:32:37,327 - INFO - ******************************************************\n",
      "2019-05-29 19:34:13,404 - INFO - Seq2Seq Examples Processed : 470400 snli Loss : 2.63074 Num snli minibatches : 180\n",
      "2019-05-29 19:34:13,452 - INFO - Round: 9800 NLI Epoch : 0 NLI Examples Processed : 47088 NLI Loss : 0.79249\n",
      "2019-05-29 19:34:13,480 - INFO - Average time per mininbatch : 0.48036\n",
      "2019-05-29 19:34:13,485 - INFO - ******************************************************\n",
      "2019-05-29 19:35:50,016 - INFO - Seq2Seq Examples Processed : 480000 snli Loss : 2.62458 Num snli minibatches : 180\n",
      "2019-05-29 19:35:50,054 - INFO - Round: 10000 NLI Epoch : 0 NLI Examples Processed : 48048 NLI Loss : 0.82520\n",
      "2019-05-29 19:35:50,060 - INFO - Average time per mininbatch : 0.48262\n",
      "2019-05-29 19:35:50,065 - INFO - ******************************************************\n",
      "2019-05-29 19:37:25,555 - INFO - Seq2Seq Examples Processed : 489600 snli Loss : 2.61139 Num snli minibatches : 180\n",
      "2019-05-29 19:37:25,621 - INFO - Round: 10200 NLI Epoch : 0 NLI Examples Processed : 49008 NLI Loss : 0.79771\n",
      "2019-05-29 19:37:25,636 - INFO - Average time per mininbatch : 0.47742\n",
      "2019-05-29 19:37:25,672 - INFO - ******************************************************\n",
      "2019-05-29 19:39:00,465 - INFO - Seq2Seq Examples Processed : 499200 snli Loss : 2.85354 Num snli minibatches : 180\n",
      "2019-05-29 19:39:00,485 - INFO - Round: 10400 NLI Epoch : 0 NLI Examples Processed : 49968 NLI Loss : 0.75161\n",
      "2019-05-29 19:39:00,515 - INFO - Average time per mininbatch : 0.47392\n",
      "2019-05-29 19:39:00,521 - INFO - ******************************************************\n",
      "2019-05-29 19:40:35,133 - INFO - Seq2Seq Examples Processed : 508800 snli Loss : 2.81737 Num snli minibatches : 180\n",
      "2019-05-29 19:40:35,153 - INFO - Round: 10600 NLI Epoch : 0 NLI Examples Processed : 50928 NLI Loss : 0.76678\n",
      "2019-05-29 19:40:35,183 - INFO - Average time per mininbatch : 0.47303\n",
      "2019-05-29 19:40:35,191 - INFO - ******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29 19:42:10,143 - INFO - Seq2Seq Examples Processed : 518400 snli Loss : 2.81220 Num snli minibatches : 180\n",
      "2019-05-29 19:42:10,181 - INFO - Round: 10800 NLI Epoch : 0 NLI Examples Processed : 51888 NLI Loss : 0.80043\n",
      "2019-05-29 19:42:10,186 - INFO - Average time per mininbatch : 0.47473\n",
      "2019-05-29 19:42:10,191 - INFO - ******************************************************\n",
      "2019-05-29 19:43:45,532 - INFO - Seq2Seq Examples Processed : 528000 snli Loss : 2.79347 Num snli minibatches : 180\n",
      "2019-05-29 19:43:45,556 - INFO - Round: 11000 NLI Epoch : 0 NLI Examples Processed : 52848 NLI Loss : 0.76758\n",
      "2019-05-29 19:43:45,561 - INFO - Average time per mininbatch : 0.47667\n",
      "2019-05-29 19:43:45,566 - INFO - ******************************************************\n",
      "2019-05-29 19:45:19,931 - INFO - Seq2Seq Examples Processed : 537600 snli Loss : 2.77058 Num snli minibatches : 180\n",
      "2019-05-29 19:45:19,940 - INFO - Round: 11200 NLI Epoch : 0 NLI Examples Processed : 53808 NLI Loss : 0.75474\n",
      "2019-05-29 19:45:19,947 - INFO - Average time per mininbatch : 0.47179\n",
      "2019-05-29 19:45:19,952 - INFO - ******************************************************\n",
      "2019-05-29 19:46:54,122 - INFO - Seq2Seq Examples Processed : 547200 snli Loss : 2.57868 Num snli minibatches : 180\n",
      "2019-05-29 19:46:54,202 - INFO - Round: 11400 NLI Epoch : 0 NLI Examples Processed : 54768 NLI Loss : 0.72065\n",
      "2019-05-29 19:46:54,207 - INFO - Average time per mininbatch : 0.47081\n",
      "2019-05-29 19:46:54,212 - INFO - ******************************************************\n",
      "2019-05-29 19:48:27,836 - INFO - Seq2Seq Examples Processed : 556800 snli Loss : 2.53883 Num snli minibatches : 180\n",
      "2019-05-29 19:48:27,866 - INFO - Round: 11600 NLI Epoch : 0 NLI Examples Processed : 55728 NLI Loss : 0.74271\n",
      "2019-05-29 19:48:27,872 - INFO - Average time per mininbatch : 0.46808\n",
      "2019-05-29 19:48:27,901 - INFO - ******************************************************\n",
      "2019-05-29 19:50:04,260 - INFO - Seq2Seq Examples Processed : 566400 snli Loss : 2.56377 Num snli minibatches : 180\n",
      "2019-05-29 19:50:04,275 - INFO - Round: 11800 NLI Epoch : 0 NLI Examples Processed : 56688 NLI Loss : 0.70260\n",
      "2019-05-29 19:50:04,280 - INFO - Average time per mininbatch : 0.48162\n",
      "2019-05-29 19:50:04,285 - INFO - ******************************************************\n",
      "2019-05-29 19:51:39,188 - INFO - Seq2Seq Examples Processed : 576000 snli Loss : 2.57128 Num snli minibatches : 180\n",
      "2019-05-29 19:51:39,237 - INFO - Round: 12000 NLI Epoch : 0 NLI Examples Processed : 57648 NLI Loss : 0.75922\n",
      "2019-05-29 19:51:39,246 - INFO - Average time per mininbatch : 0.47448\n",
      "2019-05-29 19:51:39,280 - INFO - ******************************************************\n",
      "2019-05-29 19:53:11,436 - INFO - Seq2Seq Examples Processed : 585600 snli Loss : 2.81611 Num snli minibatches : 180\n",
      "2019-05-29 19:53:11,510 - INFO - Round: 12200 NLI Epoch : 0 NLI Examples Processed : 58608 NLI Loss : 0.76561\n",
      "2019-05-29 19:53:11,545 - INFO - Average time per mininbatch : 0.46075\n",
      "2019-05-29 19:53:11,554 - INFO - ******************************************************\n",
      "2019-05-29 19:54:42,824 - INFO - Seq2Seq Examples Processed : 595200 snli Loss : 2.78098 Num snli minibatches : 180\n",
      "2019-05-29 19:54:42,867 - INFO - Round: 12400 NLI Epoch : 0 NLI Examples Processed : 59568 NLI Loss : 0.73193\n",
      "2019-05-29 19:54:42,875 - INFO - Average time per mininbatch : 0.45632\n",
      "2019-05-29 19:54:42,881 - INFO - ******************************************************\n",
      "2019-05-29 19:56:14,538 - INFO - Seq2Seq Examples Processed : 604800 snli Loss : 2.75304 Num snli minibatches : 180\n",
      "2019-05-29 19:56:14,596 - INFO - Round: 12600 NLI Epoch : 0 NLI Examples Processed : 60528 NLI Loss : 0.75785\n",
      "2019-05-29 19:56:14,602 - INFO - Average time per mininbatch : 0.45825\n",
      "2019-05-29 19:56:14,609 - INFO - ******************************************************\n",
      "2019-05-29 19:57:47,344 - INFO - Seq2Seq Examples Processed : 614400 snli Loss : 2.76325 Num snli minibatches : 180\n",
      "2019-05-29 19:57:47,364 - INFO - Round: 12800 NLI Epoch : 0 NLI Examples Processed : 61488 NLI Loss : 0.75488\n",
      "2019-05-29 19:57:47,412 - INFO - Average time per mininbatch : 0.46364\n",
      "2019-05-29 19:57:47,418 - INFO - ******************************************************\n",
      "2019-05-29 19:59:19,095 - INFO - Seq2Seq Examples Processed : 624000 snli Loss : 2.70555 Num snli minibatches : 180\n",
      "2019-05-29 19:59:19,135 - INFO - Round: 13000 NLI Epoch : 0 NLI Examples Processed : 62448 NLI Loss : 0.73895\n",
      "2019-05-29 19:59:19,145 - INFO - Average time per mininbatch : 0.45835\n",
      "2019-05-29 19:59:19,150 - INFO - ******************************************************\n",
      "2019-05-29 20:00:51,249 - INFO - Seq2Seq Examples Processed : 633600 snli Loss : 2.60308 Num snli minibatches : 180\n",
      "2019-05-29 20:00:51,287 - INFO - Round: 13200 NLI Epoch : 0 NLI Examples Processed : 63408 NLI Loss : 0.74067\n",
      "2019-05-29 20:00:51,297 - INFO - Average time per mininbatch : 0.46046\n",
      "2019-05-29 20:00:51,303 - INFO - ******************************************************\n",
      "2019-05-29 20:02:22,456 - INFO - Seq2Seq Examples Processed : 643200 snli Loss : 2.48930 Num snli minibatches : 180\n",
      "2019-05-29 20:02:22,536 - INFO - Round: 13400 NLI Epoch : 0 NLI Examples Processed : 64368 NLI Loss : 0.76212\n",
      "2019-05-29 20:02:22,542 - INFO - Average time per mininbatch : 0.45573\n",
      "2019-05-29 20:02:22,570 - INFO - ******************************************************\n",
      "2019-05-29 20:03:54,309 - INFO - Seq2Seq Examples Processed : 652800 snli Loss : 2.49109 Num snli minibatches : 180\n",
      "2019-05-29 20:03:54,334 - INFO - Round: 13600 NLI Epoch : 0 NLI Examples Processed : 65328 NLI Loss : 0.72918\n",
      "2019-05-29 20:03:54,342 - INFO - Average time per mininbatch : 0.45853\n",
      "2019-05-29 20:03:54,361 - INFO - ******************************************************\n",
      "2019-05-29 20:05:26,473 - INFO - Seq2Seq Examples Processed : 662400 snli Loss : 2.49999 Num snli minibatches : 180\n",
      "2019-05-29 20:05:26,500 - INFO - Round: 13800 NLI Epoch : 0 NLI Examples Processed : 66288 NLI Loss : 0.71488\n",
      "2019-05-29 20:05:26,531 - INFO - Average time per mininbatch : 0.46042\n",
      "2019-05-29 20:05:26,539 - INFO - ******************************************************\n",
      "2019-05-29 20:06:58,271 - INFO - Seq2Seq Examples Processed : 672000 snli Loss : 2.56470 Num snli minibatches : 180\n",
      "2019-05-29 20:06:58,336 - INFO - Round: 14000 NLI Epoch : 0 NLI Examples Processed : 67248 NLI Loss : 0.72321\n",
      "2019-05-29 20:06:58,342 - INFO - Average time per mininbatch : 0.45860\n",
      "2019-05-29 20:06:58,348 - INFO - ******************************************************\n",
      "2019-05-29 20:08:29,144 - INFO - Seq2Seq Examples Processed : 681600 snli Loss : 2.72915 Num snli minibatches : 180\n",
      "2019-05-29 20:08:29,198 - INFO - Round: 14200 NLI Epoch : 0 NLI Examples Processed : 68208 NLI Loss : 0.73935\n",
      "2019-05-29 20:08:29,204 - INFO - Average time per mininbatch : 0.45394\n",
      "2019-05-29 20:08:29,210 - INFO - ******************************************************\n",
      "2019-05-29 20:09:58,806 - INFO - Seq2Seq Examples Processed : 691200 snli Loss : 2.68844 Num snli minibatches : 180\n",
      "2019-05-29 20:09:58,846 - INFO - Round: 14400 NLI Epoch : 0 NLI Examples Processed : 69168 NLI Loss : 0.74668\n",
      "2019-05-29 20:09:58,852 - INFO - Average time per mininbatch : 0.44793\n",
      "2019-05-29 20:09:58,859 - INFO - ******************************************************\n",
      "2019-05-29 20:11:29,986 - INFO - Seq2Seq Examples Processed : 700800 snli Loss : 2.69640 Num snli minibatches : 180\n",
      "2019-05-29 20:11:30,011 - INFO - Round: 14600 NLI Epoch : 0 NLI Examples Processed : 70128 NLI Loss : 0.71737\n",
      "2019-05-29 20:11:30,017 - INFO - Average time per mininbatch : 0.45559\n",
      "2019-05-29 20:11:30,022 - INFO - ******************************************************\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: pytorch-gensen_1559153095_0e7f4645\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'pytorch-gensen_1559153095_0e7f4645',\n",
       " 'target': 'gpucluster',\n",
       " 'status': 'CancelRequested',\n",
       " 'startTimeUtc': '2019-05-29T18:05:02.390551Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_f6cd7804b6a4e89cea33d34d8659fed9',\n",
       "  'ContentSnapshotId': 'f0eb2538-559b-4051-9d66-5a6a79570c3d',\n",
       "  'azureml.git.repository_uri': 'https://github.com/Microsoft/NLP.git',\n",
       "  'azureml.git.branch': 'liqun-first-pull',\n",
       "  'azureml.git.commit': 'ba716d109a6db89aa94d95255afe7f972a97f0b8',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'azureml.git.build_id': None,\n",
       "  'azureml.git.build_uri': None,\n",
       "  'mlflow.source.git.branch': 'liqun-first-pull',\n",
       "  'mlflow.source.git.commit': 'ba716d109a6db89aa94d95255afe7f972a97f0b8',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/Microsoft/NLP.git'},\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'arguments': ['--config',\n",
       "   'sample_config.json',\n",
       "   '--data_folder',\n",
       "   '$AZUREML_DATAREFERENCE_gensen'],\n",
       "  'sourceDirectoryDataStore': 'workspaceblobstore',\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'Mpi',\n",
       "  'target': 'gpucluster',\n",
       "  'dataReferences': {'gensen': {'dataStoreName': 'gensen',\n",
       "    'mode': 'Mount',\n",
       "    'pathOnDataStore': None,\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False},\n",
       "   'workspaceblobstore': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Mount',\n",
       "    'pathOnDataStore': None,\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 4,\n",
       "  'environment': {'name': 'Experiment pytorch-gensen Environment',\n",
       "   'version': 'Autosave_2019-05-29T17:23:26Z_8a3fa4ff',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'torch==1.0.0',\n",
       "        'torchvision==0.2.1',\n",
       "        'horovod==0.15.2']},\n",
       "      'scikit-learn=0.20.3']},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_SOCKET_IFNAME': '^docker0'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda9.0-cudnn7-ubuntu16.04',\n",
       "    'enabled': True,\n",
       "    'sharedVolumes': True,\n",
       "    'gpuSupport': True,\n",
       "    'shmSize': '1g',\n",
       "    'arguments': [],\n",
       "    'baseImageRegistry': {'address': None,\n",
       "     'username': None,\n",
       "     'password': None}},\n",
       "   'spark': {'repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'packages': [{'group': 'com.microsoft.ml.spark',\n",
       "      'artifact': 'mmlspark_2.11',\n",
       "      'version': '0.12'}],\n",
       "    'precachePackages': True}},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'vmPriority': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 4},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None},\n",
       " 'logFiles': {'azureml-logs/80_driver_log_rank_0.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-gensen_1559153095_0e7f4645/azureml-logs/80_driver_log_rank_0.txt?sv=2018-03-28&sr=b&sig=DQm40ZucopOZIMdeEOgfpLYIopsnzDl0fQVKokQcOaw%3D&st=2019-05-29T20%3A01%3A43Z&se=2019-05-30T04%3A11%3A43Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_1.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-gensen_1559153095_0e7f4645/azureml-logs/80_driver_log_rank_1.txt?sv=2018-03-28&sr=b&sig=yGX4ZaTAWOu8XsikG3oZ9ZFFJycb%2FrrmPU%2FbDWfQs%2FY%3D&st=2019-05-29T20%3A01%3A43Z&se=2019-05-30T04%3A11%3A43Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_2.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-gensen_1559153095_0e7f4645/azureml-logs/80_driver_log_rank_2.txt?sv=2018-03-28&sr=b&sig=9zNw%2BZ94ncqQY6%2BzZWJiJJBT%2F3blXF6mTDohsPkvOl4%3D&st=2019-05-29T20%3A01%3A43Z&se=2019-05-30T04%3A11%3A43Z&sp=r',\n",
       "  'azureml-logs/80_driver_log_rank_3.txt': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-gensen_1559153095_0e7f4645/azureml-logs/80_driver_log_rank_3.txt?sv=2018-03-28&sr=b&sig=vowPfbhv6HR8QFeFKJJFy6afd9h5Dt5YS18r2I5Xfzs%3D&st=2019-05-29T20%3A01%3A43Z&se=2019-05-30T04%3A11%3A43Z&sp=r',\n",
       "  'logs/azureml/azureml.log': 'https://maidaptest3334372853.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-gensen_1559153095_0e7f4645/logs/azureml/azureml.log?sv=2018-03-28&sr=b&sig=KXjFQzVr00dx7PF7vL2gKOszt0Qvbj7H6%2F9eWP2FEMg%3D&st=2019-05-29T20%3A01%3A43Z&se=2019-05-30T04%3A11%3A43Z&sp=r'}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True) # this provides a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Tune Model Hyperparameters\n",
    "Now that we've seen how to do a simple PyTorch training run using the SDK, let's see if we can further improve the accuracy of our model. We can optimize our model's hyperparameters using Azure Machine Learning's hyperparameter tuning capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Start a Hyperparameter Sweep\n",
    "First, we will define the hyperparameter space to sweep over. Since our training script uses a learning rate schedule to decay the learning rate every several epochs, let's tune the initial learning rate parameter. In this example we will use random sampling to try different configuration sets of hyperparameters to minimize our primary metric, the best validation accuracy (`best_val_loss`).\n",
    "\n",
    "Then, we specify the early termination policy to use to early terminate poorly performing runs. Here we use the `BanditPolicy`, which will terminate any run that doesn't fall within the slack factor of our primary evaluation metric. In this tutorial, we will apply this policy every epoch (since we report our `best_val_loss` metric every epoch and `evaluation_interval=1`). Notice we will delay the first policy evaluation until after the first `10` epochs (`delay_evaluation=10`).\n",
    "Refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-tune-hyperparameters#specify-an-early-termination-policy) for more information on the BanditPolicy and other policies available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveRunConfig, uniform, PrimaryMetricGoal\n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "        'learning_rate': uniform(0.0001, 0.001)\n",
    "    }\n",
    ")\n",
    "\n",
    "early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=1, delay_evaluation=10)\n",
    "\n",
    "hyperdrive_run_config = HyperDriveRunConfig(estimator=estimator,\n",
    "                                            hyperparameter_sampling=param_sampling, \n",
    "                                            policy=early_termination_policy,\n",
    "                                            primary_metric_name='best_val_loss',\n",
    "                                            primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n",
    "                                            max_total_runs=8,\n",
    "                                            max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lauch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the HyperDrive run\n",
    "hyperdrive_run = experiment.submit(hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Monitor HyperDrive runs\n",
    "You can monitor the progress of the runs with the following Jupyter widget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cancel the hyper drive run to save the resources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Subramanian, Sandeep and Trischler, Adam and Bengio, Yoshua and Pal, Christopher J, [*Learning general purpose distributed sentence representations via large scale multi-task learning*](https://arxiv.org/abs/1804.00079), ICLR, 2018.\n",
    "2. A. Conneau, D. Kiela, [*SentEval: An Evaluation Toolkit for Universal Sentence Representations*](https://arxiv.org/abs/1803.05449).\n",
    "3. Semantic textual similarity. url: http://nlpprogress.com/english/semantic_textual_similarity.html\n",
    "4. Minh-Thang Luong, Quoc V Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. [*Multi-task sequence to sequence learning*](https://arxiv.org/abs/1511.06114), 2015."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "minxia"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "msauthor": "minxia"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
