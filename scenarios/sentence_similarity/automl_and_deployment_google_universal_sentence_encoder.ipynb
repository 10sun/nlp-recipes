{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using AutoML for Predicting Sentence Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use Azure AutoML to automate machine learning model selection and tuning. It also demonstrates how to use a popular sentence embedding model from Google, Universal Sentence Encoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Azure AutoML?\n",
    "\n",
    "Automated machine learning (AutoML) is a capability of Microsoft's Azure Machine Learning service. The goal of AutoML is to \"improve the productivity of data scientists and democratize AI\" [1] by allowing for the rapid development and deployment of machine learning models. To acheive this goal, AutoML automates the process of selecting a ML model and tuning the model. All the user is required to provide is a dataset (suitable for a classification, regression, or time-series forecasting problem) and a metric to optimize in choosing the model and hyperparameters. The user is also given the ability to set time and cost constraints for the model selection and tuning.\n",
    "\n",
    "[1]https://azure.microsoft.com/en-us/blog/new-automated-machine-learning-capabilities-in-azure-machine-learning-service/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](automl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AutoML model selection and tuning process can be easily tracked through the Azure portal or directly in python notebooks through the use of widgets. AutoML quickly selects a high quilty machine learning model tailored for your prediction problem. In this notebook, we walk through the steps of preparing data, setting up an AutoML experiment, and evaluating the results of our best model. More information about running AutoML experiments in Python can be found [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Problem\n",
    "\n",
    "The regression problem we will demonstrate is predicting sentence similarity scores on the STS Benchmark dataset. The [STS Benchmark dataset](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark#STS_benchmark_dataset_and_companion_dataset) contains a selection of English datasets that were used in Semantic Textual Similarity (STS) tasks 2012-2017. The dataset contains 8,628 sentence pairs with a human-labeled integer representing the sentences' similarity (ranging from 0, for no meaning overlap, to 5, meaning equivalence).\n",
    "\n",
    "For each sentence in the sentence pair, we will use Google's pretrained Universal Sentence Encoder (details provided below) to generate a $512$-dimensional embedding. Both embeddings in the sentence pair will be concatenated and the resulting $1024$-dimensional vector will be used as features in our regression problem. Our target variable is the sentence similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n",
      "System version: 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]\n",
      "Azure ML SDK Version: 1.0.43\n",
      "Pandas version: 0.23.4\n",
      "Tensorflow Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Set the environment path to find NLP\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial import distance\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Import utils\n",
    "from utils_nlp.azureml import azureml_utils\n",
    "from utils_nlp.dataset import stsbenchmark\n",
    "from utils_nlp.dataset.preprocess import (\n",
    "    to_lowercase,\n",
    "    to_spacy_tokens,\n",
    "    rm_spacy_stopwords,\n",
    ")\n",
    "\n",
    "# Tensorflow dependencies for Google Universal Sentence Encoder\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "tf.logging.set_verbosity(tf.logging.ERROR) # reduce logging output\n",
    "\n",
    "# AzureML packages\n",
    "import azureml as aml\n",
    "import logging\n",
    "from azureml.telemetry import set_diagnostics_collection\n",
    "set_diagnostics_collection(send_diagnostics=True)\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Azure ML SDK Version:\", aml.core.VERSION)\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow Version:\", tf.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_PATH = '../../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STS Benchmark Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described above, the STS Benchmark dataset contains 8.6K sentence pairs along with a human-annotated score for how similiar the two sentences are. We will load the training, development (validation), and test sets provided by STS Benchmark and preprocess the data (lowercase the text, drop irrelevant columns, and rename the remaining columns) using the utils contained in this repo. Each dataset will ultimately have three columns: _sentence1_ and _sentence2_ which contain the text of the sentences in the sentence pair, and _score_ which contains the human-annotated similarity score of the sentence pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 401/401 [00:02<00:00, 158KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to ../../data\\raw\\stsbenchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 401/401 [00:01<00:00, 274KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to ../../data\\raw\\stsbenchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 401/401 [00:02<00:00, 164KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to ../../data\\raw\\stsbenchmark\n"
     ]
    }
   ],
   "source": [
    "# Load in the raw datasets as pandas dataframes\n",
    "train_raw = stsbenchmark.load_pandas_df(BASE_DATA_PATH, file_split=\"train\")\n",
    "dev_raw = stsbenchmark.load_pandas_df(BASE_DATA_PATH, file_split=\"dev\")\n",
    "test_raw = stsbenchmark.load_pandas_df(BASE_DATA_PATH, file_split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean each dataset by lowercasing text, removing irrelevant columns,\n",
    "# and renaming the remaining columns\n",
    "train = stsbenchmark.clean_sts(train_raw)\n",
    "dev = stsbenchmark.clean_sts(dev_raw)\n",
    "test = stsbenchmark.clean_sts(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 5749 sentences\n",
      "Development set has 1500 sentences\n",
      "Testing set has 1379 sentences\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set has {} sentences\".format(len(train)))\n",
    "print(\"Development set has {} sentences\".format(len(dev)))\n",
    "print(\"Testing set has {} sentences\".format(len(test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.60</td>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.25</td>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                      sentence1  \\\n",
       "0   5.00                         A plane is taking off.   \n",
       "1   3.80                A man is playing a large flute.   \n",
       "2   3.80  A man is spreading shreded cheese on a pizza.   \n",
       "3   2.60                   Three men are playing chess.   \n",
       "4   4.25                    A man is playing the cello.   \n",
       "\n",
       "                                           sentence2  \n",
       "0                        An air plane is taking off.  \n",
       "1                          A man is playing a flute.  \n",
       "2  A man is spreading shredded cheese on an uncoo...  \n",
       "3                         Two men are playing chess.  \n",
       "4                 A man seated is playing the cello.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering:  Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our sentence pairs loaded, we will convert these sentences into a numerical representation in order to use them in our machine learning model. To do this, we'll use a popular sentence encoder called Google Universal Sentence Encoder (see [original paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf)). Google provides two pretrained models based on different design goals: a Transformer model (targets high accuracy even if this reduces model complexity) and a Deep Averaging Network model (DAN; targets efficient inference). Both models are trained on a variety of web sources (Wikipedia, news, question-answers pages, and discussion forums) and produced 512-dimensional embeddings. This notebook utilizes the Transformer-based encoding model which can be downloaded [here](https://tfhub.dev/google/universal-sentence-encoder-large/3) because of its better performance relative to the DAN model on the STS Benchmark dataset (see Table 2 in Google Research's [paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Google Universal Sentence Encoder: Transformer Model** The Transformer model produces sentence embeddings using the \"encoding sub-graph of the transformer architecture\" (original architecture introduced [here](https://arxiv.org/abs/1706.03762)). \"This sub-graph uses attention to compute context aware representations of words in a sentence that take into account both the ordering and identity of all the other workds. The context aware word representations are converted to a fixed length sentence encoding vector by computing the element-wise sum of the representations at each word position.\" The input to the model is lowercase PTB-tokenized strings and the model is designed to be useful for multiple different tasks by using multi-task learning. More details about the model can be found in the [paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf) by Google Research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the Pretrained Model**\n",
    "\n",
    "Tensorflow-hub provides the pretrained model for use by the public. We import the model from its url and then feed the model our sentences for it to encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embedding_model = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_encoder(dataset):\n",
    "    \"\"\" Function that embeds sentences using the Google Universal\n",
    "    Sentence Encoder pretrained model\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dataset: pandas dataframe with sentences and scores\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    emb1: 512-dimensional representation of sentence1\n",
    "    emb2: 512-dimensional representation of sentence2\n",
    "    \"\"\"\n",
    "    sts_input1 = tf.placeholder(tf.string, shape=(None))\n",
    "    sts_input2 = tf.placeholder(tf.string, shape=(None))\n",
    "\n",
    "    # Apply embedding model and normalize the input\n",
    "    sts_encode1 = tf.nn.l2_normalize(embedding_model(sts_input1), axis=1)\n",
    "    sts_encode2 = tf.nn.l2_normalize(embedding_model(sts_input2), axis=1)\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.tables_initializer())\n",
    "        emb1, emb2 = session.run(\n",
    "          [sts_encode1, sts_encode2],\n",
    "          feed_dict={\n",
    "              sts_input1: dataset['sentence1'],\n",
    "              sts_input2: dataset['sentence2']\n",
    "          })\n",
    "    return emb1, emb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As features, we will embed both sentences using the Google Universal Sentence Encoder and concatenate their representations into a $1024$-dimensional vector. The resulting data will be saved in a dataframe for consumption by our AutoML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(dataset):\n",
    "    \"\"\"Extracts embedding features from the dataset and returns\n",
    "    features and target in a dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dataset: pandas dataframe with sentences and scores\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    df: pandas dataframe with embedding features and target variable\n",
    "    \"\"\"\n",
    "    google_USE_emb1, google_USE_emb2 = google_encoder(dataset)\n",
    "    n_google = google_USE_emb1.shape[1] #length of the embeddings \n",
    "    df = np.concatenate((google_USE_emb1, google_USE_emb2), axis=1)\n",
    "    names = ['USEEmb1_'+str(i) for i in range(n_google)]+['USEEmb2_'+str(i) for i in range(n_google)]\n",
    "    df = pd.DataFrame(df, columns=names)\n",
    "    df['score'] = dataset['score'].tolist()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = feature_engineering(train)\n",
    "validation_data = feature_engineering(dev)\n",
    "testing_data = feature_engineering(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take this out later\n",
    "\n",
    "training_data.to_csv(os.path.join(featurized_data_location,\"googleUSE_features_train.csv\"), index=None)\n",
    "testing_data.to_csv(os.path.join(featurized_data_location,\"googleUSE_features_test.csv\"), index=None)\n",
    "validation_data.to_csv(os.path.join(featurized_data_location,\"googleUSE_features_dev.csv\"), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Baseline Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using AutoML we will calculate a baseline to compare the AutoML results to. For the baseline we will take the Google Universal Sentence Encoder embeddings of each sentence, calculate the cosine similarity between the two sentence embeddings, then compare the predicted values with the true scores using pearson correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Pearson Correlation?\n",
    "\n",
    "Our evaluation metric is Pearson correlation ($\\rho$) which is a measure of the linear correlation between two variables. The formula for calculating Pearson correlation is as follows:  \n",
    "\n",
    "$$\\rho_{X,Y} = \\frac{E[(X-\\mu_X)(Y-\\mu_Y)]}{\\sigma_X \\sigma_Y}$$\n",
    "\n",
    "This metric takes a value in [-1,1] where -1 represents a perfect negative correlation, 1 represents a perfect positive correlation, and 0 represents no correlation. We utilize the Pearson correlation metric as this is the metric that [SentEval](http://nlpprogress.com/english/semantic_textual_similarity.html), a widely-used evaluation toolkit for evaluation sentence representations, uses for the STS Benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_performance(data):\n",
    "    \"\"\" Get baseline performance by calculating the cosine similarity between\n",
    "    the embeddings in the sentence pair and then evaluating the pearson \n",
    "    correlation between the predicted and true similarity scores\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    data: dataframe containing embeddings and similarity scores\n",
    "    \"\"\"\n",
    "    emb1 = data[[i for i in data.columns if 'USEEmb1' in i]].values.tolist()\n",
    "    emb2 = data[[i for i in data.columns if 'USEEmb2' in i]].values.tolist()\n",
    "    scores = data['score'].values.tolist()\n",
    "    \n",
    "    predictions = [1-distance.cosine(emb1[i], emb2[i]) for i in range(len(emb1))]\n",
    "    print(\"Google Universal Sentence Encoder Pearson Correlation:\", round(pearsonr(predictions, scores)[0],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Universal Sentence Encoder Pearson Correlation: 0.764\n"
     ]
    }
   ],
   "source": [
    "get_baseline_performance(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoML can be used for classification, regression or timeseries experiments. Each experiment type has corresponding machine learning models and metrics that can be optimized (see [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train)) and the options will be delineated below. As a first step we connect to an existing workspace or create one if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Note, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\n",
      "WARNING - You have logged in. Now let us find all the subscriptions to which you have access...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n",
      "Workspace name: MAIDAPNLP\n",
      "Azure region: eastus2\n",
      "Subscription id: 15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\n",
      "Resource group: nlprg\n"
     ]
    }
   ],
   "source": [
    "ws = azureml_utils.get_or_create_workspace(\n",
    "    subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "    resource_group=\"<RESOURCE_GROUP>\",\n",
    "    workspace_name=\"<WORKSPACE_NAME>\",\n",
    "    workspace_region=\"<WORKSPACE_REGION>\"\n",
    ")\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoMLConfig Parameters\n",
    "Next, we specify the parameters for the AutoMLConfig class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**task**  \n",
    "AutoML supports the following base learners for the regression task: Elastic Net, Light GBM, Gradient Boosting, Decision Tree, K-nearest Neighbors, LARS Lasso, Stochastic Gradient Descent, Random Forest, Extremely Randomized Trees, XGBoost, DNN Regressor, Linear Regression. In addition, AutoML also supports two kinds of ensemble methods: voting (weighted average of the output of multiple base learners) and stacking (training a second \"metalearner\" which uses the base algorithms' predictions to predict the target variable). Specific base learners can be included or excluded in the parameters for the AutoMLConfig class (whitelist_models and blacklist_models) and the voting/stacking ensemble options can be specified as well (enable_voting_ensemble and enable_stack_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**preprocess**  \n",
    "AutoML also has advanced preprocessing methods, eliminating the need for users to perform this manually. Data is automatically scaled and normalized but an additional parameter in the AutoMLConfig class enables the use of more advanced techniques including imputation, generating additional features, transformations, word embeddings, etc. (full list found [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-create-portal-experiments#preprocess)). Note that algorithm-specific preprocessing will be applied even if preprocess=False. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**primary_metric**  \n",
    "The regression metrics available are the following: Spearman Correlation (spearman_correlation), Normalized RMSE (normalized_root_mean_squared_error), Normalized MAE (normalized_mean_absolute_error), and R2 score (r2_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constraints:**  \n",
    "There is a cost_mode parameter to set cost prediction modes (see options [here](https://docs.microsoft.com/en-us/python/api/azureml-train-automl/azureml.train.automl.automlconfig?view=azure-ml-py)). To set constraints on time there are multiple parameters including experiment_exit_score (target score to exit the experiment after acheiving), experiment_timeout_minutes (maximum amount of time for all combined iterations), and iterations (total number of different algorithm and parameter combinations to try)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"task\": 'regression', #type of task: classification, regression or forecasting\n",
    "    \"debug_log\": 'automated_ml_errors.log',\n",
    "    \"path\": './automated-ml-regression',\n",
    "    \"iteration_timeout_minutes\" : 15, #How long each iteration can take before moving on\n",
    "    \"iterations\" : 50, #Number of algorithm options to try\n",
    "    \"primary_metric\" : 'spearman_correlation', #Metric to optimize\n",
    "    \"preprocess\" : True, #Whether dataset preprocessing should be applied\n",
    "    \"verbosity\":logging.ERROR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data.drop(\"score\", axis=1).values\n",
    "y_train = training_data['score'].values.flatten()\n",
    "X_validation = validation_data.drop(\"score\", axis=1).values\n",
    "y_validation = validation_data['score'].values.flatten()\n",
    "\n",
    "# local compute\n",
    "automated_ml_config = AutoMLConfig(\n",
    "     X = X_train,\n",
    "     y = y_train,\n",
    "     X_valid = X_validation,\n",
    "     y_valid = y_validation,\n",
    "     **automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Experiment\n",
    "\n",
    "Run the experiment locally and inspect the results using a widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_5b011db3-83db-4ab5-afa6-9acf2c1a9515\n",
      "Current status: DatasetFeaturization. Beginning to featurize the dataset.\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the dataset.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   StandardScalerWrapper RandomForest             0:01:17       0.1655    0.1655\n",
      "         1   MinMaxScaler RandomForest                      0:02:19       0.4102    0.4102\n",
      "         2   StandardScalerWrapper ExtremeRandomTrees       0:00:23       0.2577    0.4102\n",
      "         3   StandardScalerWrapper LightGBM                 0:00:21       0.2708    0.4102\n",
      "         4   RobustScaler DecisionTree                      0:00:27       0.2435    0.4102\n",
      "         5   StandardScalerWrapper LassoLars                0:00:15       0.1246    0.4102\n",
      "         6   StandardScalerWrapper LightGBM                 0:00:20       0.6567    0.6567\n",
      "         7   StandardScalerWrapper RandomForest             0:00:20       0.2128    0.6567\n",
      "         8   StandardScalerWrapper LassoLars                0:00:20       0.0836    0.6567\n",
      "         9   MinMaxScaler ExtremeRandomTrees                0:00:25       0.3767    0.6567\n",
      "        10   RobustScaler ExtremeRandomTrees                0:01:05       0.3615    0.6567\n",
      "        11   StandardScalerWrapper ExtremeRandomTrees       0:00:21       0.2653    0.6567\n",
      "        12   StandardScalerWrapper LassoLars                0:00:11          nan    0.6567\n",
      "ERROR: Run AutoML_5b011db3-83db-4ab5-afa6-9acf2c1a9515_12 failed with exception \"Primary metric spearman_correlation is not available.\".\n",
      "        13   MinMaxScaler ExtremeRandomTrees                0:00:22       0.2885    0.6567\n",
      "        14   RobustScaler RandomForest                      0:00:29       0.3499    0.6567\n",
      "        15   StandardScalerWrapper LassoLars                0:00:14          nan    0.6567\n",
      "ERROR: Run AutoML_5b011db3-83db-4ab5-afa6-9acf2c1a9515_15 failed with exception \"Primary metric spearman_correlation is not available.\".\n",
      "        16   StandardScalerWrapper ExtremeRandomTrees       0:00:15       0.2155    0.6567\n",
      "        17   StandardScalerWrapper RandomForest             0:00:16       0.2296    0.6567\n",
      "        18   MinMaxScaler SGD                               0:00:17       0.0990    0.6567\n",
      "        19   StandardScalerWrapper RandomForest             0:00:46       0.3087    0.6567\n",
      "        20   StandardScalerWrapper LightGBM                 0:00:40       0.7412    0.7412\n",
      "        21   StandardScalerWrapper LightGBM                 0:00:32       0.6983    0.7412\n",
      "        22   StandardScalerWrapper LightGBM                 0:00:37       0.6864    0.7412\n",
      "        23   StandardScalerWrapper RandomForest             0:04:30       0.4236    0.7412\n",
      "        24   MaxAbsScaler DecisionTree                      0:06:51       0.2587    0.7412\n",
      "        25   MaxAbsScaler LightGBM                          0:00:22       0.3161    0.7412\n",
      "        26   StandardScalerWrapper LightGBM                 0:01:25       0.5771    0.7412\n",
      "        27   RobustScaler DecisionTree                      0:00:21       0.2484    0.7412\n",
      "        28   MaxAbsScaler LightGBM                          0:02:55       0.7195    0.7412\n",
      "        29   StandardScalerWrapper LightGBM                 0:01:49       0.7379    0.7412\n",
      "        30   SparseNormalizer LightGBM                      0:00:38       0.6011    0.7412\n",
      "        31   MaxAbsScaler LightGBM                          0:00:47       0.6835    0.7412\n",
      "        32   StandardScalerWrapper DecisionTree             0:06:19       0.2630    0.7412\n",
      "        33   MaxAbsScaler LightGBM                          0:00:32       0.7460    0.7460\n",
      "        34   StandardScalerWrapper LightGBM                 0:00:36       0.5717    0.7460\n",
      "        35   StandardScalerWrapper LightGBM                 0:00:36       0.7115    0.7460\n",
      "        36   MaxAbsScaler LightGBM                          0:00:37       0.7265    0.7460\n",
      "        37   MaxAbsScaler LightGBM                          0:01:12       0.6830    0.7460\n",
      "        38   SparseNormalizer LightGBM                      0:00:32       0.6854    0.7460\n",
      "        39   MaxAbsScaler LightGBM                          0:00:36       0.6779    0.7460\n",
      "        40   SparseNormalizer LightGBM                      0:01:38       0.3032    0.7460\n",
      "        41   MaxAbsScaler LightGBM                          0:00:30       0.5939    0.7460\n",
      "        42   MinMaxScaler DecisionTree                      0:00:31       0.1622    0.7460\n",
      "        43   MaxAbsScaler LightGBM                          0:02:34       0.7011    0.7460\n",
      "        44   MaxAbsScaler LightGBM                          0:00:41       0.6090    0.7460\n",
      "        45   RobustScaler LightGBM                          0:00:35       0.3380    0.7460\n",
      "        46   MaxAbsScaler LightGBM                          0:00:58       0.4714    0.7460\n",
      "        47   MaxAbsScaler LightGBM                          0:00:35       0.7303    0.7460\n",
      "        48   VotingEnsemble                                 0:01:34       0.7938    0.7938\n",
      "        49   StackEnsemble                                  0:06:14       0.7943    0.7943\n"
     ]
    }
   ],
   "source": [
    "experiment=Experiment(ws, 'automated-ml-regression')\n",
    "local_run = experiment.submit(automated_ml_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the completed run can be visualized in two ways. First, by using a RunDetails widget as shown in the cell below. Second, my accessing the [Azure portal](https://portal.azure.com), selecting your workspace, clicking on _Experiments_ and then selecting the name and run number of the experiment you want to inspect. Both these methods will show the results and duration for each iteration (algorithm tried), a visualization of the results, and information about the run including the compute target, primary metric, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the run details using the provided widget\n",
    "RunDetails(local_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy\n",
    "\n",
    "### Retrieve the Best Model\n",
    "Below we select the best pipeline from our iterations. The get_output method returns the best run and the fitted model for the last invocation. Overloads on get_output allow you to retrieve the best run and fitted model for any logged metric or for a particular iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = local_run.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the Fitted Model for Deployment\n",
    "If neither metric nor iteration are specified in the register_model call, the iteration with the best primary metric is registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model AutoML5b011db38best\n",
      "AutoML5b011db38best\n"
     ]
    }
   ],
   "source": [
    "description = 'AutoML Model'\n",
    "tags = {'area': \"nlp\", 'type': \"sentencesimilarity automl\"}\n",
    "name = 'automl'\n",
    "model = local_run.register_model(description = description, tags = tags)\n",
    "\n",
    "print(local_run.model_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Scoring Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import pickle\n",
    "import json\n",
    "import numpy\n",
    "import azureml.train.automl\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path(model_name = '<<modelid>>') # this name is model.id of model that we want to deploy\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(rawdata):\n",
    "    try:\n",
    "        data = json.loads(rawdata)['data']\n",
    "        data = numpy.array(data)\n",
    "        result = model.predict(data)\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n",
    "    return json.dumps({\"result\":result.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a YAML File for the Environment\n",
    "\n",
    "To ensure the fit results are consistent with the training results, the SDK dependency versions need to be the same as the environment that trains the model. The following cells create a file, myenv.yml, which specifies the dependencies from the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment=Experiment(ws, 'automated-ml-regression')\n",
    "ml_run = AutoMLRun(experiment = experiment, run_id = local_run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No issues found in the SDK package versions.\n"
     ]
    }
   ],
   "source": [
    "dependencies = ml_run.get_run_sdk_dependencies(iteration = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml-train-automl\t1.0.43.1\n",
      "azureml-sdk\t1.0.43\n",
      "azureml-core\t1.0.43\n"
     ]
    }
   ],
   "source": [
    "for p in ['azureml-train-automl', 'azureml-sdk', 'azureml-core']:\n",
    "    print('{}\\t{}'.format(p, dependencies[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autoenv.yml'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = CondaDependencies.create(conda_packages=['numpy','scikit-learn','py-xgboost<=0.80'],\n",
    "                                 pip_packages=['azureml-sdk[automl]'], python_version = '3.6.8')\n",
    "\n",
    "conda_env_file_name = 'autoenv.yml'\n",
    "myenv.save_to_file('.', conda_env_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Substitute the actual version number in the environment file.\n",
    "# This is not strictly needed in this notebook because the model should have been generated using the current SDK version.\n",
    "# However, we include this in case this code is used on an experiment from a previous SDK version.\n",
    "\n",
    "'''with open(conda_env_file_name, 'r') as cefr:\n",
    "    content = cefr.read()\n",
    "\n",
    "with open(conda_env_file_name, 'w') as cefw:\n",
    "    cefw.write(content.replace(azureml.core.VERSION, dependencies['azureml-sdk']))\n",
    "'''\n",
    "# Substitute the actual model id in the script file.\n",
    "\n",
    "script_file_name = 'score.py'\n",
    "\n",
    "with open(script_file_name, 'r') as cefr:\n",
    "    content = cefr.read()\n",
    "\n",
    "with open(script_file_name, 'w') as cefw:\n",
    "    cefw.write(content.replace('<<modelid>>', local_run.model_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Container Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running.\n",
      "NotStarted...............................................\n",
      "Succeeded\n",
      "Image creation operation finished for image automl-image:8, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"autoenv.yml\",\n",
    "                                                  description = \"Image with automl model\",\n",
    "                                                  tags = {'area': \"nlp\", 'type': \"sentencesimilarity automl\"})\n",
    "\n",
    "image = ContainerImage.create(name = \"automl-image\",\n",
    "                              # this is the model object\n",
    "                              models = [model],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://maidapnlp0056795534.blob.core.windows.net/azureml/ImageLogs/48a3794d-b14b-4ab1-aef8-357485615f27/build.log?sv=2018-03-28&sr=b&sig=FSfsmE7TEOgWeYMa8DQjrTZg31z1WEd3uO%2F5Q1%2F02gU%3D&st=2019-06-16T21%3A46%3A17Z&se=2019-07-16T21%3A51%3A17Z&sp=rl\n"
     ]
    }
   ],
   "source": [
    "print(image.image_build_log_uri) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Image as a Web Service on Azure Container Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the web service configuration (using default here)\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n",
      "Running...................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "# deploy image as web service\n",
    "aci_service_name ='aci-service-with-automl'\n",
    "aci_service = Webservice.deploy_from_image(workspace = ws, \n",
    "                                           name = aci_service_name,\n",
    "                                           image = image,\n",
    "                                           deployment_config = aci_config)\n",
    "\n",
    "aci_service.wait_for_deployment(show_output = True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "21256649\n"
     ]
    }
   ],
   "source": [
    "# load multiple sentences\n",
    "import pandas as pd\n",
    "import json \n",
    "\n",
    "sentences = []\n",
    "data = pd.read_csv(\"testing_set.csv\")\n",
    "train_y = data['score'].values.flatten()\n",
    "train_x = data.drop(\"score\", axis=1).values\n",
    "\n",
    "print(type(train_x))\n",
    "\n",
    "train_x = train_x.tolist()\n",
    "data = {'data': train_x}\n",
    "data = json.dumps(data)\n",
    "print(len(data))\n",
    "\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sentences encoded : 27145\n",
      "{\"result\": [1.4322549411038765, 3.701496597224398, 3.0479749754684877, 3.9308189127466533, 0.8635069938099544, 1.751576288452982, 3.040980961190109, 2.1431064151633423, 2.191154825045265, 1.2682110745155055, 1.2682110745155055, 4.40765538725924, 0.7558847754292286, 3.390359555883792, 2.3854790756015833, 1.7344997332170062, 4.589225643618903, 3.3416602405105817, 3.4048902285962597, 1.6773498215648046, 2.075599433031979, 0.7595681987065432, 3.9995388312550193, 3.7261206556907625, 1.19578134877992, 2.6713024996174513, 0.8020056210402666, 2.8197897135898087, 1.559042795238717, 3.3018493059315888, 4.021559714224404, 3.6230277884565276, 1.552067486049196, 4.134648970804008, 2.9405120739331627, -0.615576864235015, 0.7909618994365504, 2.932382403966035, 2.96584032513176, 0.5734777148904935, 2.9680829681354344, 2.642053672175344, 3.3176550749645064, 0.8861250646792223, 2.1513692735537417, 0.9555818872587727, 0.62480371701695, 0.27621102112607265, 2.5383000690934567, 1.894986180892777, 0.9470776270035255, 1.4772919968083298, -0.20512909341739372, 0.5368315777245871, 1.1370111739455173, -0.6110950310809333, 3.009552682781307, 0.838263432047385, 3.25524852531291, 1.748537225118001, 3.4162818656474045, 0.6309719383744596, 3.188171415158594, 1.1885539579202526, 3.885881180873047, -0.10989696061508847, 0.036949805478808884, 2.983700334965398, 0.1553958035603875, 3.4602422942767226, 2.8792367087831425, 3.3639351537595155, 0.6779550805450834, 2.9158586050826276, 2.670557684953456, 0.6516185013788782, 0.7987308948801775, -1.6724892263668112, 2.9758651057830274, 3.380656950457761, 0.04004516158518212, 0.7140577657874352, 2.6903054796295574, 1.5692886710979983, 0.11919953362192359, 1.143133149214036, 2.8050995640988585, 3.407908824524682, 3.2087369294620047, 0.7348397113383949, 1.7103949656579203, 3.195163273653194, 1.1199143710847377, 2.3346836178833947, 0.926696818163081, 3.0307953108319876, 4.168205451761104, 3.1367024152252605, 2.535571374257174, 2.70075409983324, -1.0044958301580198, 0.8428663210598888, 3.1940961166154502, 1.7675487826960015, 1.9053703873647803, 2.1382907699481084, -0.41305936846402436, 1.9052852132521325, 1.4009017961585104, 2.4418049938821267, 3.2257252328050776, 2.9018881361276554, 3.3011931786066007, 3.5698511304516214, -0.40603068624334326, -0.7481115480274674, 3.023014564190224, 2.2025556018829344, 0.8866930092348548, 0.7673690130703548, 1.4729108548829184, 0.8091773711256964, 1.3982419824010752, 0.497889676390312, 0.22313132806206126, 3.160855586109493, 0.9059444552529206, 2.1742813156418284, 2.323760254446841, 2.8829088427218896, 2.735227770796081, 2.926382914126975, 3.33319486772642, 4.08659817402215, 2.1160480705871563, 5.0896682512940625, 4.0524223720180395, 2.379174385587522, 1.6227063418743053, 3.7629148781572526, 4.176522298449342, 3.161785575922274, 2.4714191372317287, 3.908907190299748, 2.3143758345939633, 1.3225073955146498, 2.244382141500616, 3.2008764437317523, 1.6626302739062786, 0.25310424813460686, 2.0701176797980883, 1.3179306945641835, 3.0406061958776505, 3.1663366146122196, 3.3952014826237993, 2.7637033539720397, 0.23550756818263208, 1.3503743471435388, 3.757923837995467, 0.09644109520643562, 3.819737616673461, 2.8496691855314142, 1.6776859994046118, 3.233028474487374, 3.3166665542180405, 3.4020225680580762, 2.9230998306879763, 2.7375896396803756, 3.371268676623925, 2.351100544420622, 1.9837394897022427, 0.857168695309404, 3.299183079595004, 2.9734131513230335, 2.8062089719758836, 3.011163505483155, 2.8928652460502957, 3.3624907560547013, -0.7281242803067453, -0.08711697765668303, 0.3341523221312479, 2.046039991089384, 2.4177579231586983, 0.33274470050645744, 1.7461737760112204, -0.7195877983867224, -0.6296044131484234, -0.031746836738074435, 0.470579333672863, -0.1518817951981256, 3.593810223231587, 3.501204912910677, 1.2118771603351464, 2.928006962566029, 3.032530269483511, 3.715935300448145, 2.7492699001294874, 0.8160727303811668, -0.9619788359405301, 3.137679148655353, 0.5637181314112811, 1.0529799950560057, 1.0354067430198106, 0.21626668305393348, 0.7575978198258919, 1.0414766079673619, 3.7026328821540937, 0.18723276926880894, 2.018489939454151, 2.0982145454503907, 2.157541762033266, 0.9769805099453741, 0.914351958029362, 1.3249123736499873, 2.7977862360025885, 0.9575013815713964, 2.4384663704097327, 2.709006953931115, 3.7257064000887374, 2.366866244836494, 0.24240937509058735, 0.530211368038743, 1.9878195352184336, 2.8964998048649093, -0.671408510765914, 1.309177876131379, 1.6866903654001253, 2.6557547047992442, 1.0781755885340782, 0.6030910740174362, -0.13691451952812483, 0.5415414633283682, 1.8420112736436844, 3.4999537080657963, 3.1039569707062538, 2.68383212748226, -0.1990929748930763, 0.7985312625991492, 2.0211596075037117, -0.8466206372715817, 2.1330901572117935, -0.6155253096984299, 0.36905397052109823, -0.5380646127286067, 2.9145332002194477, 0.045828573716479526, 1.6578745076161314, 1.6246003796506798, -0.18990385887850791, 0.23744448164741594, 3.197354573255658, 3.5901615146301498, 3.582764091090041, 2.6294221152328583, 0.5268030077362613, 3.174438459771424, -0.04764748935583474, 1.9663393994338598, 2.9092550072300067, -0.37166341033469363, 4.229164378398597, 2.666773843905054, 3.2497869602753857, 3.0964060005334306, 1.6936622337157892, 1.5527513768130201, 2.0449976414853936, 2.4944068738879834, 1.7909269726797827, 4.231603748025412, 3.3296364232914226, 0.6757386671097878, 3.6449662889235266, 3.1389669533690627, 3.636499122887811, 3.9374237663081337, 0.878717702356582, -0.1290092187173273, 3.241939254658996, 2.7140887326055445, 1.3607405737593696, 1.4257490512391215, 3.23106725651732, 3.3218174551641275, 3.5152293218128228, 2.7732445462629687, 2.4136371334439337, 3.1472589026937174, 2.808800601425598, 1.3613838759960037, 3.573339845490277, 1.630077792944316, 3.0283175677111642, 3.7906917296943052, 0.040061762084844466, -0.04181369776242394, 1.7680746256292084, 3.2832409475675335, 3.039199515391712, 2.621054413449726, 3.7185706968951497, 2.0445555184667383, 1.4786708685517285, 3.6722082249869428, 2.9083077202272425, 3.28684709865959, 3.749337714599618, 2.0953913554482724, 3.5848399987718307, 3.1018762207977564, 1.017871382115535, 0.13396404610707469, 0.3304748751582507, 3.6543788011061262, 2.8957678867158596, 3.171904629549589, 2.0959071999748935, 3.2767306542490116, 0.7272101536144566, 1.2655240128925875, 3.3116757777286767, 2.563048521093771, 3.3708592325063838, 2.664535335194219, 3.168558668797516, -0.0018645519142349576, 3.030236721435313, 2.5488152028569107, 3.9438995266582126, 2.0717039531569643, 3.8899847740606703, 3.338091158172413, 3.7105463580128277, 3.362262276198568, 2.266417053559555, 2.950433252865158, 3.3050449057918008, 2.478457335026994, 0.4094746167202006, 1.096810624842116, 3.1598638129538834, 3.9662687657563827, 4.364913788844802, 2.282600646168691, 2.0084402125600307, 0.6999652756753105, 3.0422364032039497, 1.1460107527335772, 2.8549693609845, 0.8397603850858164, 3.586777347669963, 4.264916450277864, 0.17095021884135486, 3.531301695223584, 3.146340216254313, -0.3115213849483759, 2.572461876019024, 2.882790203231003, -0.3126564310037938, 3.6476180884539944, 3.708169714203367, 2.7073502593339747, 3.3411143187322287, 2.518567656533427, 3.5697766237053865, 1.1198336456740563, 1.6356868767276382, 2.549296253435131, 4.318640677999618, 3.5948615728341324, 3.146736265264743, 4.270698227566312, 0.5117433166472654, 0.8630208167754054, 1.1763071462064136, 3.4801500679157518, 2.3832933393086635, 0.8061180805428338, 2.455877512476104, 2.3284050209774843, 4.067809084438023, 2.933210846824142, 2.7193467588016635, 0.22923109860470703, 2.6682785548165717, 2.3761228353793373, 3.544127611221436, 1.3271789998884942, 2.1759086459332333, 1.9481421502566185, 3.0624118222221113, 1.4603220218772068, -0.32913723127021094, 1.0592630719686327, 2.9602122025486506, -1.193278580708063, -0.03328882577510761, 3.9671986187777457, 3.269583282482015, 1.6471796320970853, 2.1053039371910547, -0.29587233422710035, 1.7852465092221728, 2.574990263438694, 1.9254004986237399, 4.05256390162957, 0.4099957719151519, 2.954773795855815, 2.542267724100228, 2.7330156003574397, 2.826847651265175, 3.318641674677932, 2.051505713674652, 3.1440775825830443, 0.6679312105512905, 1.337013890270852, -0.3970435911432476, 4.187422428331585, 3.9825936316300194, 3.3966350815438866, 4.136552261399064, 1.5749402163799058, 4.002648845745151, 0.6476045329672662, 2.294980404395722, 3.0204747774331135, 0.3510539220580655, 4.1191462753277595, 2.669696941985229, 3.790893304846731, 1.0617475613901282, 3.241064350767533, 0.0514558309081663, 2.1543540510735797, 0.09754821771685118, 2.419579852425469, 2.650167111567565, 4.215553493119149, 4.111332304903263, 3.059277183559754, 2.51783676829828, 3.246904575363422, 0.8357560655740743, 3.7738681363036295, 3.8441105015706163, -0.013230127284269089, 1.8205137461929466, 3.00327595878893, 0.11256424494931405, 2.519415104119354, 2.9774850453078154, 3.9041183476161323, 0.7938809199389643, 0.16510411621087773, 4.84274805253783, 2.7767201528333123, 2.2332105813235277, 3.657120789428562, 2.8175463767404705, 2.4921794468454803, 1.149096653491113, 0.1474065600872051, -0.04749921559691117, 1.2515682461243107, 2.7030445426390686, 3.0600713317304797, 2.650678171534094, 4.259591320584862, 2.940458004734956, -0.019926879876643322, 3.085168671240447, 3.607430732127423, 2.851921479759724, 3.092034239849398, 1.9961675241084689, 2.128617021531064, -0.1885020298222957, 2.3930153979059074, 2.8759430694429393, 1.562369447356772, 4.175871888222478, 2.276974347770905, 3.2868405011310515, 1.0069274969333644, 3.79004586090991, 1.2501287794674134, 2.693503010394633, 3.1603623976228405, 3.30104327431587, 2.8628468780930194, 3.9450259517452237, 2.8400201025415535, 3.155688548951436, 3.8543625476715415, 2.4536403162158633, 2.593775214349628, 0.940856261326309, 3.393516637351181, 1.099920167095592, 5.150461606101626, 1.0427178660128522, 1.0561804584367296, 1.5579164009543898, 2.8143759481086716, 1.5768686609808888, 3.069369863901797, 2.028065576273459, 0.8954445695415738, 2.4913492484458444, 1.2423564363571413, 0.3961159134956118, 1.7530962874582725, 3.3387580691254066, 0.242562966675817, 1.344732425546174, 1.7425645513718773, 1.5007717649909478, 1.451561892844213, 2.148783184677128, 3.298943357792926, 1.8670245113319575, 2.44764921503121, 3.501084597366001, 2.4459520594019586, 3.8185920554842787, 1.0925308760479198, 2.830583458144948, 1.2604860523936416, 3.3290840522927776, 1.1046205278862673, 0.5338143345073081, 1.3155456359473403, 1.8280645409160434, 0.5110021206154163, 1.5705257864246902, 0.5375678725557025, 3.3207961779128383, 1.6336779818340075, 2.0793213919554447, 1.5054719688187377, 3.594948408057047, 1.1007970687190238, 1.0451943654792957, 3.1499668220680426, 3.444918700514315, 3.2766662394168278, 0.5449138955563286, 2.3113155051813705, 2.054931203591027, 3.24213901270507, 3.2179302713151094, 0.7019089824629756, 2.1425060897794084, 2.76724149191693, 1.7200765842290595, 2.3910017479122234, 2.1843184253788395, 1.6445391200752058, 2.7006872514372677, 2.208489482784824, 3.353657660670198, 1.9093494631689936, 1.96897369707361, 1.4357246494613602, 1.9536564137379835, 2.632999227240448, 3.8303036754326256, 2.6203575672079507, 0.4026052785953045, 2.2635647494863753, 2.3755716580325195, 1.8625535188071605, 1.3073395368471377, 3.191553676956045, 3.283658529055766, 3.1126275460060002, 2.4669996406260677, 2.980393257832582, 1.8532639259031156, 1.866645352191568, 1.5492698288624038, 2.3078376347199065, 2.9841506069295876, 1.474418822521201, 1.062727555495467, 3.0296456111282306, 1.6170112932623772, 3.7846190893506493, 1.4560719540457758, 1.7255259329230586, 2.0764995342234083, 1.3579049436768975, 3.2837069022140155, 1.399837722939238, 0.29001894779738446, 3.260959355222623, 2.233989780695921, 0.9558052873505911, 3.3747434472036306, 4.050143470350914, 2.876204074546448, 0.7165243761246614, 1.7046918394376491, 0.6819803065986494, 1.3062139099557046, 2.637300784085148, 2.3814730588102093, 1.570177775344415, 2.8308256983698414, 1.9804073698021392, 3.5501224564539045, 1.7374834465086417, 1.7868974070436345, 1.1617020178530346, 1.8744257846592922, 1.4537631950697976, 3.0310164842474334, 0.026724343268818895, 2.4360794775521692, 3.5349573769444205, 1.9473931992246207, 2.9499198837722287, 1.0730651500088713, 4.181132547494148, 1.6467412633948841, 3.216857821574723, 2.7032342747261278, 1.4986956323271712, 1.0796946756431405, 2.3906943657234514, 3.0623912982131816, 3.4528763556570268, 2.1922748803925693, 2.068452090710994, 1.6795487717688693, 1.5352328619826872, 2.78656647089892, 2.0366550647325394, 2.8347828420272276, 3.0984352833064235, 1.8419051736213503, 3.5737059141247927, 3.0248017415307284, 2.1704218556225654, 2.794586978128984, 3.765226072156372, 3.223842561038022, 3.213482698729941, 3.566269012625033, 3.4010316948805035, 1.131953469548626, 3.535590944368171, 2.4845060715593226, 2.420294935807053, 1.695045013169775, 2.913700029009367, 3.2200083697318025, 2.0820077025144923, 2.774788083465545, 2.273100132641028, 3.195370747978059, 3.2158054255664816, 1.8092274574090448, 1.6479442662090267, 3.8000476169459447, 2.6444572286687325, 2.610102078361811, 2.3741287327023683, 3.2883241081102557, 2.019312092796862, 1.4566615316886997, 2.5578744933076787, 0.9328328938617243, 3.9855163317830775, 3.94426540930372, 0.921969706361677, 2.199866048920295, 1.820887756238628, 1.3261376563770018, 1.2539816820019634, 2.6274795283590286, 1.7072177366049188, 3.1520015251394176, 1.7269348732213232, 2.1731125559666724, 1.0221640886152912, 2.432268321418929, 0.9680734208483883, 3.5257924015043156, 3.027058211829048, 2.479153650667325, 0.3959004258128349, 3.9513497946122533, 3.009174235905162, 2.9316174101837107, 1.7163291136809375, 2.052841489113538, 1.5323089160768548, 1.775568961663204, 3.315804475282985, 2.943900923253929, 4.402488702636033, 2.4149762369037955, 3.617767824843806, 1.702416067615041, 1.7716053726016083, 2.15072597999708, 0.9428017613030599, 2.99373622000175, 3.505809699552851, 3.2715904111905747, 1.3390428125548293, 1.5807076118556362, 2.5205507060381374, 2.445627337061468, 1.2221226037319926, 2.1722415251950573, 3.2975263399250205, 2.5805739236949425, 2.4926253237820064, 3.7764418504461177, 2.8084982492205732, 2.3573253959202614, 1.7124861046291193, 2.7243773957628674, 2.2138274001326077, 3.574235490950946, 3.5169925827682813, 2.2522998196583215, 3.112821615150023, 1.8994121550578495, 2.6233457683435186, 1.955110095117429, 1.9078363429863705, 2.7008432785267056, 1.7812399821718983, 2.451268853446311, 3.312417324723661, 2.1959554817541074, 2.5801672417799617, 2.864168645166507, 3.397520995298612, 2.792564299077505, 3.301874370959775, 2.1270726656893095, 2.9325723601899463, 2.2321602164672316, 2.3069482515653488, 2.7291120271957445, 1.927911267754416, 0.9503678368061559, 1.9834417172741512, 1.5785438830201102, 1.5071820462757946, 1.9346563118105005, 3.1202554097104067, 2.94418377080784, 3.1500132038961213, 2.521169068524847, 2.678330875290869, 3.609587508745854, 1.8428897294743645, 0.03685139451418595, 2.085203747835482, 3.2139517817171583, 2.372529727987184, 2.890071029598356, 1.2570206235893544, 2.9822100514282206, 2.7946669903333565, 2.5910912138693414, 2.1337822960308013, 2.62095537714702, 4.020971781361753, 3.375138296968086, 2.606413711838024, 2.3723127681667893, 1.9379444332399371, 2.3277226423814725, 1.246032393249457, 2.7915009517140428, 2.728766097313656, 4.049737803539772, 4.100521193482738, 2.540756701700773, 1.197432368505994, 1.8134141544498266, 2.3138651323610553, 3.9644572046819335, 1.9420722687705223, 2.2183224234830106, 2.1413062978809996, 2.0055896139994123, 1.6791130806353052, 1.5701179449621039, 2.8704157411056284, 1.3438640753025326, 3.0137184617471973, 1.0446594274161634, 1.9688380047844123, 2.592386412725151, 2.1842515908928726, 1.4008314580648507, 1.0806186594103357, 2.4967275472440797, 3.6436599711545115, 3.3037655789004208, 3.5261775648129237, 3.408040593632561, 1.8385654358171348, 2.7261742995954843, 2.142816060298036, 2.261390051740013, 2.5741713701007076, 2.4963853632379274, 1.882218360864142, 1.666866806610702, 2.3724477642764996, 3.6864590775628936, 1.691959375842302, 1.611300573712617, 2.1212737475564287, 2.3545245905279657, 3.171961863110192, 2.0070594077241704, 2.827291687646254, 3.1196527048287814, 0.8943604060387635, 2.2551436053175933, 3.7281026787636917, 2.06886855152618, 1.5504113912490123, 2.525567554383547, 3.6169429323214026, 2.6930183506335816, 1.9875558924773489, 3.523268837441312, 0.9065067161187119, 1.8099069957146723, 3.187811383966379, 3.5155280605634665, 2.047901545670622, 3.8172143835889396, 3.262602238451174, 3.4419413439123727, 3.4489833806573995, 2.614879235673341, 3.2252600559005966, 2.7427303302759745, 2.7303969558102072, 2.8776194090224476, 1.262866780447623, 2.9228836583024957, 3.107524256178829, 3.2047930734178887, 1.9130300226910606, 0.9275409553644343, 2.141380826182187, 2.7287278045956183, 2.4921514929391364, 3.2599808176056277, 3.5910640378350416, 3.8434992022533536, 1.169160427708226, 1.7105542196153705, 0.9767318141667023, 1.5786155307717706, 1.532716751204954, 0.9949547976215363, 3.5527948138967687, 2.383701565836542, 2.717166077997347, 2.0727823933633407, 3.1703457038234544, 1.586248973965517, 4.160821812016183, 2.1212198878935085, 3.7036652878602943, 3.879432287083566, 1.9948833308544178, 3.04199494589632, 2.505764851183073, 3.0752478917743713, 3.322244697434543, 1.9073120986909635, 3.736479095614888, 2.863853417269316, 3.4129734723857186, 3.488418513081363, 2.238447442495054, 3.5436387461256147, 2.8705912933543165, 2.5462074627619455, 2.196302995568274, 3.5784684843085173, 3.55158245129426, 3.183915332500164, 3.6746952177818755, 2.8462297017754454, 4.0272153173033, 4.033549887958106, 4.179007848295367, 2.434440041340013, 4.041411220247507, 4.701505303246616, 3.102433742284696, 2.4090018259737653, 2.403586224956943, 3.021399977946243, 3.5078028370245122, 3.313043942814279, 2.6461676333438287, 2.7872655228854692, 3.133842698030484, 3.209846654315675, 2.8608638837894715, 2.8973507536373053, 3.6248454895442976, 3.915661341838819, 3.155519339477204, 2.675756984457103, 3.519675490814952, 3.996976704537199, 4.399283050534686, 4.156023872072124, 2.9055929565047336, 1.9011112530838106, 1.9524412414445327, 3.4388761476142897, 3.3219012028323616, 2.2942521393085165, 3.5834269957745843, 3.516972582169315, 1.4097402708561835, 3.1036074657609136, 1.6125561401852657, 2.4235724288626828, 3.42168746671928, 3.0030278679623312, 2.3358541288561976, 3.9073176889200627, 3.589986837702798, 2.733227010825774, 3.6662353661574927, 2.135288122777741, 3.542872889268646, 3.936383680764472, 2.6236226685764454, 2.1209210217099863, 2.6541542393752615, 3.193300085199721, 3.2314428159027435, 3.251256366423277, 2.33754038070052, 3.8845088413215048, 2.089592291925943, 2.7158783480103263, 2.3591905423799675, 3.5638880306947045, 2.395785265989471, 3.161668263908236, 2.5456082931083652, 3.7374057400808156, 2.6826011301619537, 1.8405832150016095, 3.3345117184517084, 3.792600285904324, 2.3498721586784312, 3.1940835024154017, 2.7132250832116243, 2.325201544606895, 3.9074023537253004, 3.8817991210188016, 2.9521128150320437, 3.645220844748795, 2.373204070732212, 3.743920789453647, 4.40217650669954, 3.7400862238736248, 2.548611731629551, 3.2013720675447406, 4.3195085949746534, 2.2210569812968872, 2.6856528126368078, 2.4943282305470436, 3.536334618980622, 3.3254576377883347, 3.798298871342468, 1.872937186649351, 3.453679166957189, 3.727930120341713, 2.453214695314431, 2.799960202824836, 2.333997873338583, 1.8379303045315978, 2.351353754439647, 2.3526940747015517, 3.3120855708148533, 0.9885897340084746, 2.7092409287724983, 2.685557772292697, 2.5560068670794727, 3.4470505697395333, 3.190294268668865, 2.160210149667125, 2.5472874122915363, 3.776604766076225, 3.786430040568954, 3.4836441808214187, 3.556460641563002, 3.287154471186025, 3.5892489235539142, 3.8768095989813696, 2.7661126699615504, 3.996281853753621, 3.112285954250535, 3.9399849652501895, 3.70146183581133, 4.005486591735814, 3.068837937219039, 3.2116113227859766, 2.9253857337976688, 3.765921328407709, 2.9601534268064387, 3.0471965561074215, 3.269449784250457, 3.379796855877349, 2.558891613093514, 2.7904714249580587, 2.005567073234017, 2.4703842487823535, 3.7825165314180613, 3.5349014973513877, 2.914037118555546, 3.8901382407095304, 2.079318259216046, 3.3070473323764147, 3.8953926303357975, 3.8928875159177276, 4.340015248285244, 4.275896150418932, 3.170508377134444, 3.5657251086341177, 3.171395331301136, 3.9495000194288896, 2.523326295217936, 1.3026069968671217, 2.56765371181606, 3.3009363989174445, 3.18361467490262, 3.9925755813027988, 3.7930267091657623, 4.304279029718165, 1.922222772917206, 3.291387452575052, 3.7420297437272816, 3.3666263620775934, 4.272417190640198, 3.8245937622790263, 2.4436374817708786, 2.4681628592087828, 2.986713644557342, 2.554757981125605, 1.8568185767513508, 3.3396747695701623, 2.3449800295721954, 3.8762599053751807, 2.030163267506005, 3.2557105403113407, 3.698676340755948, 3.9568478908833478, 3.4056597587959616, 2.1860411639600454, 1.2489636118564822, 2.0065124303173048, 2.9979524003277946, 3.4054997089862655, 3.932833987075662, 4.02349369443594, 2.814155912718853, 2.15932506668032, 3.4289587459275395, 3.549411132562469, 2.108170375976798, 3.361597440347824, 3.8604597948182984, 3.0542136503257695, 2.476484391975045, 2.086549259529832, 3.6431511882613035, 3.9992210624154105, 4.17923930269111, 3.989868435904451, 2.9189537451078134, 2.807407475060708, 3.1208244919685937, 2.876056275988938, 3.0666481145413966, 2.5944686711919585, 1.395511934609011, 2.6247972740848593, 3.3462397093517846, 3.4697358621602574, 4.264667764991033, 2.4544661442972626, 3.191974977035501, 3.1355436576264952, 2.428892178896903, 3.564860999236051, 3.764887900469542, 2.0210688692117094, 2.2533908842492845, 3.702743151791149, 3.5391483673554647, 3.948438646080461, 4.0593897729636215, 3.467727186963001, 2.6341482578892026, 2.989422374751972, 2.8857125151331466, 2.057325612444448, 0.7840450270696007, 3.9019818197796776, 2.662213590486712, 2.9827813713511984, 2.959775127139561, 3.638022302813195, 4.046063297459986, 3.688822022914126, 3.0931245107899357, 1.6410997814874846, 1.7393608242671332, 3.2362246856598738, 0.6916003005419402, 1.4396832384196205, 3.353868175581923, 2.20945520501893, 2.888015907972261, 1.0668136600162215, 3.7700780559107483, 2.3101120373776434, 1.3899839396487996, 1.8380253022599424, 2.7287124928994646, 2.8467558726652227, 2.326884590544546, 1.6411879559400973, 2.609639046682453, 2.5044826203807253, 3.0486460303552496, 1.8092675996158891, -0.4937381538465453, 3.849915342047091, 2.7442018614350503, 4.349024715007115, 3.479268768413077, 2.6632466120084177, 1.586133632497892, 3.429270627067447, 1.2251076908853769, 2.627886365188162, 3.195968242499607, 1.1482657217679582, 2.8247250044533394, 2.7872044478810207, 0.8524517456663689, 2.264143574052594, 1.9214173082940582, 1.6380426489672781, 1.5774303438258608, 2.0246951372886657, 4.1079330218585675, 2.755438754919561, 2.583562787737748, 1.8337288258979139, 0.1885613115300917, 3.382622615781877, 2.269057379232853, 3.2270020193505773, 1.1975269144974519, 1.7316309494012114, 2.422846693451826, 3.32110256648652, 2.496395614313873, 1.0246012940654832, 3.2922716383371484, 3.168953810117296, 3.1311381199531003, 2.583444313603049, 3.123089545534961, 1.832792273808336, 3.7763920171642176, 2.0345258354740614, 3.120246316863542, 1.1947157035881104, 2.764449809256689, 3.836836680649848, 3.257126413127347, 3.4355096508657224, 3.0180230389811347, 1.8459885839530417, 1.7226503605353987, 2.181194882253422, 2.9263224772394723, 3.337916434932407, 3.1504306386719043, 4.159031124203057, 3.0048766929898973, 3.113484155583161, 2.474780691047801, 3.340121062727308, 3.7989488279762686, 3.9848958140051116, 2.5998847820457684, 3.915139384480525, 2.973925101181542, 1.8971592512650863, 2.2483213528296173, 1.2322895509348137, 1.4944566898701441, 1.4103916530251115, 2.268672356704769, 3.539754905338311, 1.7714864319928805, 3.403329431683947, 0.9954729768421611, 3.21230923633732, 3.2304617860618823, 4.236329871205015, 2.970097282282048, 3.7243116004060757, 3.461797259013339, 3.5017450172096285, 3.6109203684973203, 2.7948224488386626, 3.0732890408649136, 2.685628752807818, 1.9683281400960113, 3.4094349805202078, 3.3665982733131927, 1.4162582131390993, 1.8983074735384338, 3.6736563505292366, 2.882558982587445, 1.4084784825152474, 5.019653805613721, 3.8240290075701373, 2.1041429509647886, 0.21117945333162425, 3.4432332405699735, 3.3076017602004986, 3.988881104277659, 1.6851760461245644, 2.488383036441165, -0.12013789383555329, 4.340147453010362, 3.0591657584400576, 4.107040301206625, 2.6282017418678514, 3.565019855821508, 1.7960605606187197, 1.2897780955382632, 2.599856496073866, 1.7610094244414518, 2.4749320231655463, 3.0260486874532613, 3.6178081672564883, 2.466888708290946, 1.402213746483381, 1.7942478474945243, 2.9375168124517548, 1.3936229283108013, 2.163264479601719, 3.773159779899722, 2.2854935964705776, 1.8644065757768522, 0.6088108323103216, 3.1952009081140855, 1.234070690257157, 3.5095188969772493, -0.6065986175491527, 0.33188611125404766, 2.586142392248051, 2.423664544094323, 1.2539555333180648, 2.9879218152043046, 3.3822518393540437, 0.685035493291587, 0.9796795478995406, 2.549684881321413, 3.4983246763538447, 0.3659437407212731, 2.4807028666555175, 2.932567066072208, 2.6577454316201012, 1.8835696359884677, 4.055598460475293, 1.0127576374407976, 0.519356696082373, 1.8330501492773421, 2.3140569667851913, 2.7290517475495553, 2.9695085767283027, 1.7249315975936552, 1.8970763660002432, 2.0118047405550974, 1.3782117371379372, 0.8387148199255559, 1.6379720580113593, 2.6500938114363155, 2.6491691543336495, 3.412113900700073, 1.5281752076240287, 1.9875038638521683, 1.8243450071248897, 3.9293659169442905, 2.9248129692289937, 3.0426722801864687, 2.3094061676058852, 0.5766896412107054, 4.608376571735175, 2.0775345318856266, 2.6698296359834828, 2.10639950935701, 3.842149795467631, 4.34104834441008, 2.8788640400544474, 2.5789339422778492, 1.9655186072567368, 2.5252159068025444, 3.4267423266140136, 2.3019997382971646, 1.811152715768971, 3.3880978705411464, 2.723588287341063, 4.399364698550924, 3.381992360658265, 3.204781431502833, 0.9515070746612668, 2.5323125170367997, 3.0664739484819052, 3.2913351012261614, 2.402012594305343, 1.0905287813173279, 1.6787023139513964, 3.1699922804484326, 3.5410265499101183, 3.429952027233839, 3.8613572098201447, 2.2511361529290093, 3.5498650607802706, 4.958002383770324, 3.3832257203375993, 3.5853940551113337, 2.41086327024005, 2.003554593313454, 2.7078422424462327, 3.9440720884131744, 2.4532810051596283, 1.9253109804602349, 0.7230651794767462, 3.6856469584305613, 1.2171716870775766, 2.104686278625223, 2.429148270005076, 2.090901378342806, 1.6532425082227786, 3.1409705996072232, -0.03483460430907126, 2.9103796095485346, 0.7765505488025757, 0.9034238938848846, 2.7581439814843427, 1.9901517134495714, 1.6525529435360595, 1.6769384354410604, 1.2943639927570159, -0.4128409988059286, 1.572947121919047]}\n"
     ]
    }
   ],
   "source": [
    "score = aci_service.run(input_data = data)\n",
    "\n",
    "# embeddings will print the error message incase error occurs.\n",
    "print('nb sentences encoded : {0}'.format(len(score)))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7710588060229734\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "#print(train_y)\n",
    "result = json.loads(score)\n",
    "output = result[\"result\"]\n",
    "print(pearsonr(output, train_y)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the Best Model\n",
    "\n",
    "Now we can identify the model that maximized performance on a given metric (spearman correlation in our case). The object returned by AutoML is a Pipeline class which chains together multiple steps in a machine learning workflow in order to provide a \"reproducible mechanism for building, evaluating, deploying, and running ML systems\" (see [here](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-getting-started.ipynb) for additional information about Pipelines). Our best model is a Pipeline with two steps: a DataTransformer step and a PreFittedSoftVotingRegressor step. We demonstrate how to extract additional information about what data transformations were used and which models make up the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_metric = \"spearman_correlation\"\n",
    "best_run, fitted_model = local_run.get_output(metric = lookup_metric)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the different models that are used to produce the stack ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model.named_steps['stackensembleregressor'].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at how each column in our dataset was featurized by AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model.named_steps['datatransformer'].get_featurization_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
